[
  {
    "objectID": "D2_congestion_tests.html",
    "href": "D2_congestion_tests.html",
    "title": "Testing changes in centrality",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"zonebuilder\",\n    \"tmap\"\n    # \"dodgr\" # Using the developer version of dodgr\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n         sf   tidyverse zonebuilder        tmap \n       TRUE        TRUE        TRUE        TRUE \n\nrequire(dodgr)\npackageVersion (\"dodgr\")\n\n[1] '0.4.1.37'\n\n\n\n\n\nsf_bogota_2019_raw &lt;- st_read(file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),\n                              layer = \"network_2019\") |&gt;\n  mutate(way_speed = case_when(highway %in%\n                                 c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~\"road_60\",\n                               TRUE ~ \"road_30\")) |&gt; \n  rename(roadclass = highway) |&gt;\n  # mutate(oneway.raw = oneway,\n  #        oneway = if_else(roadclass %in% c(\"residential\",\"unclassified\"),\n  #                         \"no\",\n  #                         oneway)) |&gt; \n  st_transform(4326)\n\nReading layer `network_2019' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 54531 features and 15 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.441 ymin: 4.236862 xmax: -73.72583 ymax: 5.042826\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nInspecting the values of the oneway tag in residential and unclassified roads\n\nsf_bogota_2019_raw |&gt; filter(roadclass %in% c(\"residential\",\"unclassified\")) |&gt; pull(oneway) |&gt; unique()\n\n[1] NA           \"yes\"        \"no\"         \"reversible\" \"-1\"        \n[6] \"nolt\"      \n\n\nWe will reverse those links to allow the vehicles to travel in the wrong direction\n\noneway_minor_rev &lt;- sf_bogota_2019_raw |&gt; \n  filter(roadclass %in% c(\"residential\",\"unclassified\"),\n         str_detect(pattern = \"yes\",oneway)) |&gt; \n  st_reverse() |&gt; \n  mutate(osm_id = paste0(osm_id,\"r\"),\n         way_speed = \"road_10\")\n\n\nsf_bogota_2019_full &lt;- bind_rows(sf_bogota_2019_raw,\n                                 oneway_minor_rev)\n\nWe will use a small subset of the network for this test to speed up the process.\n\nbog_zone &lt;- zonebuilder::zb_zone(\"Bogota\",\n                                 n_circles = 2) |&gt; \n  st_transform(4326)\n# zb_view(bog_zone)\n\n\nsf_bogota_2019 &lt;- sf_bogota_2019_full[bog_zone,]\n\n\n\n\n\ndodgr::clear_dodgr_cache()\n\ngraph_bogota &lt;- weight_streetnet(sf_bogota_2019,\n                                 left_side = F,\n                                 wt_profile_file = \"custom_wp_speeds.json\",\n                                 type_col = \"way_speed\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols =\n                                   c(\"way_speed\",\"oneway\",\"lanes\",\"surface\",\"maxspeed\",\"roadclass\"),\n                                 turn_penalty = F)\n\nbog_contracted &lt;- graph_bogota |&gt; \n  dodgr_contract_graph()\n\nFixing the weighted time column\n\ndodgr::clear_dodgr_cache()\n\nbog_contracted$time_weighted &lt;- 3.6*bog_contracted$d_weighted/as.numeric(str_extract(bog_contracted$highway,\"\\\\d{1,2}$\"))\n\nCalculating the centrality\n\nbog_centrality &lt;- bog_contracted |&gt;\n      dodgr_centrality(column = \"time_weighted\")\n\n\n\n\ncongested_contracted &lt;- bog_contracted\ndodgr::clear_dodgr_cache()\ncongested_contracted$time_weighted[congested_contracted$highway == \"road_60\"] &lt;- (3.6*congested_contracted$d_weighted[congested_contracted$highway == \"road_60\"])/30\n\nCalculating the centrality\n\ncongested_centrality &lt;- congested_contracted |&gt;\n      dodgr_centrality(column = \"time_weighted\",dist_threshold = 1e3)\n\n\n\n\ncent_all &lt;- tibble(edge_id = bog_centrality$edge_id,\n                   cent_bl = bog_centrality$centrality) |&gt; \n  left_join(\n    tibble(edge_id = congested_centrality$edge_id,\n           cent_cong = congested_centrality$centrality),\n    by = \"edge_id\"\n  ) |&gt; \n  mutate(\n    diff = cent_cong - cent_bl,\n    reldiff = diff/(0.5*(cent_bl+cent_cong))\n  )\n\n\n\n\n\nsf_net &lt;- graph_bogota |&gt; \n  dodgr_to_sf() |&gt; \n  left_join(cent_all,by = \"edge_id\")\n\n\nggplot(cent_all, aes(diff))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(cent_all, aes(reldiff))+\n  geom_histogram()+\n  scale_x_continuous(limits = c(-1,1))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2960 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\nsf_net |&gt; \n  mutate(reldiff = if_else(abs(reldiff)&gt;2,\n                           NA_real_,\n                           reldiff)) |&gt; \n  ggplot(aes(col = reldiff))+\n  geom_sf()+\n  theme_void()+\n  scale_color_gradient2(midpoint = 0,\n                        low = \"red3\",\n                        high = \"green4\",\n                        mid = \"yellow\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis section includes the code for joining the speed data network with OSM network\n\nsf_speed &lt;- st_read(\"sf_network/sf_speed_network.gpkg\") |&gt; st_transform(3116)\n\nReading layer `sf_speed_network' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\sf_speed_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1267 features and 1 field\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.18353 ymin: 5.684342e-14 xmax: 1 ymax: 4.764635\nGeodetic CRS:  MAGNA-SIRGAS\n\nsf_speed_clean &lt;- sf_speed[bog_zone |&gt; st_transform(3116) ,]\n\n\nroad_types &lt;- rev(c(\n  \"trunk\"          ,\n  \"trunk_link\"     ,\n  \"primary\"      ,\n  \"primary_link\"   ,\n  \"secondary\"      ,\n  \"secondary_link\" ,\n  \"tertiary\"       ,\n  \"tertiary_link\"  ,\n  \"unclassified\"   ,\n  \"residential\"    \n))\n\nsf_bog_major &lt;- sf_net |&gt;\n  mutate(roadclass = factor(roadclass,\n                          levels = road_types,\n                          ordered = T)) |&gt; \n  filter(as.integer(roadclass)&gt;2,str_detect(roadclass,\"link\",negate = T)) |&gt; \n  st_transform(3116)\n\nExtracting bearings and creating a buffer to produce a correspondence\n\nsf_speed_clean$s.bearing &lt;- stplanr::line_bearing(sf_speed_clean)\n\nspeed_buffer &lt;- sf_speed_clean  |&gt;  st_buffer(100,endCapStyle = \"FLAT\") \n\nA quick visualisation of the network that could be part of the correspondence\n\ntm_shape(sf_bog_major[speed_buffer,])+\n  tm_lines()+\n  tm_shape(speed_buffer)+\n  tm_polygons(\"blue\",alpha = 0.3)\n\n\n\n\n\n\n\n\nusing the spatial operation st_intersects we select the links that can be related to the buffer.\n\nspeed_corresp &lt;- st_intersects(speed_buffer,sf_bog_major)\n\nTID_to_edge_id &lt;- do.call(bind_rows,\n        lapply(seq_along(speed_corresp),\n               \\(i) {\n                 \n                 x &lt;- speed_corresp[[i]]\n                 \n                 subset_net &lt;- sf_bog_major[x, ]\n                 \n                 ref_bearing &lt;- speed_buffer$s.bearing[[i]]\n                 ref_TID &lt;- speed_buffer$TID[[i]]\n                 \n                 subset_net$bearing &lt;- stplanr::line_bearing(subset_net)\n                 \n                 sf_ids &lt;- subset_net |&gt;\n                   mutate(bearing_check = round(abs(bearing - ref_bearing))&lt;=15) |&gt;\n                   filter(bearing_check) |&gt;\n                   pull(edge_id)\n                 \n                 tibble(TID = ref_TID, edge_id = sf_ids)\n                 }\n               )\n        )\n\nIt is possible that some links in the road network are found to be linked to multiple links in the speed network, so we will resolve such situation. First, we identify the overlaps\n\noverlap_buffer &lt;- TID_to_edge_id |&gt; \n  unique() |&gt; \n  count(edge_id) |&gt; \n  arrange(-n) |&gt; \n  filter(n&gt;1)\n\nA quick check on the distribution of overlaps\n\noverlap_buffer |&gt; \n  ggplot(aes(n))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThe following code will produce plots for all links with one-to-many correspondence. However, we will calculate the average of the speed of the observed speeds\n\n# for (j in 1:nrow(overlap_buffer)){\n#   mmap &lt;- tm_shape(speed_buffer[speed_buffer$TID %in% TID_to_edge_id$TID[TID_to_edge_id$edge_id==overlap_buffer$edge_id[j]],])+\n#     tm_polygons(\"TID\",alpha = 0.3)+\n#     tm_shape(sf_bog_major[sf_bog_major$edge_id == overlap_buffer$edge_id[j],])+\n#     tm_lines(\"yellow\")\n#   print(mmap)\n#   }\n\nTo check if there is any link in the speed dataset that has not been linked to any object of the road network.\n\nno_match_speed &lt;- sf_speed_clean |&gt;\n  anti_join(TID_to_edge_id |&gt;\n              select(TID) |&gt;\n              unique(),\n            by = \"TID\")\n\nnrow(no_match_speed)\n\n[1] 0\n\n\n\n\n\nThe following code loads the data\n\nspeed_data &lt;- read_csv(\"sf_network/summary_speeds.csv\")\n\nRows: 110880 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): day_type\ndbl (11): TID, year, hour, d_min_speed, d_q1_speed, d_median_speed, d_mean_s...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe identify the hour that showed the lowest speeds in average\n\nmin_speed_key &lt;- speed_data |&gt;\n  summarise(mean_norm_speed = mean(d_norm_speed),.by = c(year,day_type,hour)) |&gt; \n  slice_min(mean_norm_speed,by = c(year,day_type)) |&gt; \n  filter(year == 2019,day_type == \"weekday\") |&gt; \n  select(-mean_norm_speed)\n\nWe will extract the observed speed for the hour we just identified\n\nspeed_tbl &lt;- speed_data |&gt;\n  semi_join(min_speed_key,\n            by = join_by(year,day_type,hour)) |&gt; \n  select(TID,d_mean_speed)\n\nWe join the speed data to the correspondence we produced before\n\nobs_speeds_edges &lt;- TID_to_edge_id |&gt;\n  left_join(speed_tbl,by = \"TID\") |&gt; \n  summarise(obs_speed = mean(d_mean_speed),.by = edge_id)\n\nUsing the observed speed we recalculate the time_weighted.\n\nbog_contr_adjusted &lt;- bog_contracted\ndodgr::clear_dodgr_cache()\nbog_contr_adjusted$obs_speed &lt;- tibble(edge_id = bog_contr_adjusted$edge_id) |&gt; \n  left_join(obs_speeds_edges,by = \"edge_id\") |&gt; \n  pull(obs_speed)\ndodgr::clear_dodgr_cache()\nbog_contr_adjusted$time_weighted[!is.na(bog_contr_adjusted$obs_speed)] &lt;- (3.6*bog_contr_adjusted$d_weighted[!is.na(bog_contr_adjusted$obs_speed)])/bog_contr_adjusted$obs_speed[!is.na(bog_contr_adjusted$obs_speed)]\n\nWe calculate the centrality for the congested graph.\n\ncongested_centrality &lt;- bog_contr_adjusted |&gt;\n      dodgr_centrality(column = \"time_weighted\")\n\n\n\nWe consolidate the values of free-flow network and congested network into a single dataset\n\ncent_all &lt;- tibble(edge_id = bog_centrality$edge_id,\n                   cent_bl = bog_centrality$centrality) |&gt; \n  left_join(\n    tibble(edge_id = congested_centrality$edge_id,\n           cent_cong = congested_centrality$centrality),\n    by = \"edge_id\"\n  ) |&gt; \n  mutate(\n    diff = cent_cong - cent_bl,\n    reldiff = diff/(0.5*(cent_bl+cent_cong))\n  )\n\n\n\n\nThe following code produce some quick visualisation of the differences\n\nsf_net &lt;- graph_bogota |&gt; \n  dodgr_to_sf() |&gt; \n  left_join(cent_all,by = \"edge_id\")\n\n\nggplot(cent_all, aes(diff))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(cent_all, aes(reldiff))+\n  geom_histogram()+\n  scale_x_continuous(limits = c(-2,2))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 472 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\nsf_net |&gt; \n  mutate(reldiff = if_else(abs(reldiff)&gt;2,\n                           NA_real_,\n                           reldiff)) |&gt; \n  ggplot(aes(col = reldiff))+\n  geom_sf()+\n  theme_void()+\n  scale_color_gradient2(midpoint = 0,\n                        low = \"red3\",\n                        high = \"green4\",\n                        mid = \"yellow\")\n\n\n\n\n\n\n\n\n\n\n\n\nThe distance from the major network might be related to the reports of traffic offences. For this purpose, we need the following code to obtain the average distance of each minor link to the major network.\nIdentifying the junctions and classifying them based on the road hierarchy\n\nlow_hierarchy &lt;- c(\"residential\",\"unclassified\")\n\njunction_class_to &lt;- sf_net |&gt; \n  st_drop_geometry() |&gt; \n  mutate(road_type = if_else(roadclass %in% low_hierarchy,\n                             \"minor\",\n                             \"major\")) |&gt;\n  summarise(count = n(),.by = c(to_id,road_type)) |&gt;\n  pivot_wider(names_from = road_type,values_from = count)|&gt; \n  rename(id = to_id)\n\njunction_class_from &lt;- sf_net |&gt; \n  st_drop_geometry() |&gt; \n  mutate(road_type = if_else(roadclass %in% low_hierarchy,\n                             \"minor\",\n                             \"major\")) |&gt; \n  summarise(count = n(),.by = c(from_id,road_type)) |&gt;\n  pivot_wider(names_from = road_type,values_from = count) |&gt;\n  rename(id = from_id)\n\njunctions_classed &lt;- junction_class_to |&gt; \n  full_join(junction_class_from,by = \"id\",suffix = c(\".to\",\".from\")) |&gt; \n  mutate(jct_type = case_when(is.na(minor.to)&is.na(minor.from)~\"major\",\n                              is.na(major.to)&is.na(major.from)~\"minor\",\n                              (!is.na(minor.to)&!is.na(major.from))|\n                                (!is.na(minor.from)&!is.na(major.to))~\"minmaj\")) |&gt; \n  select(-starts_with(\"m\"))\n\nCalculating the network distance for all nodes in the minor network to the major network\n\nminmaj_ids &lt;- junctions_classed |&gt; filter(jct_type == \"minmaj\") |&gt; pull(id)\nminor_from_ids &lt;- junctions_classed |&gt; filter(jct_type == \"minor\") |&gt; pull(id)\n\ndist_matrix &lt;- dodgr_dists(bog_contracted,\n                           from = minor_from_ids,\n                           to = minmaj_ids,\n                           shortest = T)\n\n\nlength(colSums(dist_matrix)[is.na(colSums(dist_matrix,na.rm = T))])\n\n[1] 0\n\n\n\nfastest_all &lt;- tibble(\n  id.jct = minor_from_ids,\n  dist.jct =\n    apply(dist_matrix, 1,\\(x) min(x,na.rm = TRUE)\n      )\n  )\n\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\n\n\n\nsf_net_jct &lt;- sf_net |&gt; left_join(fastest_all,\n                                  by = c(\"from_id\"=\"id.jct\"),\n                                  relationship = \"many-to-one\") |&gt; \n  mutate(dist.jct = case_when(is.na(dist.jct)&roadclass %in% low_hierarchy ~ 0,\n                              is.infinite(dist.jct)~NA,\n                              T~dist.jct))\n\n\n\n\n\n\nst_write(sf_net_jct,\"sf_network/small_sf_network_cent_results.gpkg\",delete_dsn = T)\n\nDeleting source `sf_network/small_sf_network_cent_results.gpkg' using driver `GPKG'\nWriting layer `small_sf_network_cent_results' to data source \n  `sf_network/small_sf_network_cent_results.gpkg' using driver `GPKG'\nWriting 10970 features with 26 fields and geometry type Line String.\n\n\n\n\n\n\n\nWe assumed an initial speed of 10 km/h for the links that represent the wrong direction. But that choice is arbitrary. The following section will produce the results for multiple speeds, to compare the changes in centrality based on the assumed fre-flow speed of wrong-way links. First, we will test the changes on the free-flow network\n\ntest_centralities &lt;- do.call(bind_cols,\n                             lapply(seq(0, 30, 1), \\(v) {\n                               bog_ff_test &lt;- bog_contracted\n                               \n                               dodgr::clear_dodgr_cache()\n                               bog_ff_test$time_weighted[bog_ff_test$highway == \"road_10\"] &lt;- (3.6 * bog_ff_test$d_weighted[bog_ff_test$highway == \"road_10\"]) / v\n                               \n                               \n                               test_centrality &lt;- bog_ff_test |&gt;\n                                 dodgr_centrality(column = \"time_weighted\")\n                               \n                               \n                               t &lt;- tibble(cent = test_centrality$centrality)\n                               names(t) &lt;- paste0(\"cent_\", v)\n                               return(t)\n                               \n                             }))\n\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\n\n\nVisualising the impact of the assigned speed on centrality distribution across the network (top)\n\ntest_centralities |&gt;\n  pivot_longer(cols = any_of(names(test_centralities)),\n               names_prefix = \"cent_\") |&gt;\n  mutate(name = as.integer(name)) |&gt; \n  ggplot(aes(x = factor(name),y = value+1))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution\",\n       x = \"WWD links assigned speed\")\n\n\n\n\n\n\n\ntibble(highway = bog_contracted[,c(\"highway\")]) |&gt; \n  bind_cols(test_centralities) |&gt; \n  filter(highway == \"road_10\") |&gt; \n  pivot_longer(-highway,names_prefix = \"cent_\") |&gt;\n  mutate(name = as.integer(name)) |&gt; \n  ggplot(aes(x = factor(name),y = value+1))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution (only WW-links)\",\n       x = \"WWD links assigned speed\")\n\n\n\n\n\n\n\n\n\n\n\n\ntest_centralities_cong &lt;- do.call(bind_cols,\n                             lapply(seq(0, 30, 1), \\(v) {\n                               bog_ff_test &lt;- bog_contr_adjusted \n                               \n                               dodgr::clear_dodgr_cache()\n                               bog_ff_test$time_weighted[bog_ff_test$highway == \"road_10\"] &lt;- (3.6 * bog_ff_test$d_weighted[bog_ff_test$highway == \"road_10\"]) / v\n                               \n                               \n                               test_centrality &lt;- bog_ff_test |&gt;\n                                 dodgr_centrality(column = \"time_weighted\")\n                               \n                               \n                               t &lt;- tibble(cent = test_centrality$centrality)\n                               names(t) &lt;- paste0(\"cent_\", v)\n                               return(t)\n                               \n                             }))\n\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\n\n\nVisualising the impact of the assigned speed on centrality distribution across the network (top)\n\ntest_centralities_cong |&gt;\n  pivot_longer(cols = any_of(names(test_centralities_cong)),\n               names_prefix = \"cent_\") |&gt;\n  mutate(name = as.integer(name)) |&gt; \n  ggplot(aes(x = factor(name),y = value+1))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution\",\n       x = \"WWD links assigned speed\")\n\n\n\n\n\n\n\ntibble(highway = bog_contr_adjusted[,c(\"highway\")]) |&gt; \n  bind_cols(test_centralities_cong) |&gt; \n  filter(highway == \"road_10\") |&gt; \n  pivot_longer(-highway,names_prefix = \"cent_\") |&gt;\n  mutate(name = as.integer(name)) |&gt; \n  ggplot(aes(x = factor(name),y = value+1))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution (only WW-links)\",\n       x = \"WWD links assigned speed\")\n\n\n\n\n\n\n\n\n\n\n\n\nwwlinks &lt;- bind_cols(\n  tibble(highway = bog_contr_adjusted[, c(\"highway\")]) |&gt;\n    bind_cols(test_centralities_cong) |&gt;\n    filter(highway == \"road_10\") |&gt;\n    pivot_longer(-highway, names_prefix = \"cent_\",\n                 values_to = \"ff_cent\"),\n  tibble(highway = bog_contracted[, c(\"highway\")]) |&gt;\n    bind_cols(test_centralities) |&gt;\n    filter(highway == \"road_10\") |&gt;\n    pivot_longer(-highway, names_prefix = \"cent_\",\n                 values_to = \"cong_cent\")\n)\n\nNew names:\n• `highway` -&gt; `highway...1`\n• `name` -&gt; `name...2`\n• `highway` -&gt; `highway...4`\n• `name` -&gt; `name...5`\n\n\nA simple linear model\n\nm1 &lt;- lm(ff_cent~cong_cent+0, data = wwlinks)\nsummary(m1)\n\n\nCall:\nlm(formula = ff_cent ~ cong_cent + 0, data = wwlinks)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-545233       0       1    1308  984026 \n\nCoefficients:\n          Estimate Std. Error t value Pr(&gt;|t|)    \ncong_cent 0.931455   0.007189   129.6   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38040 on 50033 degrees of freedom\nMultiple R-squared:  0.2512,    Adjusted R-squared:  0.2512 \nF-statistic: 1.679e+04 on 1 and 50033 DF,  p-value: &lt; 2.2e-16\n\n\n\nwwlinks |&gt;\n  mutate(name = as.integer(name...2),\n         sign = (cong_cent-ff_cent)/abs(cong_cent-ff_cent)) |&gt;\n  ggplot(aes(x = factor(name),y = abs(cong_cent-ff_cent),fill = factor(sign)))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution (only WW-links)\",\n       x = \"WWD links assigned speed\")\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\n\n\nWarning: Removed 18483 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nwwlinks |&gt;\n  mutate(name = as.integer(name...2),\n         sign = (cong_cent-ff_cent)/abs(cong_cent-ff_cent)) |&gt;\n  ggplot(aes(x = factor(name),y = abs(cong_cent-ff_cent)/(0.5*(cong_cent+ff_cent)),fill = factor(sign)))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution (only WW-links)\",\n       x = \"WWD links assigned speed\")\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\n\n\nWarning: Removed 18483 rows containing non-finite outside the scale range\n(`stat_boxplot()`)."
  },
  {
    "objectID": "D2_congestion_tests.html#loading-network",
    "href": "D2_congestion_tests.html#loading-network",
    "title": "Testing changes in centrality",
    "section": "",
    "text": "sf_bogota_2019_raw &lt;- st_read(file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),\n                              layer = \"network_2019\") |&gt;\n  mutate(way_speed = case_when(highway %in%\n                                 c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~\"road_60\",\n                               TRUE ~ \"road_30\")) |&gt; \n  rename(roadclass = highway) |&gt;\n  # mutate(oneway.raw = oneway,\n  #        oneway = if_else(roadclass %in% c(\"residential\",\"unclassified\"),\n  #                         \"no\",\n  #                         oneway)) |&gt; \n  st_transform(4326)\n\nReading layer `network_2019' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 54531 features and 15 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.441 ymin: 4.236862 xmax: -73.72583 ymax: 5.042826\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nInspecting the values of the oneway tag in residential and unclassified roads\n\nsf_bogota_2019_raw |&gt; filter(roadclass %in% c(\"residential\",\"unclassified\")) |&gt; pull(oneway) |&gt; unique()\n\n[1] NA           \"yes\"        \"no\"         \"reversible\" \"-1\"        \n[6] \"nolt\"      \n\n\nWe will reverse those links to allow the vehicles to travel in the wrong direction\n\noneway_minor_rev &lt;- sf_bogota_2019_raw |&gt; \n  filter(roadclass %in% c(\"residential\",\"unclassified\"),\n         str_detect(pattern = \"yes\",oneway)) |&gt; \n  st_reverse() |&gt; \n  mutate(osm_id = paste0(osm_id,\"r\"),\n         way_speed = \"road_10\")\n\n\nsf_bogota_2019_full &lt;- bind_rows(sf_bogota_2019_raw,\n                                 oneway_minor_rev)\n\nWe will use a small subset of the network for this test to speed up the process.\n\nbog_zone &lt;- zonebuilder::zb_zone(\"Bogota\",\n                                 n_circles = 2) |&gt; \n  st_transform(4326)\n# zb_view(bog_zone)\n\n\nsf_bogota_2019 &lt;- sf_bogota_2019_full[bog_zone,]"
  },
  {
    "objectID": "D2_congestion_tests.html#baseline-graph-building",
    "href": "D2_congestion_tests.html#baseline-graph-building",
    "title": "Testing changes in centrality",
    "section": "",
    "text": "dodgr::clear_dodgr_cache()\n\ngraph_bogota &lt;- weight_streetnet(sf_bogota_2019,\n                                 left_side = F,\n                                 wt_profile_file = \"custom_wp_speeds.json\",\n                                 type_col = \"way_speed\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols =\n                                   c(\"way_speed\",\"oneway\",\"lanes\",\"surface\",\"maxspeed\",\"roadclass\"),\n                                 turn_penalty = F)\n\nbog_contracted &lt;- graph_bogota |&gt; \n  dodgr_contract_graph()\n\nFixing the weighted time column\n\ndodgr::clear_dodgr_cache()\n\nbog_contracted$time_weighted &lt;- 3.6*bog_contracted$d_weighted/as.numeric(str_extract(bog_contracted$highway,\"\\\\d{1,2}$\"))\n\nCalculating the centrality\n\nbog_centrality &lt;- bog_contracted |&gt;\n      dodgr_centrality(column = \"time_weighted\")\n\n\n\n\ncongested_contracted &lt;- bog_contracted\ndodgr::clear_dodgr_cache()\ncongested_contracted$time_weighted[congested_contracted$highway == \"road_60\"] &lt;- (3.6*congested_contracted$d_weighted[congested_contracted$highway == \"road_60\"])/30\n\nCalculating the centrality\n\ncongested_centrality &lt;- congested_contracted |&gt;\n      dodgr_centrality(column = \"time_weighted\",dist_threshold = 1e3)\n\n\n\n\ncent_all &lt;- tibble(edge_id = bog_centrality$edge_id,\n                   cent_bl = bog_centrality$centrality) |&gt; \n  left_join(\n    tibble(edge_id = congested_centrality$edge_id,\n           cent_cong = congested_centrality$centrality),\n    by = \"edge_id\"\n  ) |&gt; \n  mutate(\n    diff = cent_cong - cent_bl,\n    reldiff = diff/(0.5*(cent_bl+cent_cong))\n  )\n\n\n\n\n\nsf_net &lt;- graph_bogota |&gt; \n  dodgr_to_sf() |&gt; \n  left_join(cent_all,by = \"edge_id\")\n\n\nggplot(cent_all, aes(diff))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(cent_all, aes(reldiff))+\n  geom_histogram()+\n  scale_x_continuous(limits = c(-1,1))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2960 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\nsf_net |&gt; \n  mutate(reldiff = if_else(abs(reldiff)&gt;2,\n                           NA_real_,\n                           reldiff)) |&gt; \n  ggplot(aes(col = reldiff))+\n  geom_sf()+\n  theme_void()+\n  scale_color_gradient2(midpoint = 0,\n                        low = \"red3\",\n                        high = \"green4\",\n                        mid = \"yellow\")"
  },
  {
    "objectID": "D2_congestion_tests.html#using-the-actual-speeds-for-adjusting-graph",
    "href": "D2_congestion_tests.html#using-the-actual-speeds-for-adjusting-graph",
    "title": "Testing changes in centrality",
    "section": "",
    "text": "This section includes the code for joining the speed data network with OSM network\n\nsf_speed &lt;- st_read(\"sf_network/sf_speed_network.gpkg\") |&gt; st_transform(3116)\n\nReading layer `sf_speed_network' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\sf_speed_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1267 features and 1 field\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.18353 ymin: 5.684342e-14 xmax: 1 ymax: 4.764635\nGeodetic CRS:  MAGNA-SIRGAS\n\nsf_speed_clean &lt;- sf_speed[bog_zone |&gt; st_transform(3116) ,]\n\n\nroad_types &lt;- rev(c(\n  \"trunk\"          ,\n  \"trunk_link\"     ,\n  \"primary\"      ,\n  \"primary_link\"   ,\n  \"secondary\"      ,\n  \"secondary_link\" ,\n  \"tertiary\"       ,\n  \"tertiary_link\"  ,\n  \"unclassified\"   ,\n  \"residential\"    \n))\n\nsf_bog_major &lt;- sf_net |&gt;\n  mutate(roadclass = factor(roadclass,\n                          levels = road_types,\n                          ordered = T)) |&gt; \n  filter(as.integer(roadclass)&gt;2,str_detect(roadclass,\"link\",negate = T)) |&gt; \n  st_transform(3116)\n\nExtracting bearings and creating a buffer to produce a correspondence\n\nsf_speed_clean$s.bearing &lt;- stplanr::line_bearing(sf_speed_clean)\n\nspeed_buffer &lt;- sf_speed_clean  |&gt;  st_buffer(100,endCapStyle = \"FLAT\") \n\nA quick visualisation of the network that could be part of the correspondence\n\ntm_shape(sf_bog_major[speed_buffer,])+\n  tm_lines()+\n  tm_shape(speed_buffer)+\n  tm_polygons(\"blue\",alpha = 0.3)\n\n\n\n\n\n\n\n\nusing the spatial operation st_intersects we select the links that can be related to the buffer.\n\nspeed_corresp &lt;- st_intersects(speed_buffer,sf_bog_major)\n\nTID_to_edge_id &lt;- do.call(bind_rows,\n        lapply(seq_along(speed_corresp),\n               \\(i) {\n                 \n                 x &lt;- speed_corresp[[i]]\n                 \n                 subset_net &lt;- sf_bog_major[x, ]\n                 \n                 ref_bearing &lt;- speed_buffer$s.bearing[[i]]\n                 ref_TID &lt;- speed_buffer$TID[[i]]\n                 \n                 subset_net$bearing &lt;- stplanr::line_bearing(subset_net)\n                 \n                 sf_ids &lt;- subset_net |&gt;\n                   mutate(bearing_check = round(abs(bearing - ref_bearing))&lt;=15) |&gt;\n                   filter(bearing_check) |&gt;\n                   pull(edge_id)\n                 \n                 tibble(TID = ref_TID, edge_id = sf_ids)\n                 }\n               )\n        )\n\nIt is possible that some links in the road network are found to be linked to multiple links in the speed network, so we will resolve such situation. First, we identify the overlaps\n\noverlap_buffer &lt;- TID_to_edge_id |&gt; \n  unique() |&gt; \n  count(edge_id) |&gt; \n  arrange(-n) |&gt; \n  filter(n&gt;1)\n\nA quick check on the distribution of overlaps\n\noverlap_buffer |&gt; \n  ggplot(aes(n))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThe following code will produce plots for all links with one-to-many correspondence. However, we will calculate the average of the speed of the observed speeds\n\n# for (j in 1:nrow(overlap_buffer)){\n#   mmap &lt;- tm_shape(speed_buffer[speed_buffer$TID %in% TID_to_edge_id$TID[TID_to_edge_id$edge_id==overlap_buffer$edge_id[j]],])+\n#     tm_polygons(\"TID\",alpha = 0.3)+\n#     tm_shape(sf_bog_major[sf_bog_major$edge_id == overlap_buffer$edge_id[j],])+\n#     tm_lines(\"yellow\")\n#   print(mmap)\n#   }\n\nTo check if there is any link in the speed dataset that has not been linked to any object of the road network.\n\nno_match_speed &lt;- sf_speed_clean |&gt;\n  anti_join(TID_to_edge_id |&gt;\n              select(TID) |&gt;\n              unique(),\n            by = \"TID\")\n\nnrow(no_match_speed)\n\n[1] 0\n\n\n\n\n\nThe following code loads the data\n\nspeed_data &lt;- read_csv(\"sf_network/summary_speeds.csv\")\n\nRows: 110880 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): day_type\ndbl (11): TID, year, hour, d_min_speed, d_q1_speed, d_median_speed, d_mean_s...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe identify the hour that showed the lowest speeds in average\n\nmin_speed_key &lt;- speed_data |&gt;\n  summarise(mean_norm_speed = mean(d_norm_speed),.by = c(year,day_type,hour)) |&gt; \n  slice_min(mean_norm_speed,by = c(year,day_type)) |&gt; \n  filter(year == 2019,day_type == \"weekday\") |&gt; \n  select(-mean_norm_speed)\n\nWe will extract the observed speed for the hour we just identified\n\nspeed_tbl &lt;- speed_data |&gt;\n  semi_join(min_speed_key,\n            by = join_by(year,day_type,hour)) |&gt; \n  select(TID,d_mean_speed)\n\nWe join the speed data to the correspondence we produced before\n\nobs_speeds_edges &lt;- TID_to_edge_id |&gt;\n  left_join(speed_tbl,by = \"TID\") |&gt; \n  summarise(obs_speed = mean(d_mean_speed),.by = edge_id)\n\nUsing the observed speed we recalculate the time_weighted.\n\nbog_contr_adjusted &lt;- bog_contracted\ndodgr::clear_dodgr_cache()\nbog_contr_adjusted$obs_speed &lt;- tibble(edge_id = bog_contr_adjusted$edge_id) |&gt; \n  left_join(obs_speeds_edges,by = \"edge_id\") |&gt; \n  pull(obs_speed)\ndodgr::clear_dodgr_cache()\nbog_contr_adjusted$time_weighted[!is.na(bog_contr_adjusted$obs_speed)] &lt;- (3.6*bog_contr_adjusted$d_weighted[!is.na(bog_contr_adjusted$obs_speed)])/bog_contr_adjusted$obs_speed[!is.na(bog_contr_adjusted$obs_speed)]\n\nWe calculate the centrality for the congested graph.\n\ncongested_centrality &lt;- bog_contr_adjusted |&gt;\n      dodgr_centrality(column = \"time_weighted\")\n\n\n\nWe consolidate the values of free-flow network and congested network into a single dataset\n\ncent_all &lt;- tibble(edge_id = bog_centrality$edge_id,\n                   cent_bl = bog_centrality$centrality) |&gt; \n  left_join(\n    tibble(edge_id = congested_centrality$edge_id,\n           cent_cong = congested_centrality$centrality),\n    by = \"edge_id\"\n  ) |&gt; \n  mutate(\n    diff = cent_cong - cent_bl,\n    reldiff = diff/(0.5*(cent_bl+cent_cong))\n  )\n\n\n\n\nThe following code produce some quick visualisation of the differences\n\nsf_net &lt;- graph_bogota |&gt; \n  dodgr_to_sf() |&gt; \n  left_join(cent_all,by = \"edge_id\")\n\n\nggplot(cent_all, aes(diff))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(cent_all, aes(reldiff))+\n  geom_histogram()+\n  scale_x_continuous(limits = c(-2,2))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 472 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\nsf_net |&gt; \n  mutate(reldiff = if_else(abs(reldiff)&gt;2,\n                           NA_real_,\n                           reldiff)) |&gt; \n  ggplot(aes(col = reldiff))+\n  geom_sf()+\n  theme_void()+\n  scale_color_gradient2(midpoint = 0,\n                        low = \"red3\",\n                        high = \"green4\",\n                        mid = \"yellow\")\n\n\n\n\n\n\n\n\n\n\n\n\nThe distance from the major network might be related to the reports of traffic offences. For this purpose, we need the following code to obtain the average distance of each minor link to the major network.\nIdentifying the junctions and classifying them based on the road hierarchy\n\nlow_hierarchy &lt;- c(\"residential\",\"unclassified\")\n\njunction_class_to &lt;- sf_net |&gt; \n  st_drop_geometry() |&gt; \n  mutate(road_type = if_else(roadclass %in% low_hierarchy,\n                             \"minor\",\n                             \"major\")) |&gt;\n  summarise(count = n(),.by = c(to_id,road_type)) |&gt;\n  pivot_wider(names_from = road_type,values_from = count)|&gt; \n  rename(id = to_id)\n\njunction_class_from &lt;- sf_net |&gt; \n  st_drop_geometry() |&gt; \n  mutate(road_type = if_else(roadclass %in% low_hierarchy,\n                             \"minor\",\n                             \"major\")) |&gt; \n  summarise(count = n(),.by = c(from_id,road_type)) |&gt;\n  pivot_wider(names_from = road_type,values_from = count) |&gt;\n  rename(id = from_id)\n\njunctions_classed &lt;- junction_class_to |&gt; \n  full_join(junction_class_from,by = \"id\",suffix = c(\".to\",\".from\")) |&gt; \n  mutate(jct_type = case_when(is.na(minor.to)&is.na(minor.from)~\"major\",\n                              is.na(major.to)&is.na(major.from)~\"minor\",\n                              (!is.na(minor.to)&!is.na(major.from))|\n                                (!is.na(minor.from)&!is.na(major.to))~\"minmaj\")) |&gt; \n  select(-starts_with(\"m\"))\n\nCalculating the network distance for all nodes in the minor network to the major network\n\nminmaj_ids &lt;- junctions_classed |&gt; filter(jct_type == \"minmaj\") |&gt; pull(id)\nminor_from_ids &lt;- junctions_classed |&gt; filter(jct_type == \"minor\") |&gt; pull(id)\n\ndist_matrix &lt;- dodgr_dists(bog_contracted,\n                           from = minor_from_ids,\n                           to = minmaj_ids,\n                           shortest = T)\n\n\nlength(colSums(dist_matrix)[is.na(colSums(dist_matrix,na.rm = T))])\n\n[1] 0\n\n\n\nfastest_all &lt;- tibble(\n  id.jct = minor_from_ids,\n  dist.jct =\n    apply(dist_matrix, 1,\\(x) min(x,na.rm = TRUE)\n      )\n  )\n\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\nWarning in min(x, na.rm = TRUE): no non-missing arguments to min; returning Inf\n\n\n\nsf_net_jct &lt;- sf_net |&gt; left_join(fastest_all,\n                                  by = c(\"from_id\"=\"id.jct\"),\n                                  relationship = \"many-to-one\") |&gt; \n  mutate(dist.jct = case_when(is.na(dist.jct)&roadclass %in% low_hierarchy ~ 0,\n                              is.infinite(dist.jct)~NA,\n                              T~dist.jct))"
  },
  {
    "objectID": "D2_congestion_tests.html#saving-results-for-further-analysis",
    "href": "D2_congestion_tests.html#saving-results-for-further-analysis",
    "title": "Testing changes in centrality",
    "section": "",
    "text": "st_write(sf_net_jct,\"sf_network/small_sf_network_cent_results.gpkg\",delete_dsn = T)\n\nDeleting source `sf_network/small_sf_network_cent_results.gpkg' using driver `GPKG'\nWriting layer `small_sf_network_cent_results' to data source \n  `sf_network/small_sf_network_cent_results.gpkg' using driver `GPKG'\nWriting 10970 features with 26 fields and geometry type Line String."
  },
  {
    "objectID": "D2_congestion_tests.html#tests-for-wrong-direction-speed",
    "href": "D2_congestion_tests.html#tests-for-wrong-direction-speed",
    "title": "Testing changes in centrality",
    "section": "",
    "text": "We assumed an initial speed of 10 km/h for the links that represent the wrong direction. But that choice is arbitrary. The following section will produce the results for multiple speeds, to compare the changes in centrality based on the assumed fre-flow speed of wrong-way links. First, we will test the changes on the free-flow network\n\ntest_centralities &lt;- do.call(bind_cols,\n                             lapply(seq(0, 30, 1), \\(v) {\n                               bog_ff_test &lt;- bog_contracted\n                               \n                               dodgr::clear_dodgr_cache()\n                               bog_ff_test$time_weighted[bog_ff_test$highway == \"road_10\"] &lt;- (3.6 * bog_ff_test$d_weighted[bog_ff_test$highway == \"road_10\"]) / v\n                               \n                               \n                               test_centrality &lt;- bog_ff_test |&gt;\n                                 dodgr_centrality(column = \"time_weighted\")\n                               \n                               \n                               t &lt;- tibble(cent = test_centrality$centrality)\n                               names(t) &lt;- paste0(\"cent_\", v)\n                               return(t)\n                               \n                             }))\n\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\n\n\nVisualising the impact of the assigned speed on centrality distribution across the network (top)\n\ntest_centralities |&gt;\n  pivot_longer(cols = any_of(names(test_centralities)),\n               names_prefix = \"cent_\") |&gt;\n  mutate(name = as.integer(name)) |&gt; \n  ggplot(aes(x = factor(name),y = value+1))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution\",\n       x = \"WWD links assigned speed\")\n\n\n\n\n\n\n\ntibble(highway = bog_contracted[,c(\"highway\")]) |&gt; \n  bind_cols(test_centralities) |&gt; \n  filter(highway == \"road_10\") |&gt; \n  pivot_longer(-highway,names_prefix = \"cent_\") |&gt;\n  mutate(name = as.integer(name)) |&gt; \n  ggplot(aes(x = factor(name),y = value+1))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution (only WW-links)\",\n       x = \"WWD links assigned speed\")\n\n\n\n\n\n\n\n\n\n\n\n\ntest_centralities_cong &lt;- do.call(bind_cols,\n                             lapply(seq(0, 30, 1), \\(v) {\n                               bog_ff_test &lt;- bog_contr_adjusted \n                               \n                               dodgr::clear_dodgr_cache()\n                               bog_ff_test$time_weighted[bog_ff_test$highway == \"road_10\"] &lt;- (3.6 * bog_ff_test$d_weighted[bog_ff_test$highway == \"road_10\"]) / v\n                               \n                               \n                               test_centrality &lt;- bog_ff_test |&gt;\n                                 dodgr_centrality(column = \"time_weighted\")\n                               \n                               \n                               t &lt;- tibble(cent = test_centrality$centrality)\n                               names(t) &lt;- paste0(\"cent_\", v)\n                               return(t)\n                               \n                             }))\n\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\nWarning in file.remove(lf): cannot remove file\n'C:/Users/ts18jpf/AppData/Local/Temp/Rtmp2fWTC2/dodgr_graph_cca416ed5a88b57f886e0f7c81bb40c4.Rds',\nreason 'Permission denied'\n\n\nVisualising the impact of the assigned speed on centrality distribution across the network (top)\n\ntest_centralities_cong |&gt;\n  pivot_longer(cols = any_of(names(test_centralities_cong)),\n               names_prefix = \"cent_\") |&gt;\n  mutate(name = as.integer(name)) |&gt; \n  ggplot(aes(x = factor(name),y = value+1))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution\",\n       x = \"WWD links assigned speed\")\n\n\n\n\n\n\n\ntibble(highway = bog_contr_adjusted[,c(\"highway\")]) |&gt; \n  bind_cols(test_centralities_cong) |&gt; \n  filter(highway == \"road_10\") |&gt; \n  pivot_longer(-highway,names_prefix = \"cent_\") |&gt;\n  mutate(name = as.integer(name)) |&gt; \n  ggplot(aes(x = factor(name),y = value+1))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution (only WW-links)\",\n       x = \"WWD links assigned speed\")\n\n\n\n\n\n\n\n\n\n\n\n\nwwlinks &lt;- bind_cols(\n  tibble(highway = bog_contr_adjusted[, c(\"highway\")]) |&gt;\n    bind_cols(test_centralities_cong) |&gt;\n    filter(highway == \"road_10\") |&gt;\n    pivot_longer(-highway, names_prefix = \"cent_\",\n                 values_to = \"ff_cent\"),\n  tibble(highway = bog_contracted[, c(\"highway\")]) |&gt;\n    bind_cols(test_centralities) |&gt;\n    filter(highway == \"road_10\") |&gt;\n    pivot_longer(-highway, names_prefix = \"cent_\",\n                 values_to = \"cong_cent\")\n)\n\nNew names:\n• `highway` -&gt; `highway...1`\n• `name` -&gt; `name...2`\n• `highway` -&gt; `highway...4`\n• `name` -&gt; `name...5`\n\n\nA simple linear model\n\nm1 &lt;- lm(ff_cent~cong_cent+0, data = wwlinks)\nsummary(m1)\n\n\nCall:\nlm(formula = ff_cent ~ cong_cent + 0, data = wwlinks)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-545233       0       1    1308  984026 \n\nCoefficients:\n          Estimate Std. Error t value Pr(&gt;|t|)    \ncong_cent 0.931455   0.007189   129.6   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38040 on 50033 degrees of freedom\nMultiple R-squared:  0.2512,    Adjusted R-squared:  0.2512 \nF-statistic: 1.679e+04 on 1 and 50033 DF,  p-value: &lt; 2.2e-16\n\n\n\nwwlinks |&gt;\n  mutate(name = as.integer(name...2),\n         sign = (cong_cent-ff_cent)/abs(cong_cent-ff_cent)) |&gt;\n  ggplot(aes(x = factor(name),y = abs(cong_cent-ff_cent),fill = factor(sign)))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution (only WW-links)\",\n       x = \"WWD links assigned speed\")\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\n\n\nWarning: Removed 18483 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nwwlinks |&gt;\n  mutate(name = as.integer(name...2),\n         sign = (cong_cent-ff_cent)/abs(cong_cent-ff_cent)) |&gt;\n  ggplot(aes(x = factor(name),y = abs(cong_cent-ff_cent)/(0.5*(cong_cent+ff_cent)),fill = factor(sign)))+\n  geom_boxplot(outlier.shape = NA)+\n  scale_y_log10()+\n  labs(title = \"Centrality distribution (only WW-links)\",\n       x = \"WWD links assigned speed\")\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\n\n\nWarning: Removed 18483 rows containing non-finite outside the scale range\n(`stat_boxplot()`)."
  },
  {
    "objectID": "D1_graph_centrality_tests.html",
    "href": "D1_graph_centrality_tests.html",
    "title": "Graph Centrality Tests",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"zonebuilder\",\n    \"tmap\"\n    # \"dodgr\" # Using the developer version of dodgr\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n         sf   tidyverse zonebuilder        tmap \n       TRUE        TRUE        TRUE        TRUE \n\nrequire(dodgr)\n\n\n\n\nsf_bogota_2019_full &lt;- st_read(file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),\n                          layer = \"network_2019\")\n\nReading layer `network_2019' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 54531 features and 15 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.441 ymin: 4.236862 xmax: -73.72583 ymax: 5.042826\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nWe will use a small subset of the network for this test to speed up the process.\n\nbog_zone &lt;- zonebuilder::zb_zone(\"Bogota\",n_circles = 2) |&gt;\n  st_transform(st_crs(sf_bogota_2019_full))\n# zb_view(bog_zone)\n\nThe following the code will clip the network; also, since we will be using wrong-way-driving, we have to allow both directions inone-way links to capture the changes of centrality.\n\nsf_bogota_2019 &lt;- sf_bogota_2019_full[bog_zone,] |&gt; \n  mutate(oneway = if_else(highway %in% c(\"residential\"),\"no\",oneway))\n\n\ngraph_bogota &lt;- weight_streetnet(sf_bogota_2019,\n                                 left_side = F,\n                                 wt_profile_file = \"bogota_wp.json\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols = c(\"oneway\",\"lanes\",\"surface\",\"maxspeed\"),\n                                 turn_penalty = F)\n\nbog_contracted &lt;- graph_bogota |&gt; \n  dodgr_contract_graph()\n\n\n\n\nIn order to include the actual speed along each corridor, I will specify 60 different classes to be applied to each road link. By default, speeds are assigned by road link by road type, e.g. any trunk road in Bogotá has a 60 km/h speed.\n\n# custom_wp &lt;- dodgr::weighting_profiles$weighting_profiles |&gt; filter(name==\"motorcar\")\ncustom_penalties &lt;- dodgr::weighting_profiles$penalties |&gt; filter(name==\"motorcar\")\ncustom_surfaces &lt;- dodgr::weighting_profiles$surface_speeds |&gt; filter(name==\"motorcar\")\n\ncustom_wp &lt;- data.frame(name = \"motorcar\",\n                        way = paste0(\"road_\",1:60),\n                        value = 1,\n                        max_speed = as.numeric(1:60))\n\ncustom_wp_list &lt;- list(weighting_profiles = custom_wp,\n                       surface_speeds = custom_surfaces,\n                       pealties = custom_penalties)\n\nwpj &lt;- jsonlite::toJSON (custom_wp_list, pretty = TRUE)\nwrite_lines(wpj,file = \"custom_wp_speeds.json\")\n\nAssigning a speed category based on the speed limit (baseline scenario)\n\nsf_bogota_2019_cwp &lt;- sf_bogota_2019 |&gt;\n  mutate(way_speed = case_when(highway %in%\n                                 c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~\"road_60\",\n                                               TRUE ~ \"road_30\")) |&gt; \n  select(-highway)\n\nThe following code builds the graph using the new column instead of highway.\n\ngraph_bogota_custom &lt;- weight_streetnet(sf_bogota_2019_cwp,\n                                 left_side = F,\n                                 wt_profile_file = \"custom_wp_speeds.json\",\n                                 type_col = \"way_speed\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols = c(\"way_speed\",\"oneway\",\"lanes\",\"surface\",\"maxspeed\"),\n                                 turn_penalty = F)\n\n\n\nWe calculate the centralities with both weighting profiles\n\ngraph_baseline_centrality &lt;- graph_bogota |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality()\n\ngraph_cwp_centrality &lt;- graph_bogota_custom |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality()\n\nTo validate that the results are identical, we can run the following code\n\nidentical(graph_baseline_centrality$centrality,graph_cwp_centrality$centrality)\n\n[1] TRUE\n\n\n\n\n\n\nThere are four core alternatives for calculating the centrality using dodgr.\n\nbog_contracted[,\n    c(\"d_weighted\", \"d\", \"time_weighted\", \"time\")] |&gt;\n  pairs()\n\n\n\n\n\n\n\n\nAn initial check on the four alternatives reveal some inconsistencies in the time_weighted column.\nThere are 32 links in the contracted graph with differences in the weighted distance and the distance. The location of these edges will be inspected after calculating the centrality in Section 1.3.3.\nWhen multiple paths are available between two nodes in the contracted version of the graph, dodgr takes only the shortest weighted distance, which creates the difference. However, the resulting weighted time is not corrected and in some cases a 0 is returned.\nGiven this, we will recalculate the weighted time based on the weighted distance.\n\nbog_contracted$time_weighted[bog_contracted$time_weighted==0] &lt;- (3.6*bog_contracted$d_weighted[bog_contracted$time_weighted==0])/case_when(\n      bog_contracted$highway[bog_contracted$time_weighted==0] %in% c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~60,\n      T~30)\n\n\n\n\ncent_all &lt;- lapply(c(\"d_weighted\", \"d\", \"time_weighted\", \"time\"), \\(x) {\n  \n    df &lt;- bog_contracted |&gt;\n      dodgr_centrality(column = x)\n  \n  tibble(edge_id = df$edge_id, cent = df$centrality) |&gt;\n    rename_with(.cols = \"cent\", .fn = \\(.y) {\n      paste(.y, x, sep = \"_\")\n    })\n  }) |&gt;\n  plyr::join_all(by = \"edge_id\",type = \"full\")\n\n\n\n\n\nigraph_bog &lt;- bog_contracted |&gt; \n  dodgr_to_igraph()\n\nLoading required namespace: igraph\n\n\n\ncent_all_ig &lt;- cent_all |&gt; \n  left_join(\n    tibble(edge_id = bog_contracted$edge_id,\n       cent_ig_d = igraph::edge_betweenness(graph = igraph_bog,\n                                            weights = bog_contracted$d),\n       cent_ig_d_weighted = igraph::edge_betweenness(graph = igraph_bog,\n                                                     weights = bog_contracted$d_weighted),\n       cent_ig_time = igraph::edge_betweenness(graph = igraph_bog,weights = bog_contracted$time),\n       cent_ig_time_weighted = igraph::edge_betweenness(graph = igraph_bog,\n                                                        weights = bog_contracted$time_weighted)\n       ),\n    by = \"edge_id\")\n\n\nsummary(cent_all_ig[,2:9])\n\n cent_d_weighted       cent_d        cent_time_weighted   cent_time      \n Min.   :      0   Min.   :      0   Min.   :      0    Min.   :      0  \n 1st Qu.:   4331   1st Qu.:   4330   1st Qu.:   4329    1st Qu.:   4329  \n Median :  16607   Median :  16483   Median :  14694    Median :  14569  \n Mean   :  79033   Mean   :  78951   Mean   :  80780    Mean   :  80660  \n 3rd Qu.:  71441   3rd Qu.:  70966   3rd Qu.:  53128    3rd Qu.:  52827  \n Max.   :1405281   Max.   :1408773   Max.   :2075299    Max.   :2069854  \n   cent_ig_d       cent_ig_d_weighted  cent_ig_time     cent_ig_time_weighted\n Min.   :      0   Min.   :      0    Min.   :      0   Min.   :      0      \n 1st Qu.:   4330   1st Qu.:   4331    1st Qu.:   4329   1st Qu.:   4329      \n Median :  16483   Median :  16607    Median :  14569   Median :  14694      \n Mean   :  78951   Mean   :  79033    Mean   :  80660   Mean   :  80780      \n 3rd Qu.:  70966   3rd Qu.:  71441    3rd Qu.:  52827   3rd Qu.:  53128      \n Max.   :1408773   Max.   :1405281    Max.   :2069854   Max.   :2075299      \n\n\nCheck if igraph results are identical to the ones obtained with dodgr\n\nwith(cent_all_ig,identical(cent_ig_d_weighted,cent_d_weighted))\n\n[1] TRUE\n\nwith(cent_all_ig,identical(cent_ig_time_weighted,cent_time_weighted))\n\n[1] TRUE\n\n\n\npairs(cent_all_ig[,2:9])\n\n\n\n\n\n\n\n\nJoining the results to the sf object\n\nsf_net &lt;- graph_bogota |&gt;\n  dodgr_to_sf() |&gt; \n  left_join(cent_all,by = \"edge_id\")\n\n\n\n\n\nsf_net |&gt;  \n  select(cent_d_weighted:cent_time) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  ggplot()+\n  geom_sf(aes(col = log(cent),linewidth = cent+1))+\n  facet_wrap(type~.)+\n  scale_color_viridis_c(\n    # direction = -1\n    )+\n  scale_linewidth_continuous(range = c(0.05,0.5),\n                             transform = scales::transform_boxcox(p = 2))+\n  theme_void()+\n  guides(linewidth = \"none\",)\n\n\n\n\n\n\n\n\nVisualising differences\n\nsf_net |&gt; \n  transmute(across(cent_d_weighted:cent_time,\n                   \\(x) (x - cent_d)/cent_d)) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  ggplot(aes(cent))+\n  geom_histogram()+\n  facet_wrap(type~.)+\n  scale_x_continuous(limits = c(-1,1))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2582 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nInspecting significant changes\n\nsf_net |&gt; \n  transmute(across(cent_d_weighted:cent_time,\n                   \\(x) (x - cent_d)/cent_d)) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  mutate(cent = case_when(abs(cent)&lt;0.1~0,\n                          cent &gt; 0.6 ~ 1,\n                          -cent &gt; 0.6 ~ -1,\n                          is.na(cent)~NA)) |&gt; \n  ggplot()+\n  geom_sf(aes(col = cent))+\n  facet_wrap(type~.)+\n  scale_color_distiller(palette = \"Spectral\", direction = 1)+\n  # scale_linewidth_continuous(range = c(0.05,0.5),\n  #                            transform = scales::transform_boxcox(p = 2))+\n  theme_void()\n\n\n\n\n\n\n\n\nIdentifying the links with differences &gt; 0 in d and weighted d\n\nsf_net |&gt; \n  mutate(diff_check = (d-d_weighted)==0) |&gt; \n  ggplot(aes(col = diff_check))+\n  geom_sf()+\n  theme_void()\n\n\n\n\n\n\n\n\nSame for time\n\nsf_net |&gt; \n  mutate(diff_check = (time-time_weighted)==0) |&gt; \n  ggplot(aes(col = diff_check))+\n  geom_sf()+\n  theme_void()\n\n\n\n\n\n\n\n\nA course assumption is that people decide the route they will use based on the ETA, also differences in speed limits can only captured if time is used. So weighted time will be used.\n\n\n\n\nlibrary(sfnetworks)\n\n\nsf_net$time_weighted[sf_net$time_weighted==0] &lt;- (3.6*sf_net$d_weighted[sf_net$time_weighted==0])/case_when(\n      sf_net$highway[sf_net$time_weighted==0] %in% c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~60,\n      T~30)\n\nbog_sfnet &lt;- sf_net |&gt; \n  as_sfnetwork(directed = TRUE)\n\n\nbog_sfnet &lt;- bog_sfnet |&gt;\n  activate(\"edges\") |&gt; \n  mutate(cent_sfn_time_weighted = tidygraph::centrality_edge_betweenness(\n    weights = time_weighted,\n    directed = T))\n\n\nbog_sfnet |&gt; \n  st_as_sf(\"edges\") |&gt; \nggplot()+\n  geom_sf(aes(col = cent_time_weighted))+\n  theme_void()\n\n\n\n\n\n\n\n\n\nbog_sfnet |&gt; \n  activate(\"edges\") |&gt;\n  data.frame() |&gt; \n  select(cent_time_weighted,cent_sfn_time_weighted) |&gt; \n  pairs()\n\n\n\n\n\n\n\n\n\nbog_sfnet |&gt; \n  activate(\"edges\") |&gt;\n  data.frame() |&gt; \n  with(identical(cent_time_weighted,cent_sfn_time_weighted))\n\n[1] TRUE\n\n\n\np1 = st_geometry(bog_sfnet, \"nodes\")[2401]\nst_crs(p1) = st_crs(bog_sfnet)\np2 = st_geometry(bog_sfnet, \"nodes\")[1407]\np3 = st_geometry(bog_sfnet, \"nodes\")[1509]\np4 = st_geometry(bog_sfnet, \"nodes\")[1840]\nst_crs(p3) = st_crs(bog_sfnet)\n\npaths = st_network_paths(bog_sfnet, from = p1, to = c(p2,p3,p4), weights = \"time_weighted\")\n\n\nplot_path = function(node_path) {\n  bog_sfnet %&gt;%\n    activate(\"nodes\") %&gt;%\n    slice(node_path) %&gt;%\n    plot(cex = 1.5, lwd = 1.5, add = TRUE)\n}\n\ncolors = sf.colors(4, categorical = TRUE)\n\nplot(bog_sfnet, col = \"grey\")\npaths %&gt;%\n  pull(node_paths) %&gt;%\n  walk(plot_path)\nplot(c(p1, p2, p3,p4), col = colors, pch = 8, cex = 2, lwd = 2, add = TRUE)"
  },
  {
    "objectID": "D1_graph_centrality_tests.html#loading-network",
    "href": "D1_graph_centrality_tests.html#loading-network",
    "title": "Graph Centrality Tests",
    "section": "",
    "text": "sf_bogota_2019_full &lt;- st_read(file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),\n                          layer = \"network_2019\")\n\nReading layer `network_2019' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 54531 features and 15 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.441 ymin: 4.236862 xmax: -73.72583 ymax: 5.042826\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nWe will use a small subset of the network for this test to speed up the process.\n\nbog_zone &lt;- zonebuilder::zb_zone(\"Bogota\",n_circles = 2) |&gt;\n  st_transform(st_crs(sf_bogota_2019_full))\n# zb_view(bog_zone)\n\nThe following the code will clip the network; also, since we will be using wrong-way-driving, we have to allow both directions inone-way links to capture the changes of centrality.\n\nsf_bogota_2019 &lt;- sf_bogota_2019_full[bog_zone,] |&gt; \n  mutate(oneway = if_else(highway %in% c(\"residential\"),\"no\",oneway))\n\n\ngraph_bogota &lt;- weight_streetnet(sf_bogota_2019,\n                                 left_side = F,\n                                 wt_profile_file = \"bogota_wp.json\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols = c(\"oneway\",\"lanes\",\"surface\",\"maxspeed\"),\n                                 turn_penalty = F)\n\nbog_contracted &lt;- graph_bogota |&gt; \n  dodgr_contract_graph()"
  },
  {
    "objectID": "D1_graph_centrality_tests.html#assignment-of-the-weighting-profile",
    "href": "D1_graph_centrality_tests.html#assignment-of-the-weighting-profile",
    "title": "Graph Centrality Tests",
    "section": "",
    "text": "In order to include the actual speed along each corridor, I will specify 60 different classes to be applied to each road link. By default, speeds are assigned by road link by road type, e.g. any trunk road in Bogotá has a 60 km/h speed.\n\n# custom_wp &lt;- dodgr::weighting_profiles$weighting_profiles |&gt; filter(name==\"motorcar\")\ncustom_penalties &lt;- dodgr::weighting_profiles$penalties |&gt; filter(name==\"motorcar\")\ncustom_surfaces &lt;- dodgr::weighting_profiles$surface_speeds |&gt; filter(name==\"motorcar\")\n\ncustom_wp &lt;- data.frame(name = \"motorcar\",\n                        way = paste0(\"road_\",1:60),\n                        value = 1,\n                        max_speed = as.numeric(1:60))\n\ncustom_wp_list &lt;- list(weighting_profiles = custom_wp,\n                       surface_speeds = custom_surfaces,\n                       pealties = custom_penalties)\n\nwpj &lt;- jsonlite::toJSON (custom_wp_list, pretty = TRUE)\nwrite_lines(wpj,file = \"custom_wp_speeds.json\")\n\nAssigning a speed category based on the speed limit (baseline scenario)\n\nsf_bogota_2019_cwp &lt;- sf_bogota_2019 |&gt;\n  mutate(way_speed = case_when(highway %in%\n                                 c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~\"road_60\",\n                                               TRUE ~ \"road_30\")) |&gt; \n  select(-highway)\n\nThe following code builds the graph using the new column instead of highway.\n\ngraph_bogota_custom &lt;- weight_streetnet(sf_bogota_2019_cwp,\n                                 left_side = F,\n                                 wt_profile_file = \"custom_wp_speeds.json\",\n                                 type_col = \"way_speed\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols = c(\"way_speed\",\"oneway\",\"lanes\",\"surface\",\"maxspeed\"),\n                                 turn_penalty = F)\n\n\n\nWe calculate the centralities with both weighting profiles\n\ngraph_baseline_centrality &lt;- graph_bogota |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality()\n\ngraph_cwp_centrality &lt;- graph_bogota_custom |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality()\n\nTo validate that the results are identical, we can run the following code\n\nidentical(graph_baseline_centrality$centrality,graph_cwp_centrality$centrality)\n\n[1] TRUE"
  },
  {
    "objectID": "D1_graph_centrality_tests.html#centrality-calculations",
    "href": "D1_graph_centrality_tests.html#centrality-calculations",
    "title": "Graph Centrality Tests",
    "section": "",
    "text": "There are four core alternatives for calculating the centrality using dodgr.\n\nbog_contracted[,\n    c(\"d_weighted\", \"d\", \"time_weighted\", \"time\")] |&gt;\n  pairs()\n\n\n\n\n\n\n\n\nAn initial check on the four alternatives reveal some inconsistencies in the time_weighted column.\nThere are 32 links in the contracted graph with differences in the weighted distance and the distance. The location of these edges will be inspected after calculating the centrality in Section 1.3.3.\nWhen multiple paths are available between two nodes in the contracted version of the graph, dodgr takes only the shortest weighted distance, which creates the difference. However, the resulting weighted time is not corrected and in some cases a 0 is returned.\nGiven this, we will recalculate the weighted time based on the weighted distance.\n\nbog_contracted$time_weighted[bog_contracted$time_weighted==0] &lt;- (3.6*bog_contracted$d_weighted[bog_contracted$time_weighted==0])/case_when(\n      bog_contracted$highway[bog_contracted$time_weighted==0] %in% c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~60,\n      T~30)\n\n\n\n\ncent_all &lt;- lapply(c(\"d_weighted\", \"d\", \"time_weighted\", \"time\"), \\(x) {\n  \n    df &lt;- bog_contracted |&gt;\n      dodgr_centrality(column = x)\n  \n  tibble(edge_id = df$edge_id, cent = df$centrality) |&gt;\n    rename_with(.cols = \"cent\", .fn = \\(.y) {\n      paste(.y, x, sep = \"_\")\n    })\n  }) |&gt;\n  plyr::join_all(by = \"edge_id\",type = \"full\")\n\n\n\n\n\nigraph_bog &lt;- bog_contracted |&gt; \n  dodgr_to_igraph()\n\nLoading required namespace: igraph\n\n\n\ncent_all_ig &lt;- cent_all |&gt; \n  left_join(\n    tibble(edge_id = bog_contracted$edge_id,\n       cent_ig_d = igraph::edge_betweenness(graph = igraph_bog,\n                                            weights = bog_contracted$d),\n       cent_ig_d_weighted = igraph::edge_betweenness(graph = igraph_bog,\n                                                     weights = bog_contracted$d_weighted),\n       cent_ig_time = igraph::edge_betweenness(graph = igraph_bog,weights = bog_contracted$time),\n       cent_ig_time_weighted = igraph::edge_betweenness(graph = igraph_bog,\n                                                        weights = bog_contracted$time_weighted)\n       ),\n    by = \"edge_id\")\n\n\nsummary(cent_all_ig[,2:9])\n\n cent_d_weighted       cent_d        cent_time_weighted   cent_time      \n Min.   :      0   Min.   :      0   Min.   :      0    Min.   :      0  \n 1st Qu.:   4331   1st Qu.:   4330   1st Qu.:   4329    1st Qu.:   4329  \n Median :  16607   Median :  16483   Median :  14694    Median :  14569  \n Mean   :  79033   Mean   :  78951   Mean   :  80780    Mean   :  80660  \n 3rd Qu.:  71441   3rd Qu.:  70966   3rd Qu.:  53128    3rd Qu.:  52827  \n Max.   :1405281   Max.   :1408773   Max.   :2075299    Max.   :2069854  \n   cent_ig_d       cent_ig_d_weighted  cent_ig_time     cent_ig_time_weighted\n Min.   :      0   Min.   :      0    Min.   :      0   Min.   :      0      \n 1st Qu.:   4330   1st Qu.:   4331    1st Qu.:   4329   1st Qu.:   4329      \n Median :  16483   Median :  16607    Median :  14569   Median :  14694      \n Mean   :  78951   Mean   :  79033    Mean   :  80660   Mean   :  80780      \n 3rd Qu.:  70966   3rd Qu.:  71441    3rd Qu.:  52827   3rd Qu.:  53128      \n Max.   :1408773   Max.   :1405281    Max.   :2069854   Max.   :2075299      \n\n\nCheck if igraph results are identical to the ones obtained with dodgr\n\nwith(cent_all_ig,identical(cent_ig_d_weighted,cent_d_weighted))\n\n[1] TRUE\n\nwith(cent_all_ig,identical(cent_ig_time_weighted,cent_time_weighted))\n\n[1] TRUE\n\n\n\npairs(cent_all_ig[,2:9])\n\n\n\n\n\n\n\n\nJoining the results to the sf object\n\nsf_net &lt;- graph_bogota |&gt;\n  dodgr_to_sf() |&gt; \n  left_join(cent_all,by = \"edge_id\")\n\n\n\n\n\nsf_net |&gt;  \n  select(cent_d_weighted:cent_time) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  ggplot()+\n  geom_sf(aes(col = log(cent),linewidth = cent+1))+\n  facet_wrap(type~.)+\n  scale_color_viridis_c(\n    # direction = -1\n    )+\n  scale_linewidth_continuous(range = c(0.05,0.5),\n                             transform = scales::transform_boxcox(p = 2))+\n  theme_void()+\n  guides(linewidth = \"none\",)\n\n\n\n\n\n\n\n\nVisualising differences\n\nsf_net |&gt; \n  transmute(across(cent_d_weighted:cent_time,\n                   \\(x) (x - cent_d)/cent_d)) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  ggplot(aes(cent))+\n  geom_histogram()+\n  facet_wrap(type~.)+\n  scale_x_continuous(limits = c(-1,1))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2582 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nInspecting significant changes\n\nsf_net |&gt; \n  transmute(across(cent_d_weighted:cent_time,\n                   \\(x) (x - cent_d)/cent_d)) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  mutate(cent = case_when(abs(cent)&lt;0.1~0,\n                          cent &gt; 0.6 ~ 1,\n                          -cent &gt; 0.6 ~ -1,\n                          is.na(cent)~NA)) |&gt; \n  ggplot()+\n  geom_sf(aes(col = cent))+\n  facet_wrap(type~.)+\n  scale_color_distiller(palette = \"Spectral\", direction = 1)+\n  # scale_linewidth_continuous(range = c(0.05,0.5),\n  #                            transform = scales::transform_boxcox(p = 2))+\n  theme_void()\n\n\n\n\n\n\n\n\nIdentifying the links with differences &gt; 0 in d and weighted d\n\nsf_net |&gt; \n  mutate(diff_check = (d-d_weighted)==0) |&gt; \n  ggplot(aes(col = diff_check))+\n  geom_sf()+\n  theme_void()\n\n\n\n\n\n\n\n\nSame for time\n\nsf_net |&gt; \n  mutate(diff_check = (time-time_weighted)==0) |&gt; \n  ggplot(aes(col = diff_check))+\n  geom_sf()+\n  theme_void()\n\n\n\n\n\n\n\n\nA course assumption is that people decide the route they will use based on the ETA, also differences in speed limits can only captured if time is used. So weighted time will be used.\n\n\n\n\nlibrary(sfnetworks)\n\n\nsf_net$time_weighted[sf_net$time_weighted==0] &lt;- (3.6*sf_net$d_weighted[sf_net$time_weighted==0])/case_when(\n      sf_net$highway[sf_net$time_weighted==0] %in% c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~60,\n      T~30)\n\nbog_sfnet &lt;- sf_net |&gt; \n  as_sfnetwork(directed = TRUE)\n\n\nbog_sfnet &lt;- bog_sfnet |&gt;\n  activate(\"edges\") |&gt; \n  mutate(cent_sfn_time_weighted = tidygraph::centrality_edge_betweenness(\n    weights = time_weighted,\n    directed = T))\n\n\nbog_sfnet |&gt; \n  st_as_sf(\"edges\") |&gt; \nggplot()+\n  geom_sf(aes(col = cent_time_weighted))+\n  theme_void()\n\n\n\n\n\n\n\n\n\nbog_sfnet |&gt; \n  activate(\"edges\") |&gt;\n  data.frame() |&gt; \n  select(cent_time_weighted,cent_sfn_time_weighted) |&gt; \n  pairs()\n\n\n\n\n\n\n\n\n\nbog_sfnet |&gt; \n  activate(\"edges\") |&gt;\n  data.frame() |&gt; \n  with(identical(cent_time_weighted,cent_sfn_time_weighted))\n\n[1] TRUE\n\n\n\np1 = st_geometry(bog_sfnet, \"nodes\")[2401]\nst_crs(p1) = st_crs(bog_sfnet)\np2 = st_geometry(bog_sfnet, \"nodes\")[1407]\np3 = st_geometry(bog_sfnet, \"nodes\")[1509]\np4 = st_geometry(bog_sfnet, \"nodes\")[1840]\nst_crs(p3) = st_crs(bog_sfnet)\n\npaths = st_network_paths(bog_sfnet, from = p1, to = c(p2,p3,p4), weights = \"time_weighted\")\n\n\nplot_path = function(node_path) {\n  bog_sfnet %&gt;%\n    activate(\"nodes\") %&gt;%\n    slice(node_path) %&gt;%\n    plot(cex = 1.5, lwd = 1.5, add = TRUE)\n}\n\ncolors = sf.colors(4, categorical = TRUE)\n\nplot(bog_sfnet, col = \"grey\")\npaths %&gt;%\n  pull(node_paths) %&gt;%\n  walk(plot_path)\nplot(c(p1, p2, p3,p4), col = colors, pch = 8, cex = 2, lwd = 2, add = TRUE)"
  },
  {
    "objectID": "D3_WWD_joining.html",
    "href": "D3_WWD_joining.html",
    "title": "Joining the WWD reports",
    "section": "",
    "text": "Joining the WWD reports\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"zonebuilder\",\n    \"tmap\"\n    # \"dodgr\" # Using the developer version of dodgr\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n         sf   tidyverse zonebuilder        tmap \n       TRUE        TRUE        TRUE        TRUE \n\n\n\nbog_zone &lt;- zonebuilder::zb_zone(\"Bogota\",\n                                 n_circles = 2) |&gt; \n  st_transform(4326)\n# zb_view(bog_zone)\n\n\nWWD reports\n\nwwd_sf &lt;- st_read(\"sf_network/wwd_clean_sf.gpkg\")\n\nReading layer `wwd_clean_sf' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\wwd_clean_sf.gpkg' \n  using driver `GPKG'\nSimple feature collection with 6915 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -74.24842 ymin: 4.475113 xmax: -74.01945 ymax: 4.819386\nGeodetic CRS:  WGS 84\n\n\n\nsf_net &lt;- st_read(\"sf_network/small_sf_network_cent_results.gpkg\")\n\nReading layer `small_sf_network_cent_results' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\small_sf_network_cent_results.gpkg' \n  using driver `GPKG'\nSimple feature collection with 10970 features and 26 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.11581 ymin: 4.622787 xmax: -74.05244 ymax: 4.688989\nGeodetic CRS:  WGS 84\n\n\n\n\nAssigning reports to the network\nWe need to assign the reports to the network. As we are interested in the residential roads, any bi-directional road is represented in the sf object as two objects. Since we do not have information to know which specific direction the reports correspond to, we will need to simplify the spatial object. Our target variable is the betweenness centrality, so we are going to keep the two centrality values for each bi-directional element.\nFirst, we will create a subset of the residential and unclassified roads\n\nsubset_net &lt;- sf_net |&gt; \n  filter(roadclass %in% c(\n    \"residential\",\n    \"unclassified\"\n    )) |&gt; \n  st_transform(3116)\n\nFrom this subset, we first find the pairs of links with the st_contains function.\n\nsimplifed_net_indexes &lt;- lapply(st_contains(subset_net,subset_net),\n            \\(x){\n              x[order(x)]\n}) |&gt; unique()\n\nEach pair is then assigned a unique id.\n\nsimp_groups &lt;- do.call(bind_rows,\n        lapply(seq_along(simplifed_net_indexes),\n               \\(i){\n                 tibble(id = simplifed_net_indexes[[i]],\n                        pair_id = i)\n               })) |&gt; \n  arrange(id)\n\n\nsubset_net$pair_id &lt;- simp_groups$pair_id\n\nUsing the pair_id we extract the minimum, maximum and average change in centrality for each pair.\n\nsummary_pairs &lt;- subset_net |&gt;\n  st_drop_geometry() |&gt;\n  # Filtering only the links that were inverted during the network creation and standard links\n  filter(!any(str_detect(way_id,\"r$\"))|str_detect(way_id,\"r$\"),.by = pair_id) |&gt; \n  summarise(across(diff:dist.jct,\n                   list(min=min, max=max, avg = mean)),\n            .by = pair_id)\n\nA simplified version of the sf object is produced extracting the first element of each pair, we discard will the columns with the centrality metrics from this object to avoid confusion\n\n# simpl_network_sf &lt;- subset_net[vapply(simplifed_net_indexes,\\(x) x[1],numeric(1)),] |&gt; select(lanes:component,pair_id)\n\nsimpl_network_sf &lt;- subset_net |&gt;\n  # Filtering only the links that were inverted during the network creation and standard links\n  filter(!any(str_detect(way_id,\"r$\"))|str_detect(way_id,\"r$\"),\n         .by = pair_id) |&gt;\n  slice_head(n = 1,by = pair_id) |&gt;\n  select(lanes:component,pair_id)\n\nWe can take a quick look at the results of the simplified network\n\nsummary_pairs |&gt; \n  ggplot() + \n  geom_histogram(aes(reldiff_min),alpha = 0.3,fill = \"dodgerblue2\",binwidth = 0.05)+\n  geom_histogram(aes(reldiff_max),alpha = 0.3,fill = \"firebrick3\",binwidth = 0.05)+\n  geom_histogram(aes(reldiff_avg),alpha = 0.3,fill = \"darkgreen\",binwidth = 0.05)+\n  # scale_x_continuous(limits = c(-2,2))+\n  theme_minimal()\n\nWarning: Removed 457 rows containing non-finite outside the scale range (`stat_bin()`).\nRemoved 457 rows containing non-finite outside the scale range (`stat_bin()`).\nRemoved 457 rows containing non-finite outside the scale range (`stat_bin()`).\n\n\n\n\n\n\n\n\n\nWe are interested in the reports on residential and unclassified streets. For this, we will create a buffer. It is uncertain how the coordinates of each report are recorded, there might be some error associated with the use of GPS devices, and also, some uncertainty in the way the officers do it.\n\nsubset_buffer &lt;- simpl_network_sf |&gt; \n  st_union()  |&gt; \n  st_buffer(20)\n\nA subset of the reports during peak hour +/- 2 hours\n\nsubset_wwd &lt;- (wwd_sf |&gt; filter(abs(hour - 18)&lt;=2) |&gt; st_transform(3116))[subset_buffer,]|&gt; \n             filter(year==2019)\n\n\ntm_shape(subset_buffer)+\n  tm_polygons(\"gray60\",alpha = 0.6)+\n  tm_shape(subset_wwd)+\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\nFinding the closest element of the network\n\nsubset_wwd$near_index &lt;- st_nearest_feature(subset_wwd,simpl_network_sf)\nsubset_wwd$pair_id &lt;- simpl_network_sf$pair_id[subset_wwd$near_index]\n\n\n\nExploring results\n\nmin_offset &lt;- 0\n\nsummary_pairs |&gt;\n  mutate(bool = pair_id %in% subset_wwd$pair_id,\n         reldiff_avg = reldiff_avg,\n         reldiff_max = reldiff_max) |&gt; \n  ggplot(aes(x = reldiff_avg,\n             y = reldiff_max,\n             alpha = bool,\n             col = bool,\n             shape = bool))+\n  geom_hline(yintercept = min_offset,linetype = \"dashed\", col = \"gray30\") +\n  geom_vline(xintercept = min_offset,linetype = \"dashed\", col = \"gray30\") +\n  geom_point()+\n  scale_colour_manual(values = c(\"gray70\",\"dodgerblue4\"))+\n  scale_alpha_manual(values = c(0.05,1))+\n  coord_fixed() +\n  theme_minimal()\n\nWarning: Removed 457 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nsimpl_network_sf |&gt;\n  st_drop_geometry() |&gt; \n  filter(pair_id %in% subset_wwd$pair_id) |&gt; \n  ggplot(aes(oneway))+\n  geom_bar()\n\n\n\n\n\n\n\n\n\nsimpl_network_sf |&gt; \n  ggplot(aes(col = oneway))+\n  geom_sf()+\n  theme_void()\n\n\n\n\n\n\n\n\n\nsimpl_network_sf |&gt;\n  filter(oneway) |&gt; \n  left_join(summary_pairs,by = \"pair_id\") |&gt; \n  mutate(wwd_bool = pair_id %in% subset_wwd$pair_id) |&gt;\n  st_drop_geometry() |&gt; \n  ggplot(aes(dist.jct_avg,col = wwd_bool))+\n  stat_ecdf(alpha = 0.7)+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nsimpl_network_sf |&gt; \n  filter(oneway) |&gt; \n  left_join(summary_pairs,by = \"pair_id\") |&gt; \n  mutate(wwd_bool = pair_id %in% subset_wwd$pair_id) |&gt;\n  st_drop_geometry() |&gt; \n  ggplot(aes(dist.jct_avg,fill = wwd_bool))+\n  geom_histogram(alpha = 0.7,col=\"white\")+\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nsimpl_network_sf |&gt; \n  filter(oneway) |&gt; \n  left_join(summary_pairs,by = \"pair_id\") |&gt; \n  mutate(wwd_bool = pair_id %in% subset_wwd$pair_id) |&gt;\n  st_drop_geometry() |&gt; \n  ggplot(aes(x = dist.jct_avg,\n             y = diff_max,\n             alpha = abs(diff_max),\n             col = wwd_bool))+\n  # scale_y_log10()+\n  geom_point()+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nmodel_data &lt;- simpl_network_sf |&gt; \n  filter(oneway) |&gt;\n  left_join(summary_pairs,by = \"pair_id\") |&gt; \n  mutate(wwd_bool = pair_id %in% subset_wwd$pair_id) \n\n\nmodel_data |&gt; \n  ggplot(aes(x = (reldiff_max),y = wwd_bool))+\n    geom_jitter(alpha = 0.1)+\n  theme_minimal()\n\nWarning: Removed 445 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nmodel_data |&gt; \n  ggplot(aes(x = (reldiff_max),fill = wwd_bool))+\n  geom_histogram(alpha = 0.4)+\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 445 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\ntest1 &lt;- model_data |&gt; group_by(way_id) |&gt; \n  summarise(across(c(diff_max,reldiff_max),\n                   \\(x) mean(x,na.rm = T)),\n            across(wwd_bool,\\(x) sum(x)&gt;=1))\n\n\ntest1 |&gt;\n  ggplot(aes(x = (reldiff_max),y = wwd_bool))+\n    geom_jitter(alpha = 0.1)+\n  theme_minimal()\n\nWarning: Removed 131 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nFitting a logistic model with all the data (not useful)\n\n# cent_diff &lt;- glm(wwd_bool~reldiff_max,data = model_data)\n# \n# library(jtools)\n# effect_plot(model_data,pred = reldiff_max,plot.points = T,jitter = c(0.1,0.05),point.alpha = 0.1)\n# \n# plot(cent_diff)\n# \n# \n\n\n# simpl_network_sf |&gt; \n#   mutate(oneway.raw = if_else(is.na(oneway.raw),\"no\",oneway.raw),\n#          oneway.raw = str_detect(oneway.raw,\"(yes|Yes|YES)\")) |&gt; \n#   # filter(oneway.raw) |&gt; \n#   left_join(summary_pairs,by = \"pair_id\") |&gt; \n#   mutate(wwd_bool = pair_id %in% subset_wwd$pair_id) |&gt; \n#   st_write(\"sf_network/simpl_net.gpkg\",delete_dsn = T)"
  },
  {
    "objectID": "A2_graph.html",
    "href": "A2_graph.html",
    "title": "Baseline Network Graph",
    "section": "",
    "text": "Libraries\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\"\n    # \"dodgr\" # Using the developer version of dodgr\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n       sf tidyverse \n     TRUE      TRUE \n\nrequire(dodgr)\n\nUsing the networks extracted before. The following code loads the sf objects.\n\nsf_bogota_2019 &lt;- st_read(file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),layer = \"network_2019\")\n\nReading layer `network_2019' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 54531 features and 15 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.441 ymin: 4.236862 xmax: -73.72583 ymax: 5.042826\nGeodetic CRS:  MAGNA-SIRGAS\n\n\n\n\nIn this step, a graph representation of the 2019 road network of Bogotá is processed using the dodgr package. Posted speed limits are used as standard speeds for the road links (edges). The corresponding weighting profile has been saved in the bogota_wp.json file. To speed up the calculation, a distance threshold is applied based on an maximum error of 0.001.\n\ngraph_bogota &lt;- weight_streetnet(sf_bogota_2019,\n                                 left_side = F,\n                                 wt_profile_file = \"bogota_wp.json\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols = c(\"oneway\",\"lanes\",\"surface\",\"maxspeed\"))\n\n# graph_bogota |&gt;\n#   dodgr_contract_graph() |&gt;\n#   estimate_centrality_threshold(tolerance = 1e-3)\n# converged on distance threshold of 14000\n\ngraph_bogota_centrality &lt;- graph_bogota |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality(dist_threshold = 1.4e4,\n                   column = \"time_weighted\")\n\nsf_network &lt;- graph_bogota |&gt; \n    dodgr_to_sf ()\n\nExporting the results\n\nsf_net_cent &lt;- sf_network |&gt;\n  left_join(\n    tibble(edge_id = graph_bogota_centrality$edge_id,\n           centrality = graph_bogota_centrality$centrality),\n    by = \"edge_id\")\n\nst_write(sf_net_cent,\"sf_network/bogota_osm_network_cent.gpkg\",delete_dsn = F,delete_layer = T,layer = \"bog_cent_2019\")\n\n\n\nTo clip the network for visualisation, we will load the file with urban perimeter\n\nurban_perimeter &lt;- st_read(\"raw_data/perimetrourbano.gpkg\") |&gt; \n  st_transform(4326)\n\nReading layer `PerimetroUrbano' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\raw_data\\perimetrourbano.gpkg' \n  using driver `GPKG'\n\n\nWarning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : GDAL\nMessage 1: Non-conformant content for record 1 in column\nFECHA_ACTO_ADMINISTRATIVO, 2021-12-29T00:00:00.0Z, successfully parsed\n\n\nSimple feature collection with 3 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.22358 ymin: 4.468614 xmax: -74.01206 ymax: 4.830661\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nThe following code produces a visualisation of the network with the calculated centrality.\n\nroad_hierarchy &lt;- c( \n  \"trunk\",\n  \"trunk_link\",\n  \"primary\",\n  \"primary_link\",\n  \"secondary\",\n  \"secondary_link\",\n  \"tertiary\",\n  \"tertiary_link\",\n  \"residential\",\n  \"unclassified\"\n  )\n\nmymap &lt;- sf_net_cent[urban_perimeter,] |&gt; \n  mutate(highway = factor(highway,levels = road_hierarchy,ordered = T)) |&gt; \n  ggplot(aes(linewidth = centrality+1))+\n  geom_sf(aes(col = log(centrality)))+\n  scale_color_viridis_c(direction = -1)+\n  scale_linewidth_continuous(range = c(0.05,0.3),\n                             transform = scales::transform_boxcox(p = 2))+\n  theme_void()+\n  guides(linewidth = \"none\",)+\n  labs(col = \"Centrality (log)\",\n       caption = \"BC at posted speed limit\")+\n  theme(legend.position = \"inside\",\n        legend.position.inside = c(0.25,0.8),\n        # text = element_text(family = \"Roboto Condensed\"),\n        legend.key.width = unit(3, \"mm\"))\n\n## For saving the final plot\n# ggsave(plot = mymap,\n#        filename = \"bog_centrality.png\",\n#        dpi = 330,\n#        units = \"cm\",\n#        height = 13,\n#        width = 11)\nmymap\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_sf()`)."
  },
  {
    "objectID": "A2_graph.html#building-the-graph",
    "href": "A2_graph.html#building-the-graph",
    "title": "Baseline Network Graph",
    "section": "",
    "text": "In this step, a graph representation of the 2019 road network of Bogotá is processed using the dodgr package. Posted speed limits are used as standard speeds for the road links (edges). The corresponding weighting profile has been saved in the bogota_wp.json file. To speed up the calculation, a distance threshold is applied based on an maximum error of 0.001.\n\ngraph_bogota &lt;- weight_streetnet(sf_bogota_2019,\n                                 left_side = F,\n                                 wt_profile_file = \"bogota_wp.json\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols = c(\"oneway\",\"lanes\",\"surface\",\"maxspeed\"))\n\n# graph_bogota |&gt;\n#   dodgr_contract_graph() |&gt;\n#   estimate_centrality_threshold(tolerance = 1e-3)\n# converged on distance threshold of 14000\n\ngraph_bogota_centrality &lt;- graph_bogota |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality(dist_threshold = 1.4e4,\n                   column = \"time_weighted\")\n\nsf_network &lt;- graph_bogota |&gt; \n    dodgr_to_sf ()\n\nExporting the results\n\nsf_net_cent &lt;- sf_network |&gt;\n  left_join(\n    tibble(edge_id = graph_bogota_centrality$edge_id,\n           centrality = graph_bogota_centrality$centrality),\n    by = \"edge_id\")\n\nst_write(sf_net_cent,\"sf_network/bogota_osm_network_cent.gpkg\",delete_dsn = F,delete_layer = T,layer = \"bog_cent_2019\")\n\n\n\nTo clip the network for visualisation, we will load the file with urban perimeter\n\nurban_perimeter &lt;- st_read(\"raw_data/perimetrourbano.gpkg\") |&gt; \n  st_transform(4326)\n\nReading layer `PerimetroUrbano' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\raw_data\\perimetrourbano.gpkg' \n  using driver `GPKG'\n\n\nWarning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : GDAL\nMessage 1: Non-conformant content for record 1 in column\nFECHA_ACTO_ADMINISTRATIVO, 2021-12-29T00:00:00.0Z, successfully parsed\n\n\nSimple feature collection with 3 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.22358 ymin: 4.468614 xmax: -74.01206 ymax: 4.830661\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nThe following code produces a visualisation of the network with the calculated centrality.\n\nroad_hierarchy &lt;- c( \n  \"trunk\",\n  \"trunk_link\",\n  \"primary\",\n  \"primary_link\",\n  \"secondary\",\n  \"secondary_link\",\n  \"tertiary\",\n  \"tertiary_link\",\n  \"residential\",\n  \"unclassified\"\n  )\n\nmymap &lt;- sf_net_cent[urban_perimeter,] |&gt; \n  mutate(highway = factor(highway,levels = road_hierarchy,ordered = T)) |&gt; \n  ggplot(aes(linewidth = centrality+1))+\n  geom_sf(aes(col = log(centrality)))+\n  scale_color_viridis_c(direction = -1)+\n  scale_linewidth_continuous(range = c(0.05,0.3),\n                             transform = scales::transform_boxcox(p = 2))+\n  theme_void()+\n  guides(linewidth = \"none\",)+\n  labs(col = \"Centrality (log)\",\n       caption = \"BC at posted speed limit\")+\n  theme(legend.position = \"inside\",\n        legend.position.inside = c(0.25,0.8),\n        # text = element_text(family = \"Roboto Condensed\"),\n        legend.key.width = unit(3, \"mm\"))\n\n## For saving the final plot\n# ggsave(plot = mymap,\n#        filename = \"bog_centrality.png\",\n#        dpi = 330,\n#        units = \"cm\",\n#        height = 13,\n#        width = 11)\nmymap\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_sf()`)."
  },
  {
    "objectID": "A3_Congested_graph.html",
    "href": "A3_Congested_graph.html",
    "title": "Congested Network",
    "section": "",
    "text": "Congested Network\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\"\n    # \"dodgr\"\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n       sf tidyverse \n     TRUE      TRUE \n\nrequire(dodgr)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rat-runs",
    "section": "",
    "text": "Rat-runs in Bogota\n\nNetwork data\n\nOSM\nIDECA malla vial integral\n\n\n\nInfractions data\n\n\nAssumptions:\n\nRecurring wrong-way infraction reports in residential streets is a result of rat-running\n\n\n\nHypothesis:"
  },
  {
    "objectID": "B2_congestion_data.html",
    "href": "B2_congestion_data.html",
    "title": "Congestion Data",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"raster\",\n    \"tidyverse\",\n    \"googletraffic\",\n    \"mapboxapi\"\n)\n\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n           sf        raster     tidyverse googletraffic     mapboxapi \n         TRUE          TRUE          TRUE          TRUE          TRUE \n\n\n\n\n\n## Make raster\nr &lt;- gt_make_raster(location   = c(4.702161, -74.093498),\n                    height     = 2000,\n                    width      = 2000,\n                    zoom       = 16,\n                    google_key = Sys.getenv(\"GMAPS\"))\n\nPausing for 16 seconds to allow traffic data to render\n\n\nWarning in dir.create(filename_dir):\n'C:\\Users\\ts18jpf\\AppData\\Local\\Temp\\RtmpMpFMCm' already exists\n\n## Plot\nr_df &lt;- rasterToPoints(r, spatial = TRUE) |&gt;  as.data.frame()\nnames(r_df) &lt;- c(\"value\", \"x\", \"y\")\n\n\n\n\n\nggplot() +\n  geom_raster(data = r_df, \n  aes(x = x, y = y, \n  fill = as.factor(value))) +\n  labs(fill = \"Traffic\\nLevel\") +\n  scale_fill_manual(values = c(\"green2\", \"orange\", \"red\", \"#660000\")) +\n  coord_quickmap() + \n  theme_void() +\n  theme(plot.background = element_rect(fill = \"white\", color=\"white\"))\n\n\n\n\n\n\n\n\n\nr1 &lt;- raster::raster(ncol=10, nrow=10, xmn = -10, xmx = 1,  ymn = -10, ymx = 1)\nr2 &lt;- raster::raster(ncol=10, nrow=10, xmn = 0,   xmx = 10, ymn = 0,   ymx = 10)\nr3 &lt;- raster::raster(ncol=10, nrow=10, xmn = 9,   xmx = 20, ymn = 9,   ymx = 20)\n\nr123 &lt;- list(r1, r2, r3)\n\nr &lt;- gt_mosaic(r123)\n\nplot(r)"
  },
  {
    "objectID": "B2_congestion_data.html#google-traffic",
    "href": "B2_congestion_data.html#google-traffic",
    "title": "Congestion Data",
    "section": "",
    "text": "## Make raster\nr &lt;- gt_make_raster(location   = c(4.702161, -74.093498),\n                    height     = 2000,\n                    width      = 2000,\n                    zoom       = 16,\n                    google_key = Sys.getenv(\"GMAPS\"))\n\nPausing for 16 seconds to allow traffic data to render\n\n\nWarning in dir.create(filename_dir):\n'C:\\Users\\ts18jpf\\AppData\\Local\\Temp\\RtmpMpFMCm' already exists\n\n## Plot\nr_df &lt;- rasterToPoints(r, spatial = TRUE) |&gt;  as.data.frame()\nnames(r_df) &lt;- c(\"value\", \"x\", \"y\")\n\n\n\n\n\nggplot() +\n  geom_raster(data = r_df, \n  aes(x = x, y = y, \n  fill = as.factor(value))) +\n  labs(fill = \"Traffic\\nLevel\") +\n  scale_fill_manual(values = c(\"green2\", \"orange\", \"red\", \"#660000\")) +\n  coord_quickmap() + \n  theme_void() +\n  theme(plot.background = element_rect(fill = \"white\", color=\"white\"))\n\n\n\n\n\n\n\n\n\nr1 &lt;- raster::raster(ncol=10, nrow=10, xmn = -10, xmx = 1,  ymn = -10, ymx = 1)\nr2 &lt;- raster::raster(ncol=10, nrow=10, xmn = 0,   xmx = 10, ymn = 0,   ymx = 10)\nr3 &lt;- raster::raster(ncol=10, nrow=10, xmn = 9,   xmx = 20, ymn = 9,   ymx = 20)\n\nr123 &lt;- list(r1, r2, r3)\n\nr &lt;- gt_mosaic(r123)\n\nplot(r)"
  },
  {
    "objectID": "A1_network.html",
    "href": "A1_network.html",
    "title": "Extracting OSM networks",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"osmextract\",\n    \"rvest\"\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n        sf  tidyverse osmextract      rvest \n      TRUE       TRUE       TRUE       TRUE \n\n\nFor this study, we will use OpenStreetMap to obtain the road network data. First, we will download a spatial data file with the urban perimeter of Bogotá from Datos Abiertos de Bogotá (Bogotá’s Open Data platform).\n\ndir.create(\"raw_data\",showWarnings = F)\n\nif(!file.exists(file.path(\"raw_data\", \"perimetrourbano.gpkg\"))) {\n  u &lt;- \"https://datosabiertos.bogota.gov.co/dataset/12a704ee-e5bb-4c5d-bad6-a5069d12f90a/resource/bfc61e3c-fa58-4fe7-9581-7ead66c494cb/download/perimetrourbano.gpkg\"\n  download.file(u, file.path(\"raw_data\", basename(u)), mode = \"wb\")\n}\n\nurban_perimeter &lt;- st_read(\"raw_data/perimetrourbano.gpkg\")\n\nReading layer `PerimetroUrbano' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\raw_data\\perimetrourbano.gpkg' \n  using driver `GPKG'\n\n\nWarning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : GDAL\nMessage 1: Non-conformant content for record 1 in column\nFECHA_ACTO_ADMINISTRATIVO, 2021-12-29T00:00:00.0Z, successfully parsed\n\n\nSimple feature collection with 3 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.22358 ymin: 4.468614 xmax: -74.01206 ymax: 4.830661\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nWe will use the osmextract package to get OSM data in R. Please note that we will be using previous versions of the OSM data, as the network might have changed in recent years. For example, some sections of the roads are currently closed (2024) due to the works for the first metro line in Bogotá. We will use OSM networks for end of 2019 (January 1st, 2020) and 2020 (January 1st, 2021).\nFirst, we produce a boundary box for an area covering the urban perimeter and the neighbouring municipalities. This is done by producing a buffer of 20 km around Bogotá.\n\nbbox_bogota &lt;- urban_perimeter |&gt;\n  st_buffer(dist = 20e3) |&gt; \n  st_bbox() |&gt;\n  st_as_sfc() |&gt;\n  st_transform(crs = 4326)\n\nWe obtain the url of the pbf file in Geofabrik which contains the area we are interested in.\n\nbog_match &lt;- oe_match(bbox_bogota,provider = \"geofabrik\")\n\nThe input place was matched with Colombia. \n\n\nThe following code obtains the names of the files with the older versions of the OSM data and downloads the 2019 and 2020 pbf files.\n\nu &lt;- dirname(bog_match$url)\nf &lt;- basename(bog_match$url)\n\nid_files &lt;- gsub(\"latest\\\\.osm\\\\.pbf\",replacement = \"\",f)\n\nfiles_table &lt;- (rvest::read_html(u) |&gt; html_table())[[1]]\n\navailable_versions &lt;- files_table$Name[grep(paste0(id_files,\"\\\\d{6}\\\\.osm\\\\.pbf$\"),\n                                            files_table$Name)]\n\nnet_options &lt;- osmextract:::load_options_driving(NA_character_)\n\nnet_options$extra_tags &lt;- c(\"oneway\",\"lanes\",\"surface\",\"maxspeed\",net_options$extra_tags)\n\nnet_old_200101 &lt;- do.call(oe_read,\n                          c(file_path = paste0(u,\"/\",available_versions[7]),\n                            net_options[2:4]\n                     )\n                   )\n\nThe chosen file was already detected in the download directory. Skip downloading.\n\n\nStarting with the vectortranslate operations on the input file!\n\n\n0...10...20...30...40...50...60...70...80...90...100 - done.\n\n\nFinished the vectortranslate operations on the input file!\n\n\nReading layer `lines' from data source \n  `C:\\Users\\ts18jpf\\Documents\\OSMEXT_downloads\\geofabrik_colombia-200101.gpkg' \n  using driver `GPKG'\nSimple feature collection with 461429 features and 15 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -81.73539 ymin: -4.259884 xmax: -66.83441 ymax: 13.38586\nGeodetic CRS:  WGS 84\n\nnet_old_210101 &lt;- do.call(oe_read,\n                          c(file_path = paste0(u,\"/\",available_versions[8]),\n                            net_options[2:4]\n                     )\n                   )\n\nThe chosen file was already detected in the download directory. Skip downloading.\nStarting with the vectortranslate operations on the input file!\n\n\n0...10...20...30...40...50...60...70...80...90...100 - done.\n\n\nFinished the vectortranslate operations on the input file!\n\n\nReading layer `lines' from data source \n  `C:\\Users\\ts18jpf\\Documents\\OSMEXT_downloads\\geofabrik_colombia-210101.gpkg' \n  using driver `GPKG'\nSimple feature collection with 650682 features and 15 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -81.73539 ymin: -4.259656 xmax: -66.83441 ymax: 13.38586\nGeodetic CRS:  WGS 84\n\n\nOnce we have downloaded the data. We can clean and clip the network by using the boundary box we produced and by filtering only relevant road links (see the road_types vector).\n\nroad_types &lt;- c(\"tertiary\"       ,\n  \"residential\"    ,\n  \"primary_link\"   ,\n  \"primary\"      ,\n  \"secondary\"      ,\n  \"trunk\"          ,\n  \"trunk_link\"     ,\n  # \"service\"      ,\n  \"secondary_link\" ,\n  \"unclassified\"   ,\n  \"tertiary_link\"  \n  # \"living_street\"\n  # \"track\"          ,\n  # \"busway\"         ,\n  # \"raceway\"\n)\n\nosm_bogota_200101 &lt;- net_old_200101[bbox_bogota,] |&gt;\n  filter(highway %in% road_types) |&gt; st_transform(st_crs(urban_perimeter))\n\nosm_bogota_210101 &lt;- net_old_210101[bbox_bogota,] |&gt;\n  filter(highway %in% road_types) |&gt; st_transform(st_crs(urban_perimeter))\n\nrm(net_old_200101,net_old_210101)\n\n\n\nFinally, we save the sf objects as GeoPackages.\n\ndir.create(\"sf_network\",showWarnings = F)\nst_write(osm_bogota_200101,\n         file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),\n         delete_dsn = F,\n         layer = \"network_2019\",\n         delete_layer = T)\n\nDeleting layer `network_2019' using driver `GPKG'\nWriting layer `network_2019' to data source \n  `sf_network/bogota_osm_network.gpkg' using driver `GPKG'\nWriting 54531 features with 15 fields and geometry type Line String.\n\nst_write(osm_bogota_210101,\n         file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),\n         delete_dsn = F,\n         layer = \"network_2020\",\n         delete_layer = T)\n\nDeleting layer `network_2020' using driver `GPKG'\nWriting layer `network_2020' to data source \n  `sf_network/bogota_osm_network.gpkg' using driver `GPKG'\nWriting 62166 features with 15 fields and geometry type Line String."
  },
  {
    "objectID": "A1_network.html#save-network-in-sf-format",
    "href": "A1_network.html#save-network-in-sf-format",
    "title": "Extracting OSM networks",
    "section": "",
    "text": "Finally, we save the sf objects as GeoPackages.\n\ndir.create(\"sf_network\",showWarnings = F)\nst_write(osm_bogota_200101,\n         file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),\n         delete_dsn = F,\n         layer = \"network_2019\",\n         delete_layer = T)\n\nDeleting layer `network_2019' using driver `GPKG'\nWriting layer `network_2019' to data source \n  `sf_network/bogota_osm_network.gpkg' using driver `GPKG'\nWriting 54531 features with 15 fields and geometry type Line String.\n\nst_write(osm_bogota_210101,\n         file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),\n         delete_dsn = F,\n         layer = \"network_2020\",\n         delete_layer = T)\n\nDeleting layer `network_2020' using driver `GPKG'\nWriting layer `network_2020' to data source \n  `sf_network/bogota_osm_network.gpkg' using driver `GPKG'\nWriting 62166 features with 15 fields and geometry type Line String."
  },
  {
    "objectID": "C1_infractions.html",
    "href": "C1_infractions.html",
    "title": "Ticket Data",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"tmap\",\n    \"webshot2\"\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n       sf tidyverse      tmap  webshot2 \n     TRUE      TRUE      TRUE      TRUE \n\ntmap_mode(\"plot\")\n\n\n\n\nreports2019 &lt;- read_csv(\"../00_data/bogota/Comparendos_2019_Bogota_D_C.csv\",\n                        col_types = cols(\n                          X = col_double(),\n                          Y = col_double(),\n                          OBJECTID = col_double(),\n                          NUM_COMPARENDO = col_character(),\n                          FECHA_HORA = col_character(),\n                          ANO = col_double(),\n                          HORA_OCURRENCIA = col_character(),\n                          MES = col_character(),\n                          MEDIO_DETECCION = col_character(),\n                          CLASE_VEHICULO = col_character(),\n                          TIPO_SERVICIO = col_character(), \n                          INFRACCION = col_character(),\n                          DES_INFRACCION = col_character(),\n                          LOCALIDAD = col_character(),\n                          MUNICIPIO = col_character(),\n                          LATITUD = col_double(),\n                          LONGITUD = col_double(),\n                          GlobalID = col_character()\n                        ))\n\nreports2020 &lt;- read_csv(\"../00_data/bogota/Comparendos_DEI_2020_Bogot%C3%A1_D_C.csv\",\n                        col_types = cols(\n                          X = col_double(),\n                          Y = col_double(),\n                          FID = col_double(),\n                          OBJECTID = col_double(),\n                          FECHA_HORA = col_character(),\n                          ANO = col_double(),\n                          HORA_OCURR = col_character(),\n                          MES = col_character(),\n                          MEDIO_DETE = col_character(),\n                          CLASE_VEHI = col_character(),\n                          TIPO_SERVI = col_character(),\n                          INFRACCION = col_character(),\n                          DES_INFRAC = col_character(),\n                          MUNICIPIO = col_character(),\n                          PAIS = col_character(),\n                          LATITUD = col_double(),\n                          LONGITUD = col_double()))\n\n\n\n\n\nreports2019 |&gt; \n  count(INFRACCION) |&gt; \n  filter(n&gt;quantile(n,0.90)) |&gt; \n  ggplot(aes(y = fct_reorder(INFRACCION,n),\n             x = n))+\n  geom_col()+\n  scale_x_continuous()\n\n\n\n\n\n\n\n\n\ncount_infractions &lt;- reports2019 |&gt; \n  count(INFRACCION,DES_INFRACCION) |&gt; \n  filter(n&gt;quantile(n,0.70)) |&gt; \n  arrange(-n)\n\n\n\n\nCreating an sf object with the reports for driving in the wrong-way\n\nwrong_way_2019_sf &lt;- reports2019 |&gt;\n  filter(INFRACCION == \"D03\") |&gt; \n  select(-DES_INFRACCION) |&gt;\n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  st_as_sf(coords = c(\"LONGITUD\",\"LATITUD\"),crs = 4326)\n\nwrong_way_2020_sf &lt;- reports2020 |&gt;\n  filter(INFRACCION == \"D03\") |&gt; \n  select(-DES_INFRAC) |&gt; \n  mutate(time = hms(HORA_OCURR)) |&gt;\n  st_as_sf(coords = c(\"LONGITUD\",\"LATITUD\"),crs = 4326)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `time = hms(HORA_OCURR)`.\nCaused by warning in `.parse_hms()`:\n! Some strings failed to parse\n\n\n\n\n\nWe will select only relevant columns and also classify the records by type of day. For that, we will use the bank holiday list we used for the speed data processing.\n\nbank_holidays &lt;- read.csv(\"../00_data/bogota/bank_holidays.csv\") |&gt;\n  mutate(bank_holiday = dmy(bank_holiday)) |&gt;\n  pull(bank_holiday)\n\n\nwwd_2019_clean &lt;- wrong_way_2019_sf |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETECCION,\n         CLASE_VEHICULO,\n         time) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETECCION,\n         veh_class = CLASE_VEHICULO) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp)) |&gt; \n  mutate(day_type = case_when(date(timestamp) %in% bank_holidays~\"weekend\",\n                              wday(timestamp,week_start = 1)&lt;=4~\"weekday\",\n                              wday(timestamp,week_start = 1) == 5~\"friday\",\n                              T~\"weekend\"))\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\nwwd_2020_clean &lt;- wrong_way_2020_sf |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETE,\n         CLASE_VEHI,\n         time) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETE,\n         veh_class = CLASE_VEHI) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp)) |&gt; \n  mutate(day_type = case_when(date(timestamp) %in% bank_holidays~\"weekend\",\n                              wday(timestamp,week_start = 1)&lt;=4~\"weekday\",\n                              wday(timestamp,week_start = 1) == 5~\"friday\",\n                              T~\"weekend\"))\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\nAnd consolidating the two datasets\n\nall_wwd_reports &lt;- bind_rows(wwd_2019_clean,wwd_2020_clean) |&gt; \n  mutate(veh_class = str_to_lower(veh_class))\n\n\n\n\n\n\n\nggplot(all_wwd_reports,aes(col = factor(year)))+\n         geom_sf(alpha = 0.2,size = 0.5)+\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\nA daily profile\n\nggplot(all_wwd_reports,\n         aes(x = time, col = factor(year)))+\n  geom_density(alpha = 0.5,linewidth = 2)+\n    scale_x_time()+\n  scale_colour_manual(values = c(\"dodgerblue3\",\"firebrick3\"))+\n  # scale_y_continuous(labels = scales::label_percent(accuracy = 2))+\ntheme_minimal()\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\n\nall_wwd_reports |&gt;\n  st_drop_geometry() |&gt; \n  count(date(timestamp),day_type,hour,year) |&gt; \n  ggplot(aes(x=factor(hour),y = n,col = day_type))+\n  geom_jitter(alpha = 0.05)+\n  geom_boxplot(alpha = 0.5,outlier.shape = NA)+\n  facet_grid(year~.)+\n  theme_minimal()\n\n\n\n\n\n\n\n\nA check of the reports per day\n\nexp_dates_count &lt;- all_wwd_reports |&gt;\n  st_drop_geometry() |&gt; \n  count(date = date(timestamp)) |&gt; \n  right_join(\n    tibble(date = seq(min(date(all_wwd_reports$date_time)),\n                      max(date(all_wwd_reports$date_time)),\n                      by = \"1 day\")),by = \"date\")\n\nA quick check of the timeline reveals gaps in the reports of 2019. We do not know the causes.\n\nexp_dates_count |&gt; \n  mutate(n = if_else(is.na(n),0,n)) |&gt; \n  ggplot(aes(x = date,y = n))+\n  geom_line()+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nexp_dates_count |&gt; \n  mutate(wday = wday(date,week_start = 2),\n         week = week(date)) |&gt; \n  ggplot(aes(y = factor(wday),x = factor(week),fill = n))+\n  geom_tile()+\n  theme_minimal()+\n  facet_grid(year(date)~.)+\n  scale_fill_viridis_c(direction = -1)\n\n\n\n\n\n\n\n\n\n\nLet us check if there is any patter related to the day of the week\n\nall_wwd_reports |&gt;\n  st_drop_geometry() |&gt; \n  count(date = date(timestamp),year) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = mean(n),.by = c(wday,year)) |&gt; \n  ggplot(aes(x= wday,y = n, col = factor(year)))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\n\n\n\n\n\n\n\nThere seems to be a pattern that might be related to the sampling i.e. how the enforcement officers are assigned along the week.\nLet’s compare with other types of infractions reported by officers\n\nreports2019 |&gt;\n  select(-DES_INFRACCION) |&gt;\n  filter(MEDIO_DETECCION == \"LAPIZ\") |&gt; \n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETECCION,\n         CLASE_VEHICULO,\n         time,\n         INFRACCION) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETECCION,\n         veh_class = CLASE_VEHICULO,\n         offence = INFRACCION) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp)) |&gt; \n  count(date = date(timestamp),offence) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = mean(n),.by = c(wday,offence)) |&gt; \n  filter(sum(n)&gt;250,.by = offence) |&gt; \n  ggplot(aes(x= wday,y = n, col = factor(offence)))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\nWe can also inspect the median number of tickets per weekday for all offences that are reported by traffic management officers in 2019 and 2020\n\nreports2019 |&gt;\n  select(-DES_INFRACCION) |&gt;\n  filter(MEDIO_DETECCION == \"LAPIZ\") |&gt; \n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETECCION,\n         CLASE_VEHICULO,\n         time,\n         INFRACCION) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETECCION,\n         veh_class = CLASE_VEHICULO,\n         offence = INFRACCION) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp)) |&gt; \n  count(date = date(timestamp)) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = mean(n),.by = c(wday)) |&gt; \n  # filter(sum(n)&gt;250,.by = offence) |&gt; \n  ggplot(aes(x= wday,y = n))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\n\nreports2020 |&gt; \n  select(-DES_INFRAC) |&gt;\n  filter(MEDIO_DETE == \"DISPOSITIVOS EN VÍA\") |&gt; \n  mutate(time = hms(HORA_OCURR)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETE,\n         CLASE_VEHI,\n         time,\n         INFRACCION) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETE,\n         veh_class = CLASE_VEHI,\n         offence = INFRACCION) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp)) |&gt; \n  count(date = date(timestamp)) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = mean(n),.by = c(wday)) |&gt; \n  # filter(sum(n)&gt;250,.by = offence) |&gt; \n  ggplot(aes(x= wday,y = n))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `time = hms(HORA_OCURR)`.\nCaused by warning in `.parse_hms()`:\n! Some strings failed to parse\n\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\nIs it a problem with the data, as some months are not reported? Let’s see if the pattern is similar across months\n\nreports2019 |&gt;\n  select(-DES_INFRACCION) |&gt;\n  filter(MEDIO_DETECCION == \"LAPIZ\") |&gt; \n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETECCION,\n         CLASE_VEHICULO,\n         time,\n         INFRACCION) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETECCION,\n         veh_class = CLASE_VEHICULO,\n         offence = INFRACCION) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp),\n         month = month(timestamp)) |&gt; \n  count(date = date(timestamp),month) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = median(n),.by = c(wday,month)) |&gt; \n  # filter(sum(n)&gt;250,.by = offence) |&gt; \n  ggplot(aes(x= wday,y = n,col =  factor(month)))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\n\nreports2020 |&gt; \n  select(-DES_INFRAC) |&gt;\n  filter(MEDIO_DETE == \"DISPOSITIVOS EN VÍA\") |&gt; \n  mutate(time = hms(HORA_OCURR)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETE,\n         CLASE_VEHI,\n         time,\n         INFRACCION) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETE,\n         veh_class = CLASE_VEHI,\n         offence = INFRACCION) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp),\n         month = month(timestamp)) |&gt; \n  count(date = date(timestamp),month) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = median(n),.by = c(wday,month)) |&gt; \n  # filter(sum(n)&gt;250,.by = offence) |&gt; \n  ggplot(aes(x= wday,y = n,col =  factor(month)))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `time = hms(HORA_OCURR)`.\nCaused by warning in `.parse_hms()`:\n! Some strings failed to parse\n\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\nVisually, there seems to be a consistent pattern of a low number of reports during friday and saturday, followed by a surge on Sundays.\n\n\n\n\nLet’s assign all reports to the nearest link to explore where the enforcement offices tend to catch the offenders\n\nnet_bog_2019 &lt;- st_read(file.path(\"sf_network\",\"bogota_osm_network.gpkg\")) |&gt; st_transform(3116)\n\nMultiple layers are present in data source C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg, reading layer `network_2019'.\nUse `st_layers' to list all layer names and their type in a data source.\nSet the `layer' argument in `st_read' to read a particular layer.\n\n\nWarning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, :\nautomatically selected the first layer in a data source containing more than\none.\n\n\nReading layer `network_2019' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 54531 features and 15 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.441 ymin: 4.236862 xmax: -73.72583 ymax: 5.042826\nGeodetic CRS:  MAGNA-SIRGAS\n\n\n\nmajor_network &lt;- net_bog_2019 |&gt; filter(!(highway %in% c(\"residential\",\"unclassified\")))\n\n\nmanual_reports_2019 &lt;- reports2019 |&gt;\n  select(-DES_INFRACCION) |&gt;\n  filter(MEDIO_DETECCION == \"LAPIZ\") |&gt; \n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETECCION,\n         CLASE_VEHICULO,\n         time,\n         INFRACCION,\n         LONGITUD,LATITUD) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETECCION,\n         veh_class = CLASE_VEHICULO,\n         offence = INFRACCION) |&gt; \n  st_as_sf(coords = c(\"LONGITUD\",\"LATITUD\"),crs = 4326) |&gt; \n  st_transform(3116)\n\n\nmanual_reports_2019$near_index &lt;- st_nearest_feature(manual_reports_2019,net_bog_2019)\nmanual_reports_2019$near_major_index &lt;- st_nearest_feature(manual_reports_2019,major_network)\n\n\nmanual_reports_2019$highway &lt;- net_bog_2019$highway[manual_reports_2019$near_index]\nmanual_reports_2019$oneway &lt;- net_bog_2019$oneway[manual_reports_2019$near_index]\n\n\nmanual_reports_2019$dist_to_major &lt;- st_distance(\n  manual_reports_2019,\n  major_network[manual_reports_2019$near_major_index,],\n  by_element = T) |&gt; as.numeric()\n\nType of road where the offence was reported\n\nmanual_reports_2019 |&gt; \n  st_drop_geometry() |&gt; \n  mutate(highway = str_remove(highway,\"_link\")) |&gt; \n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp),\n         month = month(timestamp)) |&gt; \n  count(date = date(timestamp),highway) |&gt; \n  summarise(n = median(n),.by = c(highway)) |&gt; \n  ggplot(aes(x = fct_reorder(highway,n,.desc = F),y = n))+\n  geom_col()+\n  coord_flip()\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\n\nmanual_reports_2019 |&gt; \n  st_drop_geometry() |&gt; \n  mutate(highway = str_remove(highway,\"_link\")) |&gt;\n  mutate(highway = factor(highway,\n                          levels =\n                            c(\"trunk\",\"primary\",\"secondary\",\"tertiary\",\"residential\",\"unclassified\"),\n                          ordered = T)) |&gt; \n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp),\n         month = month(timestamp)) |&gt; \n  count(date = date(timestamp),highway) |&gt; \n  summarise(n = median(n),.by = c(highway)) |&gt;\n  arrange(highway) |&gt; \n  mutate(perc = n/sum(n)) |&gt;\n  # mutate(prev = cumsum(perc)-perc) |&gt; \n  # select(-n) |&gt; \n  # pivot_longer(-highway) |&gt; \n  ggplot(aes(x = 1,y = perc,fill = highway))+\n  geom_col(position = \"stack\")+\n  # scale_alpha_manual(values = c(1,0.2))+\n  coord_flip()+\n  theme_minimal()+\n  scale_y_continuous(labels = scales::label_percent())\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\nMedian daily reports in residential roads\n\nmanual_reports_2019 |&gt; \n  st_drop_geometry() |&gt; \n  mutate(highway = str_remove(highway,\"_link\")) |&gt; \n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp),\n         month = month(timestamp)) |&gt; \n  filter(highway == \"residential\") |&gt;\n  count(date = date(timestamp),offence) |&gt; \n  summarise(n = median(n),.by = c(offence)) |&gt;\n  slice_max(n,n=15) |&gt; \n  ggplot(aes(x = fct_reorder(offence,n), y = n))+\n  geom_col()+\n  coord_flip()\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\nEuclidean distance to major network vs all reports\n\nggplot()+\n  geom_histogram(data = manual_reports_2019,\n                 aes(dist_to_major),\n                 alpha = 0.1)+\n  geom_histogram(data = manual_reports_2019 |&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\")),\n  aes(dist_to_major),\n  alpha = 0.3,\n  fill = \"dodgerblue4\",\n  col = \"dodgerblue3\")+\n  scale_x_log10()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot()+\n  geom_histogram(data = manual_reports_2019 |&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\")),\n  aes(dist_to_major),\n  alpha = 0.2)+\n  geom_histogram(data = manual_reports_2019 |&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\"),offence == \"D03\"),\n  aes(dist_to_major),\n  alpha = 0.3,\n  fill = \"dodgerblue4\",\n  col = \"dodgerblue3\")+\n  scale_x_sqrt()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nnet_points &lt;- net_bog_2019 |&gt;\n  st_cast(\"POINT\") |&gt;\n  slice_head(by = osm_id)\n\nWarning in st_cast.sf(net_bog_2019, \"POINT\"): repeating attributes for all\nsub-geometries for which they may not be constant\n\nnet_points &lt;- net_bog_2019 |&gt; st_centroid()\n\nWarning: st_centroid assumes attributes are constant over geometries\n\nnet_points$near_id &lt;- st_nearest_feature(net_points,major_network)\nnet_points$dist_to_major &lt;- st_distance(net_points,\n                                        major_network[net_points$near_id,],\n                                        by_element = T) |&gt;\n  as.numeric()\n\n\nggplot()+\n  geom_density(data = net_points|&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\")),\n                 aes(dist_to_major),\n                 alpha = 0.1)+\n  geom_density(data = manual_reports_2019 |&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\"), offence == \"D03\"),\n  aes(dist_to_major),\n  alpha = 0.3,\n  fill = \"dodgerblue4\",\n  col = \"dodgerblue3\")+\n  scale_x_sqrt(breaks = c(0,0.1,0.25,.5,1,2.5,5,7.5,10)*1e3)\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(major_network)+\n  tm_lines()+\n  tm_shape(manual_reports_2019 |&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\"), offence == \"D03\"))+\n  tm_dots(\"dist_to_major\")\n\n\n\n\n\n\n\n\n\n\n\n\nall_wwd_reports |&gt;\n  st_drop_geometry() |&gt;  \n  count(veh_class,year) |&gt; \n  arrange(-n) |&gt; \n  mutate(n = n/sum(n),.by=year) |&gt; \n  ggplot(aes(x = fct_reorder(veh_class,n,.desc = F),  y = n, fill = factor(year)))+\n  geom_col(position = \"dodge\",)+\n  coord_flip()+\n  scale_y_continuous(labels = scales::label_percent())+\n  theme_minimal()+\n  scale_fill_manual(values = c(\"dodgerblue3\",\"firebrick3\"))\n\n\n\n\n\n\n\n\n\n\n\n\nst_write(all_wwd_reports,\n         dsn = \"sf_network/wwd_clean_sf.gpkg\",\n         delete_dsn = T)\n\nDeleting source `sf_network/wwd_clean_sf.gpkg' using driver `GPKG'\nWriting layer `wwd_clean_sf' to data source \n  `sf_network/wwd_clean_sf.gpkg' using driver `GPKG'\nWriting 6915 features with 8 fields and geometry type Point."
  },
  {
    "objectID": "C1_infractions.html#loading-infractions",
    "href": "C1_infractions.html#loading-infractions",
    "title": "Ticket Data",
    "section": "",
    "text": "reports2019 &lt;- read_csv(\"../00_data/bogota/Comparendos_2019_Bogota_D_C.csv\",\n                        col_types = cols(\n                          X = col_double(),\n                          Y = col_double(),\n                          OBJECTID = col_double(),\n                          NUM_COMPARENDO = col_character(),\n                          FECHA_HORA = col_character(),\n                          ANO = col_double(),\n                          HORA_OCURRENCIA = col_character(),\n                          MES = col_character(),\n                          MEDIO_DETECCION = col_character(),\n                          CLASE_VEHICULO = col_character(),\n                          TIPO_SERVICIO = col_character(), \n                          INFRACCION = col_character(),\n                          DES_INFRACCION = col_character(),\n                          LOCALIDAD = col_character(),\n                          MUNICIPIO = col_character(),\n                          LATITUD = col_double(),\n                          LONGITUD = col_double(),\n                          GlobalID = col_character()\n                        ))\n\nreports2020 &lt;- read_csv(\"../00_data/bogota/Comparendos_DEI_2020_Bogot%C3%A1_D_C.csv\",\n                        col_types = cols(\n                          X = col_double(),\n                          Y = col_double(),\n                          FID = col_double(),\n                          OBJECTID = col_double(),\n                          FECHA_HORA = col_character(),\n                          ANO = col_double(),\n                          HORA_OCURR = col_character(),\n                          MES = col_character(),\n                          MEDIO_DETE = col_character(),\n                          CLASE_VEHI = col_character(),\n                          TIPO_SERVI = col_character(),\n                          INFRACCION = col_character(),\n                          DES_INFRAC = col_character(),\n                          MUNICIPIO = col_character(),\n                          PAIS = col_character(),\n                          LATITUD = col_double(),\n                          LONGITUD = col_double()))"
  },
  {
    "objectID": "C1_infractions.html#exploring-types-of-infractions",
    "href": "C1_infractions.html#exploring-types-of-infractions",
    "title": "Ticket Data",
    "section": "",
    "text": "reports2019 |&gt; \n  count(INFRACCION) |&gt; \n  filter(n&gt;quantile(n,0.90)) |&gt; \n  ggplot(aes(y = fct_reorder(INFRACCION,n),\n             x = n))+\n  geom_col()+\n  scale_x_continuous()\n\n\n\n\n\n\n\n\n\ncount_infractions &lt;- reports2019 |&gt; \n  count(INFRACCION,DES_INFRACCION) |&gt; \n  filter(n&gt;quantile(n,0.70)) |&gt; \n  arrange(-n)"
  },
  {
    "objectID": "C1_infractions.html#wrong-way-infraction",
    "href": "C1_infractions.html#wrong-way-infraction",
    "title": "Ticket Data",
    "section": "",
    "text": "Creating an sf object with the reports for driving in the wrong-way\n\nwrong_way_2019_sf &lt;- reports2019 |&gt;\n  filter(INFRACCION == \"D03\") |&gt; \n  select(-DES_INFRACCION) |&gt;\n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  st_as_sf(coords = c(\"LONGITUD\",\"LATITUD\"),crs = 4326)\n\nwrong_way_2020_sf &lt;- reports2020 |&gt;\n  filter(INFRACCION == \"D03\") |&gt; \n  select(-DES_INFRAC) |&gt; \n  mutate(time = hms(HORA_OCURR)) |&gt;\n  st_as_sf(coords = c(\"LONGITUD\",\"LATITUD\"),crs = 4326)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `time = hms(HORA_OCURR)`.\nCaused by warning in `.parse_hms()`:\n! Some strings failed to parse"
  },
  {
    "objectID": "C1_infractions.html#tidying-up-the-datasets",
    "href": "C1_infractions.html#tidying-up-the-datasets",
    "title": "Ticket Data",
    "section": "",
    "text": "We will select only relevant columns and also classify the records by type of day. For that, we will use the bank holiday list we used for the speed data processing.\n\nbank_holidays &lt;- read.csv(\"../00_data/bogota/bank_holidays.csv\") |&gt;\n  mutate(bank_holiday = dmy(bank_holiday)) |&gt;\n  pull(bank_holiday)\n\n\nwwd_2019_clean &lt;- wrong_way_2019_sf |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETECCION,\n         CLASE_VEHICULO,\n         time) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETECCION,\n         veh_class = CLASE_VEHICULO) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp)) |&gt; \n  mutate(day_type = case_when(date(timestamp) %in% bank_holidays~\"weekend\",\n                              wday(timestamp,week_start = 1)&lt;=4~\"weekday\",\n                              wday(timestamp,week_start = 1) == 5~\"friday\",\n                              T~\"weekend\"))\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\nwwd_2020_clean &lt;- wrong_way_2020_sf |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETE,\n         CLASE_VEHI,\n         time) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETE,\n         veh_class = CLASE_VEHI) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp)) |&gt; \n  mutate(day_type = case_when(date(timestamp) %in% bank_holidays~\"weekend\",\n                              wday(timestamp,week_start = 1)&lt;=4~\"weekday\",\n                              wday(timestamp,week_start = 1) == 5~\"friday\",\n                              T~\"weekend\"))\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\nAnd consolidating the two datasets\n\nall_wwd_reports &lt;- bind_rows(wwd_2019_clean,wwd_2020_clean) |&gt; \n  mutate(veh_class = str_to_lower(veh_class))"
  },
  {
    "objectID": "C1_infractions.html#eda",
    "href": "C1_infractions.html#eda",
    "title": "Ticket Data",
    "section": "",
    "text": "ggplot(all_wwd_reports,aes(col = factor(year)))+\n         geom_sf(alpha = 0.2,size = 0.5)+\n  theme_void()"
  },
  {
    "objectID": "C1_infractions.html#temporal-distribution",
    "href": "C1_infractions.html#temporal-distribution",
    "title": "Ticket Data",
    "section": "",
    "text": "A daily profile\n\nggplot(all_wwd_reports,\n         aes(x = time, col = factor(year)))+\n  geom_density(alpha = 0.5,linewidth = 2)+\n    scale_x_time()+\n  scale_colour_manual(values = c(\"dodgerblue3\",\"firebrick3\"))+\n  # scale_y_continuous(labels = scales::label_percent(accuracy = 2))+\ntheme_minimal()\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\n\nall_wwd_reports |&gt;\n  st_drop_geometry() |&gt; \n  count(date(timestamp),day_type,hour,year) |&gt; \n  ggplot(aes(x=factor(hour),y = n,col = day_type))+\n  geom_jitter(alpha = 0.05)+\n  geom_boxplot(alpha = 0.5,outlier.shape = NA)+\n  facet_grid(year~.)+\n  theme_minimal()\n\n\n\n\n\n\n\n\nA check of the reports per day\n\nexp_dates_count &lt;- all_wwd_reports |&gt;\n  st_drop_geometry() |&gt; \n  count(date = date(timestamp)) |&gt; \n  right_join(\n    tibble(date = seq(min(date(all_wwd_reports$date_time)),\n                      max(date(all_wwd_reports$date_time)),\n                      by = \"1 day\")),by = \"date\")\n\nA quick check of the timeline reveals gaps in the reports of 2019. We do not know the causes.\n\nexp_dates_count |&gt; \n  mutate(n = if_else(is.na(n),0,n)) |&gt; \n  ggplot(aes(x = date,y = n))+\n  geom_line()+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nexp_dates_count |&gt; \n  mutate(wday = wday(date,week_start = 2),\n         week = week(date)) |&gt; \n  ggplot(aes(y = factor(wday),x = factor(week),fill = n))+\n  geom_tile()+\n  theme_minimal()+\n  facet_grid(year(date)~.)+\n  scale_fill_viridis_c(direction = -1)\n\n\n\n\n\n\n\n\n\n\nLet us check if there is any patter related to the day of the week\n\nall_wwd_reports |&gt;\n  st_drop_geometry() |&gt; \n  count(date = date(timestamp),year) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = mean(n),.by = c(wday,year)) |&gt; \n  ggplot(aes(x= wday,y = n, col = factor(year)))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\n\n\n\n\n\n\n\nThere seems to be a pattern that might be related to the sampling i.e. how the enforcement officers are assigned along the week.\nLet’s compare with other types of infractions reported by officers\n\nreports2019 |&gt;\n  select(-DES_INFRACCION) |&gt;\n  filter(MEDIO_DETECCION == \"LAPIZ\") |&gt; \n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETECCION,\n         CLASE_VEHICULO,\n         time,\n         INFRACCION) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETECCION,\n         veh_class = CLASE_VEHICULO,\n         offence = INFRACCION) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp)) |&gt; \n  count(date = date(timestamp),offence) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = mean(n),.by = c(wday,offence)) |&gt; \n  filter(sum(n)&gt;250,.by = offence) |&gt; \n  ggplot(aes(x= wday,y = n, col = factor(offence)))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\nWe can also inspect the median number of tickets per weekday for all offences that are reported by traffic management officers in 2019 and 2020\n\nreports2019 |&gt;\n  select(-DES_INFRACCION) |&gt;\n  filter(MEDIO_DETECCION == \"LAPIZ\") |&gt; \n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETECCION,\n         CLASE_VEHICULO,\n         time,\n         INFRACCION) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETECCION,\n         veh_class = CLASE_VEHICULO,\n         offence = INFRACCION) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp)) |&gt; \n  count(date = date(timestamp)) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = mean(n),.by = c(wday)) |&gt; \n  # filter(sum(n)&gt;250,.by = offence) |&gt; \n  ggplot(aes(x= wday,y = n))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\n\nreports2020 |&gt; \n  select(-DES_INFRAC) |&gt;\n  filter(MEDIO_DETE == \"DISPOSITIVOS EN VÍA\") |&gt; \n  mutate(time = hms(HORA_OCURR)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETE,\n         CLASE_VEHI,\n         time,\n         INFRACCION) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETE,\n         veh_class = CLASE_VEHI,\n         offence = INFRACCION) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp)) |&gt; \n  count(date = date(timestamp)) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = mean(n),.by = c(wday)) |&gt; \n  # filter(sum(n)&gt;250,.by = offence) |&gt; \n  ggplot(aes(x= wday,y = n))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `time = hms(HORA_OCURR)`.\nCaused by warning in `.parse_hms()`:\n! Some strings failed to parse\n\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\nIs it a problem with the data, as some months are not reported? Let’s see if the pattern is similar across months\n\nreports2019 |&gt;\n  select(-DES_INFRACCION) |&gt;\n  filter(MEDIO_DETECCION == \"LAPIZ\") |&gt; \n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETECCION,\n         CLASE_VEHICULO,\n         time,\n         INFRACCION) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETECCION,\n         veh_class = CLASE_VEHICULO,\n         offence = INFRACCION) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp),\n         month = month(timestamp)) |&gt; \n  count(date = date(timestamp),month) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = median(n),.by = c(wday,month)) |&gt; \n  # filter(sum(n)&gt;250,.by = offence) |&gt; \n  ggplot(aes(x= wday,y = n,col =  factor(month)))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\n\nreports2020 |&gt; \n  select(-DES_INFRAC) |&gt;\n  filter(MEDIO_DETE == \"DISPOSITIVOS EN VÍA\") |&gt; \n  mutate(time = hms(HORA_OCURR)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETE,\n         CLASE_VEHI,\n         time,\n         INFRACCION) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETE,\n         veh_class = CLASE_VEHI,\n         offence = INFRACCION) |&gt;\n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp),\n         month = month(timestamp)) |&gt; \n  count(date = date(timestamp),month) |&gt; \n  mutate(wday = wday(date,week_start = 2)) |&gt; \n  summarise(n = median(n),.by = c(wday,month)) |&gt; \n  # filter(sum(n)&gt;250,.by = offence) |&gt; \n  ggplot(aes(x= wday,y = n,col =  factor(month)))+\n  geom_line()+\n  scale_x_continuous(breaks = 1:7,\n                     labels = weekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6))+\n  labs(x=\"\")\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `time = hms(HORA_OCURR)`.\nCaused by warning in `.parse_hms()`:\n! Some strings failed to parse\n\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\nVisually, there seems to be a consistent pattern of a low number of reports during friday and saturday, followed by a surge on Sundays."
  },
  {
    "objectID": "C1_infractions.html#spatial-sampling-bias",
    "href": "C1_infractions.html#spatial-sampling-bias",
    "title": "Ticket Data",
    "section": "",
    "text": "Let’s assign all reports to the nearest link to explore where the enforcement offices tend to catch the offenders\n\nnet_bog_2019 &lt;- st_read(file.path(\"sf_network\",\"bogota_osm_network.gpkg\")) |&gt; st_transform(3116)\n\nMultiple layers are present in data source C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg, reading layer `network_2019'.\nUse `st_layers' to list all layer names and their type in a data source.\nSet the `layer' argument in `st_read' to read a particular layer.\n\n\nWarning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, :\nautomatically selected the first layer in a data source containing more than\none.\n\n\nReading layer `network_2019' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 54531 features and 15 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.441 ymin: 4.236862 xmax: -73.72583 ymax: 5.042826\nGeodetic CRS:  MAGNA-SIRGAS\n\n\n\nmajor_network &lt;- net_bog_2019 |&gt; filter(!(highway %in% c(\"residential\",\"unclassified\")))\n\n\nmanual_reports_2019 &lt;- reports2019 |&gt;\n  select(-DES_INFRACCION) |&gt;\n  filter(MEDIO_DETECCION == \"LAPIZ\") |&gt; \n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  select(FECHA_HORA,\n         MEDIO_DETECCION,\n         CLASE_VEHICULO,\n         time,\n         INFRACCION,\n         LONGITUD,LATITUD) |&gt;\n  rename(date_time = FECHA_HORA,\n         detect_device = MEDIO_DETECCION,\n         veh_class = CLASE_VEHICULO,\n         offence = INFRACCION) |&gt; \n  st_as_sf(coords = c(\"LONGITUD\",\"LATITUD\"),crs = 4326) |&gt; \n  st_transform(3116)\n\n\nmanual_reports_2019$near_index &lt;- st_nearest_feature(manual_reports_2019,net_bog_2019)\nmanual_reports_2019$near_major_index &lt;- st_nearest_feature(manual_reports_2019,major_network)\n\n\nmanual_reports_2019$highway &lt;- net_bog_2019$highway[manual_reports_2019$near_index]\nmanual_reports_2019$oneway &lt;- net_bog_2019$oneway[manual_reports_2019$near_index]\n\n\nmanual_reports_2019$dist_to_major &lt;- st_distance(\n  manual_reports_2019,\n  major_network[manual_reports_2019$near_major_index,],\n  by_element = T) |&gt; as.numeric()\n\nType of road where the offence was reported\n\nmanual_reports_2019 |&gt; \n  st_drop_geometry() |&gt; \n  mutate(highway = str_remove(highway,\"_link\")) |&gt; \n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp),\n         month = month(timestamp)) |&gt; \n  count(date = date(timestamp),highway) |&gt; \n  summarise(n = median(n),.by = c(highway)) |&gt; \n  ggplot(aes(x = fct_reorder(highway,n,.desc = F),y = n))+\n  geom_col()+\n  coord_flip()\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\n\nmanual_reports_2019 |&gt; \n  st_drop_geometry() |&gt; \n  mutate(highway = str_remove(highway,\"_link\")) |&gt;\n  mutate(highway = factor(highway,\n                          levels =\n                            c(\"trunk\",\"primary\",\"secondary\",\"tertiary\",\"residential\",\"unclassified\"),\n                          ordered = T)) |&gt; \n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp),\n         month = month(timestamp)) |&gt; \n  count(date = date(timestamp),highway) |&gt; \n  summarise(n = median(n),.by = c(highway)) |&gt;\n  arrange(highway) |&gt; \n  mutate(perc = n/sum(n)) |&gt;\n  # mutate(prev = cumsum(perc)-perc) |&gt; \n  # select(-n) |&gt; \n  # pivot_longer(-highway) |&gt; \n  ggplot(aes(x = 1,y = perc,fill = highway))+\n  geom_col(position = \"stack\")+\n  # scale_alpha_manual(values = c(1,0.2))+\n  coord_flip()+\n  theme_minimal()+\n  scale_y_continuous(labels = scales::label_percent())\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\nMedian daily reports in residential roads\n\nmanual_reports_2019 |&gt; \n  st_drop_geometry() |&gt; \n  mutate(highway = str_remove(highway,\"_link\")) |&gt; \n  mutate(date_time = str_replace(date_time,\"\\\\+00\",\"-05\")) |&gt; \n  mutate(timestamp = ymd_hms(date_time, tz = \"America/Bogota\"),\n         hour = hour(time),\n         year = year(timestamp),\n         month = month(timestamp)) |&gt; \n  filter(highway == \"residential\") |&gt;\n  count(date = date(timestamp),offence) |&gt; \n  summarise(n = median(n),.by = c(offence)) |&gt;\n  slice_max(n,n=15) |&gt; \n  ggplot(aes(x = fct_reorder(offence,n), y = n))+\n  geom_col()+\n  coord_flip()\n\nDate in ISO8601 format; converting timezone from UTC to \"America/Bogota\".\n\n\n\n\n\n\n\n\n\nEuclidean distance to major network vs all reports\n\nggplot()+\n  geom_histogram(data = manual_reports_2019,\n                 aes(dist_to_major),\n                 alpha = 0.1)+\n  geom_histogram(data = manual_reports_2019 |&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\")),\n  aes(dist_to_major),\n  alpha = 0.3,\n  fill = \"dodgerblue4\",\n  col = \"dodgerblue3\")+\n  scale_x_log10()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot()+\n  geom_histogram(data = manual_reports_2019 |&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\")),\n  aes(dist_to_major),\n  alpha = 0.2)+\n  geom_histogram(data = manual_reports_2019 |&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\"),offence == \"D03\"),\n  aes(dist_to_major),\n  alpha = 0.3,\n  fill = \"dodgerblue4\",\n  col = \"dodgerblue3\")+\n  scale_x_sqrt()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nnet_points &lt;- net_bog_2019 |&gt;\n  st_cast(\"POINT\") |&gt;\n  slice_head(by = osm_id)\n\nWarning in st_cast.sf(net_bog_2019, \"POINT\"): repeating attributes for all\nsub-geometries for which they may not be constant\n\nnet_points &lt;- net_bog_2019 |&gt; st_centroid()\n\nWarning: st_centroid assumes attributes are constant over geometries\n\nnet_points$near_id &lt;- st_nearest_feature(net_points,major_network)\nnet_points$dist_to_major &lt;- st_distance(net_points,\n                                        major_network[net_points$near_id,],\n                                        by_element = T) |&gt;\n  as.numeric()\n\n\nggplot()+\n  geom_density(data = net_points|&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\")),\n                 aes(dist_to_major),\n                 alpha = 0.1)+\n  geom_density(data = manual_reports_2019 |&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\"), offence == \"D03\"),\n  aes(dist_to_major),\n  alpha = 0.3,\n  fill = \"dodgerblue4\",\n  col = \"dodgerblue3\")+\n  scale_x_sqrt(breaks = c(0,0.1,0.25,.5,1,2.5,5,7.5,10)*1e3)\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(major_network)+\n  tm_lines()+\n  tm_shape(manual_reports_2019 |&gt; \n  filter(highway %in% c(\"residential\",\"unclassified\"), offence == \"D03\"))+\n  tm_dots(\"dist_to_major\")"
  },
  {
    "objectID": "C1_infractions.html#summary-by-vehicle-type",
    "href": "C1_infractions.html#summary-by-vehicle-type",
    "title": "Ticket Data",
    "section": "",
    "text": "all_wwd_reports |&gt;\n  st_drop_geometry() |&gt;  \n  count(veh_class,year) |&gt; \n  arrange(-n) |&gt; \n  mutate(n = n/sum(n),.by=year) |&gt; \n  ggplot(aes(x = fct_reorder(veh_class,n,.desc = F),  y = n, fill = factor(year)))+\n  geom_col(position = \"dodge\",)+\n  coord_flip()+\n  scale_y_continuous(labels = scales::label_percent())+\n  theme_minimal()+\n  scale_fill_manual(values = c(\"dodgerblue3\",\"firebrick3\"))"
  },
  {
    "objectID": "C1_infractions.html#saving-clean-datasets",
    "href": "C1_infractions.html#saving-clean-datasets",
    "title": "Ticket Data",
    "section": "",
    "text": "st_write(all_wwd_reports,\n         dsn = \"sf_network/wwd_clean_sf.gpkg\",\n         delete_dsn = T)\n\nDeleting source `sf_network/wwd_clean_sf.gpkg' using driver `GPKG'\nWriting layer `wwd_clean_sf' to data source \n  `sf_network/wwd_clean_sf.gpkg' using driver `GPKG'\nWriting 6915 features with 8 fields and geometry type Point."
  },
  {
    "objectID": "B1_speed_data.html",
    "href": "B1_speed_data.html",
    "title": "Speed Data Processing",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"data.table\",\n    \"paletteer\"\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n        sf  tidyverse data.table  paletteer \n      TRUE       TRUE       TRUE       TRUE \n\nsetDTthreads(0)"
  },
  {
    "objectID": "B1_speed_data.html#preliminary-cleaning",
    "href": "B1_speed_data.html#preliminary-cleaning",
    "title": "Speed Data Processing",
    "section": "Preliminary cleaning",
    "text": "Preliminary cleaning\n\nall_data[,\n           INICIO := mdy_hms(INICIO,\n                             tz = \"America/Bogota\")\n         ][,\n           `:=`(year = year(INICIO))\n           ]\n\nNot all links have data for all months. So the first step is to identify the links with enough data per year.\n\nlinks_summary &lt;- unique(\n  all_data[,\n           c(\"TID\",\"year\",\"MES\")])[,\n                                   .(count = .N),\n                                   by = c(\"TID\",\"year\")]\n\n\nlinks_summary |&gt; \n  ggplot(aes(count))+\n  geom_histogram(binwidth = 1)+\n  scale_y_log10()+\n  scale_x_continuous(breaks = 0:12)+\n  facet_grid(year~.)\n\nLinks with data in 5 or more months per year will be used for this analysis.\n\nlinks_data = links_summary[,count := 1*(count&gt;=5)\n                           ][,.(tot_count = sum(count)),\n                             by = \"TID\"][\n                               tot_count == 2,\n                               ] |&gt; pull(TID)\n\nWe extract the data only for these links with the following code and clean the memory:\n\nclean_data &lt;- all_data[TID %in% links_data]\nrm(all_data,links_data,links_summary,lst_files)\ngc()"
  },
  {
    "objectID": "B1_speed_data.html#classifiying-the-data",
    "href": "B1_speed_data.html#classifiying-the-data",
    "title": "Speed Data Processing",
    "section": "Classifiying the data",
    "text": "Classifiying the data\nFirst, we will identify the days that were bank holidays in Colombia\n\nbank_holidays &lt;- read.csv(\"../00_data/bogota/bank_holidays.csv\") |&gt;\n  mutate(bank_holiday = dmy(bank_holiday)) |&gt;\n  pull(bank_holiday)\n\n\nclean_data[date(INICIO) %in% bank_holidays,\n           DIA_SEMANA := \"Festivo\"\n           ]\n\nclean_data[,day_type := fcase(\n             DIA_SEMANA == \"Domingo\",\"weekend\",\n             DIA_SEMANA == \"Sabado\",\"weekend\",\n             DIA_SEMANA == \"Festivo\",\"weekend\",\n             DIA_SEMANA == \"Viernes\",\"friday\",\n             default = \"weekday\")\n             ]\n\nThe following code extracts the 94th percentile of the speeds in each road link.\n\nmax_speeds &lt;- clean_data[,\n                             .(p94_speed = quantile(VEL_PROMEDIO,\n                                                       0.94,\n                                                       na.rm = T)),\n                             by =  c(\"TID\",\"year\")]\n\nNow, we calculate the median hourly speed for each road link by day type and road link.\n\nsummary_speeds &lt;- clean_data[, as.list(summary(VEL_PROMEDIO)),\n  by = .(TID, HORA, day_type, year)]\n\nsetnames(summary_speeds,\n         old = c(\"HORA\",\"Min.\",\"1st Qu.\",\"Median\",\"Mean\",\"3rd Qu.\",\"Max.\"),\n         new = c(\"hour\",\"d_min_speed\",\"d_q1_speed\",\"d_median_speed\",\"d_mean_speed\",\"d_q3_speed\",\"d_max_speed\"))\n\nNow we normalise the values by dividing by the 95th-percentile speed\n\nnorm_summary_spd &lt;- merge(summary_speeds,\n                          max_speeds,\n                          by = c(\"TID\",\"year\"))[,\n                                                d_norm_speed := d_median_speed/p94_speed\n                                                ]\n\n\nfwrite(norm_summary_spd,file = \"sf_network/summary_speeds.csv\")"
  },
  {
    "objectID": "B1_speed_data.html#some-visualisations-of-speed-distribution",
    "href": "B1_speed_data.html#some-visualisations-of-speed-distribution",
    "title": "Speed Data Processing",
    "section": "Some visualisations of speed distribution:",
    "text": "Some visualisations of speed distribution:\n\nHourly distributions\n\nNormalised speed\n\nnorm_summary_spd |&gt; \n  ggplot(aes(x = hour,y = d_norm_speed))+\n  geom_boxplot(aes(group = hour), fill = NA,alpha = 0.3,outlier.shape = NA)+\n  geom_jitter(alpha = 0.3, size = 0.3,col = \"gray60\")+\n  stat_summary(geom = \"line\",\n               fun = \"mean\",\n               aes(col = day_type),\n               linewidth = 1,\n               alpha = 0.6,\n               show.legend = F)+\n  facet_grid(day_type~.)+\n  theme_minimal()+\n  labs(x = \"Hour\", y = \"Norm speed (observed/94th percentile)\")+\n  scale_x_continuous(breaks = 0:23,\n                     labels = sprintf(\"%02d:00\",0:23))+\n  theme(axis.text.x = element_text(angle = 90))+\n  scale_colour_manual(values = paletteer_d(\"ggsci::lanonc_lancet\",n = 3))\n\n\n\n\n\n\n\n\n\n\nAbsolute speed\n\nnorm_summary_spd |&gt; \n  ggplot(aes(x = hour,y = d_median_speed))+\n  geom_boxplot(aes(group = hour), fill = NA,alpha = 0.3,outlier.shape = NA)+\n  geom_jitter(alpha = 0.3, size = 0.3,col = \"gray60\")+\n  stat_summary(geom = \"line\",\n               fun = \"mean\",\n               aes(col = day_type),\n               linewidth = 1,\n               alpha = 0.6,\n               show.legend = F)+\n  facet_grid(day_type~year)+\n  theme_minimal()+\n  labs(x = \"Hour\", y = \"Observed speed\")+\n  scale_x_continuous(breaks = 0:23,\n                     labels = sprintf(\"%02d:00\",0:23))+\n  theme(axis.text.x = element_text(angle = 90))+\n  scale_colour_manual(values = paletteer_d(\"ggsci::lanonc_lancet\",n = 3))\n\n\n\n\n\n\n\n\n\n\n\nDaily profile by Link\n\nNormalised speed\n\nnorm_summary_spd |&gt; \n  ggplot(aes(x = hour,y = d_norm_speed))+\n  # geom_boxplot(aes(group = HORA), fill = NA,alpha = 0.3,outlier.shape = NA)+\n  # geom_jitter(alpha = 0.3, size = 0.3,col = \"gray60\")+\n  stat_summary(geom = \"line\",\n               fun = \"mean\",\n               aes(col = day_type,\n                   group = TID),\n               linewidth = 0.01,\n               alpha = 0.04,\n               # show.legend = F\n               )+\n  facet_grid(day_type~year)+\n  theme_minimal()+\n  labs(x = \"Hour\", y = \"Speed ratio (observed/94th percentile)\")+\n  scale_x_continuous(breaks = 0:23,\n                     labels = sprintf(\"%02d:00\",0:23))+\n  scale_y_continuous(limits = c(0,1.25),breaks = seq(0,1.25,0.25))+\n  scale_colour_manual(values = paletteer_d(\"ggsci::default_nejm\",n = 3))+\n  theme(axis.text.x = element_text(angle = 90),\n        panel.grid.minor = element_blank(),\n        legend.position = \"top\")\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_summary()`).\n\n\n\n\n\n\n\n\n\n\n\nAbsolute speed\n\nnorm_summary_spd |&gt; \n  ggplot(aes(x = hour,y = d_median_speed))+\n  stat_summary(geom = \"line\",\n               fun = \"mean\",\n               aes(col = day_type,\n                   group = TID),\n               linewidth = 0.01,\n               alpha = 0.04,\n               # show.legend = F\n               )+\n  facet_grid(day_type~year)+\n  geom_hline(yintercept = 60,col = \"#EE4C97\",linetype = \"dashed\",alpha = 0.6,linewidth = 1)+\n  annotate(geom = \"text\",x = 23,y = 63,label = \"Speed Limit \",vjust = 0,hjust = 1,face = \"italic\")+\n  theme_minimal()+\n  labs(x = \"Hour\", y = \"Observed speed\")+\n  scale_x_continuous(breaks = 0:23,\n                     labels = sprintf(\"%02d:00\",0:23))+\n  scale_y_continuous(limits = c(0,100),breaks = seq(0,100,20))+\n  scale_colour_manual(values = paletteer_d(\"ggsci::default_nejm\",n = 3))+\n  theme(axis.text.x = element_text(angle = 90),\n        panel.grid.minor = element_blank(),\n        legend.position = \"none\")\n\nWarning in annotate(geom = \"text\", x = 23, y = 63, label = \"Speed Limit \", :\nIgnoring unknown parameters: `face`\n\n\n\n\n\n\n\n\n\nMedian overall speed profile\n\nnorm_summary_spd |&gt; \n  ggplot(aes(x = hour,y = d_norm_speed))+\n  stat_summary(geom = \"line\",\n               fun = \"mean\",\n               aes(col = day_type),\n               linewidth = 1.5,\n               alpha = 0.6,\n               # show.legend = F\n               )+\n  facet_grid(.~year)+\n  theme_minimal()+\n  labs(x = \"Hour\", y = \"Speed ratio (observed/94th percentile)\")+\n  scale_x_continuous(breaks = 0:23,\n                     labels = sprintf(\"%02d:00\",0:23))+\n  scale_y_continuous(limits = c(0,1.25),breaks = seq(0,1.25,0.25))+\n  scale_colour_manual(values = paletteer_d(\"ggsci::default_nejm\",n = 3))+\n  theme(axis.text.x = element_text(angle = 90),\n        panel.grid.minor = element_blank(),\n        legend.position = \"top\")\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_summary()`)."
  },
  {
    "objectID": "B1_speed_data.html#spatial-data",
    "href": "B1_speed_data.html#spatial-data",
    "title": "Speed Data Processing",
    "section": "Spatial data",
    "text": "Spatial data\nUp to this point, all the data processing has not involved the spatial component. On the open data platform, it is possible to download the gpkg files for each month. With the following code, we will identify which file(s) is(are) needed to have all data.\nIdeally, we need a file that contains all 770 TID.\n\nunique(\n  clean_data[,\n           c(\"TID\",\"year\",\"MES\")])[,\n                                   .(count = .N),\n                                   by = c(\"year\",\"MES\")][count == max(count)]\n\n    year      MES count\n   &lt;int&gt;   &lt;char&gt; &lt;int&gt;\n1:  2019 February   767\n\n\nAs the file of February 2019 does not have all the links, we identify alternative files.\n\ntid_feb2019 &lt;- unique(clean_data[year == 2019 & MES == \"February\",\"TID\"])[,1]\ntid_missing &lt;- unique(clean_data[!(TID %in% tid_feb2019$TID),\"TID\"])\n\nunique(\n  clean_data[TID %in% tid_missing$TID,\n           c(\"TID\",\"year\",\"MES\")])[,\n                                   .(count = .N),\n                                   by = c(\"year\",\"MES\")][count == max(count)]\n\n     year       MES count\n    &lt;int&gt;    &lt;char&gt; &lt;int&gt;\n 1:  2020     April     3\n 2:  2019    August     3\n 3:  2020    August     3\n 4:  2019  December     3\n 5:  2020  December     3\n 6:  2020   January     3\n 7:  2020  February     3\n 8:  2019      July     3\n 9:  2020      July     3\n10:  2020      June     3\n11:  2020     March     3\n12:  2020       May     3\n13:  2019  November     3\n14:  2020  November     3\n15:  2019   October     3\n16:  2020   October     3\n17:  2019 September     3\n18:  2020 September     3\n\n\nThe files for February 2019 and October 2020 have been downloaded manually from the same source. As we are only interested in the geometries, we filter out all the other data.\n\nsf_feb2019&lt;- st_read(\n   \"../00_data/bogota/speed_data/Velocidades_Bitcarrier_Febrero_2019_1361955177739874723.gpkg\",\n   query=\"select TID,SHAPE from 'Velocidades_Bitcarrier_Febrero_2019'\"\n   ) |&gt;\n  filter(TID %in% tid_feb2019$TID) |&gt; select(TID) |&gt; slice_head(n = 1,by = TID)\n\nReading query `select TID,SHAPE from 'Velocidades_Bitcarrier_Febrero_2019''\nfrom data source `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\00_data\\bogota\\speed_data\\Velocidades_Bitcarrier_Febrero_2019_1361955177739874723.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1930309 features and 1 field\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: -74.18353 ymin: 5.684342e-14 xmax: 1 ymax: 4.764635\nGeodetic CRS:  MAGNA-SIRGAS\n\nsf_oct2020 &lt;- st_read(\n  \"../00_data/bogota/speed_data/Velocidades_Bitcarrier_Octubre_2020_-1518838627102027019.gpkg\",\n  query=\"select TID,SHAPE from 'Velocidades_Bitcarrier_Octubre_2020'\") |&gt;\n  filter(TID %in% tid_missing$TID) |&gt; slice_head(n = 1,by = TID)\n\nReading query `select TID,SHAPE from 'Velocidades_Bitcarrier_Octubre_2020''\nfrom data source `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\00_data\\bogota\\speed_data\\Velocidades_Bitcarrier_Octubre_2020_-1518838627102027019.gpkg' \n  using driver `GPKG'\nSimple feature collection with 2325212 features and 1 field\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: -74.20333 ymin: 5.684342e-14 xmax: 1 ymax: 4.764635\nGeodetic CRS:  MAGNA-SIRGAS\n\n\n\nsf_speed &lt;- bind_rows(sf_feb2019,sf_oct2020)\nrm(sf_feb2019,sf_oct2020)\ngc()\n\n            used   (Mb) gc trigger    (Mb)   max used    (Mb)\nNcells   1616359   86.4   30050334  1604.9   37562917  2006.1\nVcells 837892044 6392.7 1428722601 10900.3 1427163610 10888.4\n\n\nThe elements in the spatial objects contain MULTILINESTRINGS which cover long sections of the main corridors. Before saving the results, we will cast all features as LINESTRING to ease the process of working out a correspondence with the OSM network.\n\nsf_speed_cast &lt;- sf_speed |&gt; st_cast(\"LINESTRING\")\n\nWarning in st_cast.sf(sf_speed, \"LINESTRING\"): repeating attributes for all\nsub-geometries for which they may not be constant\n\n\nSaving the network\n\nst_write(sf_speed_cast,dsn = \"sf_network/sf_speed_network.gpkg\",delete_dsn = T)\n\nDeleting source `sf_network/sf_speed_network.gpkg' using driver `GPKG'\nWriting layer `sf_speed_network' to data source \n  `sf_network/sf_speed_network.gpkg' using driver `GPKG'\nWriting 1267 features with 1 fields and geometry type Line String.\n\n\n\nurban_perimeter &lt;- st_read(\"raw_data/perimetrourbano.gpkg\")\n\nReading layer `PerimetroUrbano' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\raw_data\\perimetrourbano.gpkg' \n  using driver `GPKG'\n\n\nWarning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : GDAL\nMessage 1: Non-conformant content for record 1 in column\nFECHA_ACTO_ADMINISTRATIVO, 2021-12-29T00:00:00.0Z, successfully parsed\n\n\nSimple feature collection with 3 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.22358 ymin: 4.468614 xmax: -74.01206 ymax: 4.830661\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nA quick visualisation of the maximum speeds in 2019:\n\nsf_speed_cast[urban_perimeter,] |&gt; \n  left_join(max_speeds |&gt; filter(year==2019), by = \"TID\") |&gt; \n  ggplot()+\n  geom_sf(aes(col = p94_speed),linewidth = 0.3,alpha = 0.7)+\n  scale_color_gradientn(colours = paletteer_c(\"grDevices::Plasma\", 30))+\n  theme_void()+\n  facet_grid(.~year)"
  }
]