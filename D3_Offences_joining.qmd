---
editor: 
  markdown: 
    wrap: 72
---

# Joining the WWD reports

```{r,message=FALSE}
#| label: libraries
#| message: false

options(repos = c(CRAN = "https://cloud.r-project.org"))
if (!require("remotes")) install.packages("remotes")
pkgs = c(
    "sf",
    "tidyverse",
    "zonebuilder",
    "tmap",
    "ggExtra",
    "effectsize"
    # "dodgr" # Using the developer version of dodgr
)
remotes::install_cran(pkgs)
sapply(pkgs, require, character.only = TRUE)
```

## Loading data

```{r}
#| label: zone4clipping

bog_zone <- zonebuilder::zb_zone("Bogota",
                                 n_circles = 2) |> 
  st_transform(3116)
# zb_view(bog_zone)
```

### Offence reports (tickets)

```{r}
# off_sf_all <- st_read("sf_network/wwd_clean_sf.gpkg")
off_sf_all <- st_read("sf_network/manualtickets_clean_sf.gpkg")
```

### Network

```{r}
sf_net <- st_read("sf_network/small_sf_network.gpkg")
```

### Centrality results

```{r}
cent_tests <- read_csv("sf_network/cent_tests.csv",
                       lazy = F)

cent_tests_wkend <- read_csv("sf_network/cent_tests_wkend.csv",
                             lazy = F)
```

### Assigning reports to the network

We need to assign the reports to the network. As we are interested in
the residential roads, any bi-directional road is represented in the
`sf` object as two `LINESTRING` objects. Since we do not have
information to know which specific direction the reports correspond to,
we will need to simplify the spatial object. Our target variable is the
betweenness centrality, so we are going to keep the two centrality
values for each bi-directional element.

First, we will create a subset of the `residential` and `unclassified`
roads, and another with all other roads

```{r}
subset_net <- sf_net |> 
  filter(roadclass %in% c(
    "residential",
    "unclassified"
    )) |> 
  st_transform(3116)
```

```{r}
major_net <- sf_net |> 
  filter(!roadclass %in% c(
    "residential",
    "unclassified"
    )) |> 
  st_transform(3116)
```

From this subset, we first find the pairs of links with the
`st_contains` function.

```{r}
simplifed_net_indexes <- lapply(st_contains(subset_net,subset_net),
            \(x){
              x[order(x)]
}) |> unique()
```

Each pair is then assigned a unique id.

```{r}
simp_groups <- do.call(bind_rows,
        lapply(seq_along(simplifed_net_indexes),
               \(i){
                 tibble(id = simplifed_net_indexes[[i]],
                        pair_id = i)
               })) |> 
  arrange(id)


subset_net$pair_id <- simp_groups$pair_id
```

Using the `pair_id` we extract the minimum, maximum and average change
in centrality for each pair.

```{r}
summary_pairs <- cent_tests |> 
  right_join(subset_net |>
               st_drop_geometry() |>
               select(edge_id,way_id,pair_id),
            by = "edge_id") |> 
  # # Filtering only the links that were inverted during the network creation and standard links
  # filter(!any(str_detect(way_id,"r$"))|str_detect(way_id,"r$"),.by = pair_id) |>
  summarise(across(diff:logreldiff.ff,
                   list(min=min, max=max, avg = mean)),
            .by = c(pair_id,wwd.speed,dist.th))

summary_pairs_wkend <- cent_tests_wkend |> 
  right_join(subset_net |>
               st_drop_geometry() |>
               select(edge_id,way_id,pair_id),
            by = "edge_id") |> 
  # # Filtering only the links that were inverted during the network creation and standard links
  # filter(!any(str_detect(way_id,"r$"))|str_detect(way_id,"r$"),.by = pair_id) |>
  summarise(across(diff:logreldiff.ff,
                   list(min=min, max=max, avg = mean)),
            .by = c(pair_id,wwd.speed,dist.th))
```

```{r}
summary_pairs_dist.jct <- 
  subset_net |>
  st_drop_geometry() |>
  summarise(across(dist.jct,\(x) mean(x) |> round()),
            .by = c(pair_id))
```

A simplified version of the `sf` object is produced extracting the first
element of each pair, we will discard columns with the centrality
metrics from this object to avoid confusion

```{r}
# simpl_network_sf <- subset_net[vapply(simplifed_net_indexes,\(x) x[1],numeric(1)),] |> select(lanes:component,pair_id)

simpl_network_sf <- subset_net |>
  # # Filtering only the links that were inverted during the network creation and standard links
  # filter(!any(str_detect(way_id,"r$"))|str_detect(way_id,"r$"),
  #        .by = pair_id) |>
  slice_head(n = 1,by = pair_id) |>
  select(lanes:component,pair_id)
```

We are interested in the reports on residential and unclassified
streets. For this, we will create two buffers from the subsets created
before. It is uncertain how thecoordinates of each report are recorded,
there might be some error associated with the use of GPS devices, and
also, some uncertainty in the way the officers do it.

```{r}
anti_buffer <- major_net |>
  st_union() |> 
  st_buffer(10,endCapStyle = "FLAT")
```

```{r}
subset_buffer <- simpl_network_sf |> 
  st_union()  |> 
  st_buffer(15,endCapStyle = "FLAT")
```

As some reports might be associated to the major network, we will first
filter reports within 10 meters from a major road, so these do not get
wrongly assigned to a minor road. We are also going to subset reports during
the morning peak hour (+/- 2 hours) in 2019.

```{r}
off_sf <- (off_sf_all |>
                 filter(abs(hour - 9)<=2,
                        year == 2019,
                        day_type == "weekday") |>
                 st_transform(3116))[bog_zone,][anti_buffer,,op = st_disjoint]

off_sf_wkend <- (off_sf_all |>
                 filter(abs(hour - 9)<=2,
                        year == 2019,
                        day_type == "weekend") |>
                 st_transform(3116))[bog_zone,][anti_buffer,,op = st_disjoint]
```

The offences that are assumed to happen in the minor offences are assumed to
be within 20 meters.

```{r}
minor_offences <- off_sf[subset_buffer,,op = st_intersects]
minor_offences_wkend <- off_sf_wkend[subset_buffer,,op = st_intersects]
```

```{r}
# tmap_mode("view")
tm_shape(anti_buffer)+
  tm_polygons("gray60",alpha = 0.6)+
  tm_shape(subset_buffer)+
  tm_polygons("blue",alpha = 0.6)+
  tm_shape(minor_offences)+
  tm_dots()
```

### Finding the closest element of the network

```{r}
minor_offences$near_index <- st_nearest_feature(minor_offences,simpl_network_sf)
minor_offences$pair_id <- simpl_network_sf$pair_id[minor_offences$near_index]

minor_offences_wkend$near_index <- st_nearest_feature(minor_offences_wkend,simpl_network_sf)
minor_offences_wkend$pair_id <- simpl_network_sf$pair_id[minor_offences_wkend$near_index]
```

### Exploring preliminary results

```{r}
simpl_network_sf |>
  st_drop_geometry() |> 
  filter(pair_id %in% minor_offences$pair_id) |> 
  ggplot(aes(oneway))+
  geom_bar()
```

```{r}
simpl_network_sf |> 
  ggplot(aes(col = oneway))+
  geom_sf()+
  theme_void()
```

The following plot compares the cumulative probability of distance to
the major network looking for a sampling bias

```{r}
simpl_network_sf |>
  left_join(summary_pairs_dist.jct, by = "pair_id") |> 
  mutate(offence_bool = pair_id %in% minor_offences$pair_id) |>
  st_drop_geometry() |> 
  ggplot(aes(dist.jct,col = offence_bool))+
  stat_ecdf(alpha = 0.7)+
  theme_minimal()
```

The following produces a histogram with the distribution

```{r}
simpl_network_sf |> 
  filter(oneway) |> 
  left_join(summary_pairs_dist.jct, by = "pair_id") |> 
  mutate(offence_bool = pair_id %in% minor_offences$pair_id) |>
  st_drop_geometry() |> 
  ggplot(aes(dist.jct, fill = offence_bool))+
  geom_histogram(alpha = 0.7,col="white")+
  theme_minimal()
```

Let's try see if a naive logistic regression can be fit with the data.
For this, we subset the data for one-way links

```{r}
model_data <- (summary_pairs |>
  semi_join(simpl_network_sf[bog_zone,],
            by = "pair_id")) |> 
  mutate(offence_bool = pair_id %in% minor_offences$pair_id) |> 
  left_join(summary_pairs_dist.jct,by = join_by(pair_id))

model_data_wkend <- (summary_pairs_wkend |>
  semi_join(simpl_network_sf[bog_zone,],
            by = "pair_id")) |> 
  mutate(offence_bool = pair_id %in% minor_offences_wkend$pair_id) |> 
  left_join(summary_pairs_dist.jct,by = join_by(pair_id))
```

A jitter plot to explore the distribution

```{r}
## Congested
model_data |> 
  filter(wwd.speed == 9, dist.th == 1140) |> 
  ggplot(aes(x = (reldiff_max),y = offence_bool))+
    geom_jitter(alpha = 0.1)+
  theme_minimal()


## Weekend
model_data_wkend |> 
  filter(wwd.speed == 9, dist.th == 1140) |> 
  ggplot(aes(x = (reldiff_max),y = offence_bool))+
    geom_jitter(alpha = 0.1)+
  theme_minimal()
```

Distribution of average relative change for the data

```{r}
model_data |> 
    filter(wwd.speed == 9, dist.th == 1140) |> 
  ggplot(aes(x = (reldiff_max),fill = offence_bool))+
  geom_histogram(alpha = 0.4)+
  theme_minimal()
```

Some OSM links have been split, so we will simplify the data by
summarising the results by OSM way id

```{r}
test1 <- model_data |>
  filter(wwd.speed == 9, dist.th == 1140) |>
  left_join(simpl_network_sf |>
              st_drop_geometry() |> 
              select(pair_id,way_id),
            by = "pair_id") |> 
  group_by(way_id) |> 
  summarise(across(c(diff_max,reldiff_max,logdiff_max),
                   \(x) mean(x,na.rm = T)),
            across(offence_bool,\(x) sum(x)>=1))

test1_wkend <- model_data_wkend |>
  filter(wwd.speed == 9, dist.th == 1140) |>
  left_join(simpl_network_sf |>
              st_drop_geometry() |> 
              select(pair_id,way_id),
            by = "pair_id") |> 
  group_by(way_id) |> 
  summarise(across(c(diff_max,reldiff_max,logdiff_max),
                   \(x) mean(x,na.rm = T)),
            across(offence_bool,\(x) sum(x)>=1))

```

The following code shows how a logistic regression fits the data in one of the scenarios.
Unfortunately, the *false positives* do have a significant impact.

```{r}
test1 |>
  mutate(offence_bool = if_else(offence_bool,1,0)) |> 
  ggplot(aes(x = (reldiff_max),y = offence_bool))+
    geom_point(alpha = 0.1)+
  theme_minimal()+
  geom_smooth(method = "glm",
              formula = y ~ x,
              method.args=list(family="binomial"),se = F)
```

```{r}
test1_wkend |>
  mutate(offence_bool = if_else(offence_bool,1,0)) |> 
  ggplot(aes(x = (reldiff_max),y = offence_bool))+
    geom_point(alpha = 0.1)+
  theme_minimal()+
  geom_smooth(method = "glm",
              formula = y ~ x,
              method.args=list(family="binomial"),se = F)
```

```{r}
test1 |>
  mutate(offence_bool = if_else(offence_bool,1,0)) |> 
  ggplot(aes(x = (logdiff_max),
             y = offence_bool))+
    geom_point(alpha = 0.1)+
  theme_minimal()+
  geom_smooth(method = "glm",
              formula = y ~ x,
              method.args=list(family="binomial"),se = F)

test1_wkend |>
  mutate(offence_bool = if_else(offence_bool,1,0)) |> 
  ggplot(aes(x = (logdiff_max),
             y = offence_bool))+
    geom_point(alpha = 0.1)+
  theme_minimal()+
  geom_smooth(method = "glm",
              formula = y ~ x,
              method.args=list(family="binomial"),se = F)
```


#### Fitting logisting regressions 

```{r}
glm_models_0 <- model_data |> 
  nest(data = c(pair_id,
                diff_min:dist.jct)) |> 
  mutate(
    model_rel = map(data,
                \(.x) {
                 glm(offence_bool ~ logdiff_max,
                     data = .x,
                     family = binomial(link = "logit"))
                # },
                # model_abs = map(data,
                # \(.x) {
                #  glm(p ~ logdiff_max,
                #      data = .x,
                #      family = binomial(link = "logit"))
                }
                )
                )


mod_pred_0 <- glm_models_0 |> 
  mutate(predicted = map2(model_rel, data ,\(.x,.y) {
    tibble(logdiff_max = .y$logdiff_max,
           offence_bool = predict(.x,
                                  newdata = .y,
                                  type = "response"))
    })) |> 
  select(-data,-model_rel) |> 
  unnest(cols = predicted) |> 
  unite("id",wwd.speed:dist.th,remove = F) |> unique()
```

```{r}
glm_models_0_wkend <- model_data_wkend |> 
  nest(data = c(pair_id,
                diff_min:dist.jct)) |> 
  mutate(
    model_rel = map(data,
                \(.x) {
                 glm(offence_bool ~ 1,
                     data = .x,
                     family = binomial(link = "logit"))
                # },
                # model_abs = map(data,
                # \(.x) {
                #  glm(p ~ logdiff_max,
                #      data = .x,
                #      family = binomial(link = "logit"))
                }
                )
                )


mod_pred_0_wkend <- glm_models_0_wkend |> 
  mutate(predicted = map2(model_rel, data ,\(.x,.y) {
    tibble(logdiff_max = .y$logdiff_max,
           offence_bool = predict(.x,
                                  newdata = .y,
                                  type = "response"))
  })) |> 
  select(-data,-model_rel) |> 
  unnest(cols = predicted) |> 
  unite("id",wwd.speed:dist.th,remove = F) |> unique()
```

A visual of the fitted lines

```{r}
mod_pred_0 |> 
  ggplot(aes(x = logdiff_max,
             y = offence_bool,
             group = id,
             col = wwd.speed))+
  geom_line(alpha = 0.1)+
  scale_y_continuous(limits = c(0,1))+
  theme_minimal()+
  scale_color_viridis_c(option = "plasma")

mod_pred_0_wkend |> 
  ggplot(aes(x = logdiff_max,
             y = offence_bool,
             group = id,
             col = wwd.speed))+
  geom_line(alpha = 0.1)+
  scale_y_continuous(limits = c(0,1))+
  theme_minimal()+
  scale_color_viridis_c(option = "plasma")
```


#### Calculating Risk-ratios

```{r}
mod_0_coefs <- glm_models_0 |> 
  mutate(coefs = map(model_rel,\(.x) {
    broom::tidy(.x)
  }
  )
  ) |>
  select(wwd.speed,dist.th,coefs) |> 
  unnest(coefs) |> 
  # pivot_wider(names_from = term,values_from = estimate) |> 
  mutate(term = term |> str_replace(pattern = "\\(Intercept\\)",replacement = "intercept"),
         term = term |> str_replace(pattern = "logdiff_max",replacement = "slope"))

mod_0_coefs_wkend <- glm_models_0_wkend |> 
  mutate(coefs = map(model_rel,\(.x) {
    broom::tidy(.x)
  }
  )
  ) |>
  select(wwd.speed,dist.th,coefs) |> 
  unnest(coefs) |> 
  # pivot_wider(names_from = term,values_from = estimate) |> 
  mutate(term = term |> str_replace(pattern = "\\(Intercept\\)",replacement = "intercept"),
         term = term |> str_replace(pattern = "logdiff_max",replacement = "slope"))
```



```{r}
control_rates <- mod_0_coefs_wkend |> 
  filter(term == "intercept") |> 
  mutate(p0 = exp(estimate)) |> 
  select(wwd.speed:dist.th,p0)


oddsratio_to_riskratio(glm_models_0$model_rel[[1]])

RR_summary <-mod_0_coefs |> 
  filter(term == "slope") |>
  left_join(control_rates,
            by = join_by(wwd.speed, dist.th)
            ) |> 
  mutate(OR = exp(estimate),
         RR = OR / (1 - p0 + (p0 * OR)),         #risk ratios: RR = OR / (1 - p + (p x OR))
         e.value = case_when(
           RR >= 1 ~ RR + sqrt(RR * (RR - 1)),
           RR < 1 ~ RR ^ (-1) + sqrt(RR ^ (-1)*(RR^(-1)-1))))
```

```{r}
RR_summary |> 
  ggplot(aes(x = RR, y = dist.th, col =wwd.speed))+
  # geom_vline(xintercept = 0,linetype = "dashed",col= "gray70")+
  geom_point()+
  # coord_fixed()+
  theme_minimal()+
  labs(y="")
  theme(axis.text.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
        )
```

### Reducing the bias of pseudo-negatives by random sampling

```{r}
model_reports <- model_data |>
  filter(offence_bool)


rand_absences_data <- bind_rows(
  model_reports,
  model_data |>
    filter(!offence_bool) |>
    sample_n(size = nrow(model_reports), replace = F)
)


# Same links are considered
rand_absences_data_wkend <- model_data_wkend |> 
  semi_join(rand_absences_data,by = join_by(pair_id,wwd.speed,dist.th))

```


```{r}
glm_models_0_rand <- rand_absences_data |> 
  nest(data = c(pair_id,
                diff_min:dist.jct)) |> 
  mutate(
    model_rel = map(data,
                \(.x) {
                 glm(offence_bool ~ logdiff_max,
                     data = .x,
                     family = binomial(link = "logit"))
                # },
                # model_abs = map(data,
                # \(.x) {
                #  glm(p ~ logdiff_max,
                #      data = .x,
                #      family = binomial(link = "logit"))
                }
                )
                )


mod_pred_0_rand <- glm_models_0_rand |> 
  mutate(predicted = map2(model_rel, data ,\(.x,.y) {
    tibble(logdiff_max = .y$logdiff_max,
           offence_bool = predict(.x,
                                  newdata = .y,
                                  type = "response"))
    })) |> 
  select(-data,-model_rel) |> 
  unnest(cols = predicted) |> 
  unite("id",wwd.speed:dist.th,remove = F) |> unique()


glm_models_0_rand_wkend <- rand_absences_data_wkend |> 
  nest(data = c(pair_id,
                diff_min:dist.jct)) |> 
  mutate(
    model_rel = map(data,
                \(.x) {
                 glm(offence_bool ~ 1,
                     data = .x,
                     family = binomial(link = "logit"))
                # },
                # model_abs = map(data,
                # \(.x) {
                #  glm(p ~ logdiff_max,
                #      data = .x,
                #      family = binomial(link = "logit"))
                }
                )
                )


mod_pred_0_rand_wkend <- glm_models_0_rand_wkend |> 
  mutate(predicted = map2(model_rel, data ,\(.x,.y) {
    tibble(logdiff_max = .y$logdiff_max,
           offence_bool = predict(.x,
                                  newdata = .y,
                                  type = "response"))
    })) |> 
  select(-data,-model_rel) |> 
  unnest(cols = predicted) |> 
  unite("id",wwd.speed:dist.th,remove = F) |> unique()
```


```{r}
mod_pred_0_rand |>
  filter(wwd.speed == 12) |>
  ggplot(aes(
    x = logdiff_max,
    y = offence_bool,
    group = id,
    col = dist.th
  )) +
  geom_line(alpha = 0.3) +
  geom_line(
    data = mod_pred_0_rand_wkend |>
      filter(wwd.speed == 12),
    linetype = "dashed",
    alpha = 0.6
  ) +
  scale_y_continuous(limits = c(0, 1)) +
  theme_minimal() +
  scale_color_viridis_c(option = "plasma")
```

#### Calculating Risk-ratios

```{r}
mod_0_coefs_rand <- glm_models_0_rand |> 
  mutate(coefs = map(model_rel,\(.x) {
    broom::tidy(.x)
  }
  )
  ) |>
  select(wwd.speed,dist.th,coefs) |> 
  unnest(coefs) |> 
  # pivot_wider(names_from = term,values_from = estimate) |> 
  mutate(term = term |> str_replace(pattern = "\\(Intercept\\)",replacement = "intercept"),
         term = term |> str_replace(pattern = "logdiff_max",replacement = "slope"))

control_rates_rand <- glm_models_0_rand_wkend |> 
  mutate(coefs = map(model_rel,\(.x) {
    broom::tidy(.x)
  }
  )
  ) |>
  select(wwd.speed,dist.th,coefs) |> 
  unnest(coefs) |> 
  # pivot_wider(names_from = term,values_from = estimate) |> 
  mutate(term = term |> str_replace(pattern = "\\(Intercept\\)",replacement = "intercept"),
         term = term |> str_replace(pattern = "logdiff_max",replacement = "slope")) |> 
  filter(term == "intercept") |> 
  mutate(p0 = exp(estimate)) |> 
  select(wwd.speed:dist.th,p0)
```


```{r}

RR_summary_rand <- mod_0_coefs_rand |> 
  filter(term == "slope") |>
  left_join(control_rates_rand,
            by = join_by(wwd.speed, dist.th)
            ) |> 
  mutate(OR = exp(estimate),
         RR = OR / (1 - p0 + (p0 * OR)),         #risk ratios: RR = OR / (1 - p + (p x OR))
         e.value = case_when(
           RR >= 1 ~ RR + sqrt(RR * (RR - 1)),
           RR < 1 ~ RR ^ (-1) + sqrt(RR ^ (-1)*(RR^(-1)-1))))
```

```{r}
RR_summary_rand |> 
  ggplot(aes(y = RR, x = e.value, col = dist.th))+
  # geom_vline(xintercept = 0,linetype = "dashed",col= "gray70")+
  geom_point()+
  # coord_fixed()+
  theme_minimal()+
  labs(y="E-value")
  theme(axis.text.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
        )
```


### Filling the reports to adjacent links

```{r}
subset_net_offence <- subset_net |> 
  # left_join(summary_pairs,
  #           by = "pair_id") |> 
  mutate(offence_bool = pair_id %in% minor_offences$pair_id)
```

Let's take one link with a wwd report

```{r}
sample_offence <- subset_net_offence |> filter(offence_bool) |> slice_head(n=1)
```

```{r}
buf_sample <- sample_offence |> st_buffer(500)
```

```{r}
net_sample <- subset_net_offence[buf_sample,]

net_sample |> 
  tm_shape()+tm_lines("gray80")+
  tm_shape(sample_offence)+tm_lines("dodgerblue")
```

```{r}
fill_probs <- function(edges_df,
                       direction = c("1","-1")
                       ) {
  
  direction = match.arg(direction)

    if (direction == "1") {
      do.call(bind_rows, lapply(1:nrow(edges_df), \(j) {
        subset_net_offence |>
          st_drop_geometry() |>
          select(from_id, to_id) |>
          filter(to_id == edges_df$from_id[j],
                 from_id != edges_df$to_id[j]) |>
          mutate(p = edges_df$p[j] / n())
      }))
  } else {
    do.call(bind_rows, lapply(1:nrow(edges_df), \(j) {
      subset_net_offence |>
        st_drop_geometry() |>
        select(from_id, to_id) |>
        filter(from_id == edges_df$to_id[j],
               to_id != edges_df$from_id[j]) |>
        mutate(p = edges_df$p[j] / n())
    }))
    
  }
}


expand_reports <- function(
    df,
    max_degree = 6
) {
  
  check0 <- df |>
    st_drop_geometry() |>
    select(from_id, to_id) |>
    mutate(p = 1)
  
  check <- list()
  check[[1]] <- fill_probs(check0)
  for (i in 2:max_degree) {
    if (nrow(check[[i-1]]) < 1) break
    check[[i]] <- fill_probs(check[[i - 1]])
  }
  
  checkr <- list()
  checkr[[1]] <- fill_probs(check0, direction = "-1")
  for (i in 2:max_degree) {
    if (nrow(checkr[[i - 1]]) < 1) break
    checkr[[i]] <- fill_probs(checkr[[i - 1]], direction = "-1")
  }
  
  ckeck_df <- bind_rows(check0, do.call(bind_rows, check), do.call(bind_rows, checkr)) |>
    summarise(across(p, max), .by = c(from_id, to_id))
  return(ckeck_df)
}

```

```{r}
sample_exp <- expand_reports(df = sample_offence)
```

```{r}
net_sample |> 
  left_join(sample_exp,
            by = join_by(from_id,to_id)) |> 
  tm_shape()+
  tm_lines("p",lwd = 2,alpha = 0.5)
```




#### Applying to the whole network

```{r}
#| label: fill-probs
#| eval: false

full_exp <- subset_net_offence |> filter(offence_bool) |> expand_reports()
```

```{r}
#| label: save-probs
#| eval: false
#| include: false

write_csv(full_exp,"sf_network/filled_probabilities.csv")
```

```{r}
#| include: false

full_exp <- read_csv("sf_network/filled_probabilities.csv",
                     col_types = 
                       cols(from_id = col_character(),
                            to_id = col_character(),
                            p = col_double()))
```

```{r}
summary_probs_adj <- subset_net_offence |>
  st_drop_geometry() |>
  left_join(full_exp,
            by = join_by(from_id, to_id)) |>
  mutate(p = if_else(is.na(p),0,p)) |> 
  # Filtering only the links that were inverted during the network creation and standard links
  # filter(!any(str_detect(way_id,"r$"))|str_detect(way_id,"r$"),.by = pair_id) |> 
  summarise(across(p,\(x) sum(x,na.rm = T)),
            .by = pair_id) |>
  mutate(p = if_else(p>1,1,p)) |> 
  left_join(summary_pairs_dist.jct,by = join_by(pair_id))
  
```

```{r}
net_offence_p <- simpl_network_sf[bog_zone,] |>
  left_join(summary_probs_adj,
            by = "pair_id")
```

```{r}
tm_shape(net_offence_p)+
  tm_lines("p",style = "fisher")
```

```{r}
# tmap_mode("view")

net_offence_p |> 
  left_join(summary_pairs,
            by = join_by(pair_id)) |> 
  filter(wwd.speed==6,dist.th == 1140) |> 
  tm_shape()+
  tm_lines("logdiff_max",
           style = "fisher")+
  tm_shape(minor_offences)+
  tm_dots()
```

```{r}
adjusted_probs_model_data <- 
  summary_pairs |> 
  right_join(net_offence_p |> 
              st_drop_geometry(),
            by = join_by(pair_id))
```

```{r}
adjusted_probs_model_data|>
  filter(wwd.speed == 6, dist.th == 1140) |>
  ggplot(aes(x = reldiff_avg,
             y = p))+
    geom_point(alpha = 0.1)+
  theme_minimal()+
  geom_smooth(method = "glm",
              formula = y ~ x,
              method.args=list(family="quasibinomial"),se = F)
```

```{r}
adjusted_probs_model_data|>
  filter(wwd.speed == 6, dist.th == 1140) |>
  ggplot(aes(x = dist.jct,
             y = p))+
    geom_point(alpha = 0.1)+
  theme_minimal()+
  geom_smooth(method = "glm",
              formula = y ~ x,
              family = "binomial",
              method.args=list(family="binomial"),se = F)
```

#### Fitting GLM with adjusted probabilities

```{r}
glm_models_probs <- adjusted_probs_model_data |> 
  nest(data = c(pair_id,
                diff_min:dist.jct)) |> 
  mutate(
    model_rel = map(data,
                \(.x) {
                 glm(p ~ reldiff_max,
                     data = .x,
                     family = quasibinomial(link = "logit"))
                # },
                # model_abs = map(data,
                # \(.x) {
                #  glm(p ~ logdiff_max,
                #      data = .x,
                #      family = binomial(link = "logit"))
                }
                )
                )


mod_pred <- glm_models_probs |> 
  mutate(predicted = map2(model_rel, data ,\(.x,.y) {
    tibble(reldiff_max = .y$reldiff_max,
      p = predict(.x, newdata = .y,type = "response"))
  })) |> 
  select(-data,-model_rel) |> 
  unnest(cols = predicted) |> 
  unite("id",wwd.speed:dist.th,remove = F) |> unique()

```

A visual of the fitted lines

```{r}
mod_pred |> 
  ggplot(aes(x = reldiff_max,y = p,group = id, col = wwd.speed))+
  geom_line(alpha = 0.1)+
  scale_y_continuous(limits = c(0,1))+
  theme_minimal()+
  scale_color_viridis_c(option = "plasma")
```


A visual exploration of the coefficients

```{r}
mod_coefs <- glm_models_probs |> 
  mutate(coefs = map(model_rel,\(.x) {
    broom::tidy(.x)
  }
  )
  ) |>
  select(wwd.speed,dist.th,coefs) |> 
  unnest(coefs) |> 
  # pivot_wider(names_from = term,values_from = estimate) |> 
  mutate(term = term |> str_replace(pattern = "\\(Intercept\\)",replacement = "intercept"),
         term = term |> str_replace(pattern = "reldiff_max",replacement = "slope"))

```

```{r}
mod_coefs |> 
  filter(term == "slope") |> 
ggplot(aes(x = wwd.speed,
           y = estimate,
           # col = wwd.speed,
           col = dist.th
           ))+
  geom_line(aes(group = dist.th))+
  geom_point(aes(size = p.value),alpha = 0.3)+
  theme_minimal()+
  scale_color_viridis_b(option = "plasma")+
  scale_size_binned(transform = "reciprocal")

mod_coefs |> 
  filter(term == "slope") |> 
ggplot(aes(x = dist.th,
           y = estimate,
           col = wwd.speed,
           # col = dist.th
           ))+
  geom_line(aes(group = wwd.speed))+
  geom_point(aes(size = p.value),alpha = 0.3)+
  theme_minimal()+
  scale_color_viridis_b(option = "plasma")+
  scale_size_binned(transform = "reciprocal")
```

```{r}
mod_coefs |> 
  filter(term == "intercept") |> 
ggplot(aes(x = dist.th,
           y = estimate,
           col = wwd.speed,
           # col = dist.th,
           ))+
  geom_line(aes(group = wwd.speed),alpha = 0.2)+
  geom_point(aes(size = std.error),alpha = 0.4)+
  theme_minimal()+
  scale_color_viridis_b(option = "A")+
  scale_size_binned(transform = "reciprocal")
```

```{r}
# p <- mod_coefs |> 
#   
#   
# ggplot(aes(x = intercept,y = slope,col = wwd.speed, alpha = dist.th))+
#   geom_point()+
#   theme_minimal()+
#   scale_color_viridis_b(option = "plasma")
# 
#   ggMarginal(p,type = "histogram")
#   
  
```


