[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rat-runs",
    "section": "",
    "text": "Rat-runs in Bogota\n\nNetwork data\n\nOSM\nIDECA malla vial integral\n\n\n\nInfractions data\n\n\nAssumptions:\n\nRecurring wrong-way infraction reports in residential streets is a result of rat-running\n\n\n\nHypothesis:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "A1_network.html",
    "href": "A1_network.html",
    "title": "Extracting OSM networks",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"osmextract\",\n    \"rvest\"\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n        sf  tidyverse osmextract      rvest \n      TRUE       TRUE       TRUE       TRUE \n\n\nFor this study, we will use OpenStreetMap to obtain the road network data. First, we will download a spatial data file with the urban perimeter of Bogotá from Datos Abiertos de Bogotá (Bogotá’s Open Data platform).\n\ndir.create(\"raw_data\",showWarnings = F)\n\nif(!file.exists(file.path(\"raw_data\", \"perimetrourbano.gpkg\"))) {\n  u &lt;- \"https://datosabiertos.bogota.gov.co/dataset/12a704ee-e5bb-4c5d-bad6-a5069d12f90a/resource/bfc61e3c-fa58-4fe7-9581-7ead66c494cb/download/perimetrourbano.gpkg\"\n  download.file(u, file.path(\"raw_data\", basename(u)), mode = \"wb\")\n}\n\nurban_perimeter &lt;- st_read(\"raw_data/perimetrourbano.gpkg\")\n\nReading layer `PerimetroUrbano' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\raw_data\\perimetrourbano.gpkg' \n  using driver `GPKG'\n\n\nWarning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : GDAL\nMessage 1: Non-conformant content for record 1 in column\nFECHA_ACTO_ADMINISTRATIVO, 2021-12-29T00:00:00.0Z, successfully parsed\n\n\nSimple feature collection with 3 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.22358 ymin: 4.468614 xmax: -74.01206 ymax: 4.830661\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nWe will use the osmextract package to get OSM data in R. Please note that we will be using previous versions of the OSM data, as the network might have changed in recent years. For example, some sections of the roads are currently closed (2024) due to the works for the first metro line in Bogotá. We will use OSM networks for end of 2019 (January 1st, 2020) and 2020 (January 1st, 2021).\nFirst, we produce a boundary box for an area covering the urban perimeter and the neighbouring municipalities. This is done by producing a buffer of 20 km around Bogotá.\n\nbbox_bogota &lt;- urban_perimeter |&gt;\n  st_buffer(dist = 20e3) |&gt; \n  st_bbox() |&gt;\n  st_as_sfc() |&gt;\n  st_transform(crs = 4326)\n\nWe obtain the url of the pbf file in Geofabrik which contains the area we are interested in.\n\nbog_match &lt;- oe_match(bbox_bogota,provider = \"geofabrik\")\n\nThe input place was matched with Colombia. \n\n\nThe following code obtains the names of the files with the older versions of the OSM data and downloads the 2019 and 2020 pbf files.\n\nu &lt;- dirname(bog_match$url)\nf &lt;- basename(bog_match$url)\n\nid_files &lt;- gsub(\"latest\\\\.osm\\\\.pbf\",replacement = \"\",f)\n\nfiles_table &lt;- (rvest::read_html(u) |&gt; html_table())[[1]]\n\navailable_versions &lt;- files_table$Name[grep(paste0(id_files,\"\\\\d{6}\\\\.osm\\\\.pbf$\"),\n                                            files_table$Name)]\n\nnet_options &lt;- osmextract:::load_options_driving(NA_character_)\n\nnet_old_200101 &lt;- do.call(oe_read,\n                          c(file_path = paste0(u,\"/\",available_versions[7]),\n                            net_options[2:4]\n                     )\n                   )\n\nThe chosen file was already detected in the download directory. Skip downloading.\n\n\nStarting with the vectortranslate operations on the input file!\n\n\n0...10...20...30...40...50...60...70...80...90...100 - done.\n\n\nFinished the vectortranslate operations on the input file!\n\n\nReading layer `lines' from data source \n  `C:\\Users\\ts18jpf\\Documents\\OSMEXT_downloads\\geofabrik_colombia-200101.gpkg' \n  using driver `GPKG'\nSimple feature collection with 461429 features and 11 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -81.73539 ymin: -4.259884 xmax: -66.83441 ymax: 13.38586\nGeodetic CRS:  WGS 84\n\nnet_old_210101 &lt;- do.call(oe_read,\n                          c(file_path = paste0(u,\"/\",available_versions[8]),\n                            net_options[2:4]\n                     )\n                   )\n\nThe chosen file was already detected in the download directory. Skip downloading.\nStarting with the vectortranslate operations on the input file!\n\n\n0...10...20...30...40...50...60...70...80...90...100 - done.\n\n\nFinished the vectortranslate operations on the input file!\n\n\nReading layer `lines' from data source \n  `C:\\Users\\ts18jpf\\Documents\\OSMEXT_downloads\\geofabrik_colombia-210101.gpkg' \n  using driver `GPKG'\nSimple feature collection with 650682 features and 11 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -81.73539 ymin: -4.259656 xmax: -66.83441 ymax: 13.38586\nGeodetic CRS:  WGS 84\n\n\nOnce we have downloaded the data. We can clean and clip the network by using the boundary box we produced and by filtering only relevant road links (see the road_types vector).\n\nroad_types &lt;- c(\"tertiary\"       ,\n  \"residential\"    ,\n  \"primary_link\"   ,\n  \"primary\"      ,\n  \"secondary\"      ,\n  \"trunk\"          ,\n  \"trunk_link\"     ,\n  # \"service\"      ,\n  \"secondary_link\" ,\n  \"unclassified\"   ,\n  \"tertiary_link\"  \n  # \"living_street\"\n  # \"track\"          ,\n  # \"busway\"         ,\n  # \"raceway\"\n)\n\nosm_bogota_200101 &lt;- net_old_200101[bbox_bogota,] |&gt;\n  filter(highway %in% road_types) |&gt; st_transform(st_crs(urban_perimeter))\n\nosm_bogota_210101 &lt;- net_old_210101[bbox_bogota,] |&gt;\n  filter(highway %in% road_types) |&gt; st_transform(st_crs(urban_perimeter))\n\nrm(net_old_200101,net_old_210101)\n\n\n\nFinally, we save the sf objects as GeoPackages.\n\ndir.create(\"sf_network\",showWarnings = F)\nst_write(osm_bogota_200101,file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),delete_dsn = F,layer = \"network_2019\",delete_layer = T)\n\nDeleting layer `network_2019' using driver `GPKG'\nWriting layer `network_2019' to data source \n  `sf_network/bogota_osm_network.gpkg' using driver `GPKG'\nWriting 54531 features with 11 fields and geometry type Line String.\n\nst_write(osm_bogota_210101,file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),delete_dsn = F,layer = \"network_2020\",delete_layer = T)\n\nDeleting layer `network_2020' using driver `GPKG'\nWriting layer `network_2020' to data source \n  `sf_network/bogota_osm_network.gpkg' using driver `GPKG'\nWriting 62166 features with 11 fields and geometry type Line String."
  },
  {
    "objectID": "A1_network.html#save-network-in-sf-format",
    "href": "A1_network.html#save-network-in-sf-format",
    "title": "Extracting OSM networks",
    "section": "",
    "text": "Finally, we save the sf objects as GeoPackages.\n\ndir.create(\"sf_network\",showWarnings = F)\nst_write(osm_bogota_200101,file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),delete_dsn = F,layer = \"network_2019\",delete_layer = T)\n\nDeleting layer `network_2019' using driver `GPKG'\nWriting layer `network_2019' to data source \n  `sf_network/bogota_osm_network.gpkg' using driver `GPKG'\nWriting 54531 features with 11 fields and geometry type Line String.\n\nst_write(osm_bogota_210101,file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),delete_dsn = F,layer = \"network_2020\",delete_layer = T)\n\nDeleting layer `network_2020' using driver `GPKG'\nWriting layer `network_2020' to data source \n  `sf_network/bogota_osm_network.gpkg' using driver `GPKG'\nWriting 62166 features with 11 fields and geometry type Line String."
  },
  {
    "objectID": "A2_graph.html",
    "href": "A2_graph.html",
    "title": "Baseline Network Graph",
    "section": "",
    "text": "Libraries\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"dodgr\"\n)\nremotes::install_cran(pkgs)\n\npackage 'dodgr' successfully unpacked and MD5 sums checked\n\n\nWarning: cannot remove prior installation of package 'dodgr'\n\n\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\ts18jpf\\AppData\\Local\\R\\win-library\\4.4\\00LOCK\\dodgr\\libs\\x64\\dodgr.dll\nto C:\\Users\\ts18jpf\\AppData\\Local\\R\\win-library\\4.4\\dodgr\\libs\\x64\\dodgr.dll:\nPermission denied\n\n\nWarning: restored 'dodgr'\n\n\n\nThe downloaded binary packages are in\n    C:\\Users\\ts18jpf\\AppData\\Local\\Temp\\Rtmp2Rlm4C\\downloaded_packages\n\nsapply(pkgs, require, character.only = TRUE)\n\n       sf tidyverse     dodgr \n     TRUE      TRUE      TRUE \n\n\nUsing the networks extracted before. The following code loads the sf objects.\n\nsf_bogota_2019 &lt;- st_read(file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),layer = \"network_2019\")\n\nReading layer `network_2019' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 54531 features and 11 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.441 ymin: 4.236862 xmax: -73.72583 ymax: 5.042826\nGeodetic CRS:  MAGNA-SIRGAS\n\n\n\n\nIn this step, a graph representation of the 2019 road network of Bogotá is processed using the dodgr package. Posted speed limits are used as standard speeds for the road links (edges). The corresponding weighting profile has been saved in the bogota_wp.json file. To speed up the calculation, a distance threshold is applied based on an maximum error of 0.001.\n\ngraph_bogota &lt;- weight_streetnet(sf_bogota_2019,\n                                 left_side = F,\n                                 wt_profile_file = \"bogota_wp.json\",\n                                 wt_profile = \"motorcar\")\n\n# graph_bogota |&gt;\n#   dodgr_contract_graph() |&gt;\n#   estimate_centrality_threshold(tolerance = 1e-3)\n# converged on distance threshold of 14000\n\ngraph_bogota_centrality &lt;- graph_bogota |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality(dist_threshold = 1.4e4)\n\nsf_network &lt;- graph_bogota |&gt; \n    dodgr_to_sf ()\n\nExporting the results\n\nsf_net_cent &lt;- sf_network |&gt;\n  left_join(\n    tibble(edge_id = graph_bogota_centrality$edge_id,\n           centrality = graph_bogota_centrality$centrality),\n    by = \"edge_id\")\n\nst_write(sf_net_cent,\"sf_network/bogota_osm_network_cent.gpkg\",delete_dsn = F,delete_layer = T,layer = \"bog_cent_2019\")\n\n\n\nTo clip the network for visualisation, we will load the file with urban perimeter\n\nurban_perimeter &lt;- st_read(\"raw_data/perimetrourbano.gpkg\") |&gt; \n  st_transform(4326)\n\nReading layer `PerimetroUrbano' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\raw_data\\perimetrourbano.gpkg' \n  using driver `GPKG'\n\n\nWarning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : GDAL\nMessage 1: Non-conformant content for record 1 in column\nFECHA_ACTO_ADMINISTRATIVO, 2021-12-29T00:00:00.0Z, successfully parsed\n\n\nSimple feature collection with 3 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.22358 ymin: 4.468614 xmax: -74.01206 ymax: 4.830661\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nThe following code produces a visualisation of the network with the calculated centrality.\n\nroad_hierarchy &lt;- c( \n  \"trunk\",\n  \"trunk_link\",\n  \"primary\",\n  \"primary_link\",\n  \"secondary\",\n  \"secondary_link\",\n  \"tertiary\",\n  \"tertiary_link\",\n  \"residential\",\n  \"unclassified\"\n  )\n\n\nmymap &lt;- sf_net_cent[urban_perimeter,] |&gt; \n  mutate(highway = factor(highway,levels = road_hierarchy,ordered = T)) |&gt; \n  ggplot(aes(linewidth = centrality+1))+\n  geom_sf(aes(col = log(centrality)))+\n  scale_color_viridis_c(direction = -1)+\n  scale_linewidth_continuous(range = c(0.05,0.3),\n                             transform = scales::transform_boxcox(p = 2))+\n  theme_void()+\n  guides(linewidth = \"none\",)+\n  labs(col = \"Centrality (log)\",\n       caption = \"BC at posted speed limit\")+\n  theme(legend.position = \"inside\",\n        legend.position.inside = c(0.25,0.8),\n        # text = element_text(family = \"Roboto Condensed\"),\n        legend.key.width = unit(3, \"mm\"))\n\n## For saving the final plot\n# ggsave(plot = mymap,\n#        filename = \"bog_centrality.png\",\n#        dpi = 330,\n#        units = \"cm\",\n#        height = 13,\n#        width = 11)\nmymap\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_sf()`)."
  },
  {
    "objectID": "B1_infractions.html",
    "href": "B1_infractions.html",
    "title": "Infraction data",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"tmap\",\n    \"webshot2\"\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n       sf tidyverse      tmap  webshot2 \n     TRUE      TRUE      TRUE      TRUE \n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "B1_infractions.html#loading-infractions",
    "href": "B1_infractions.html#loading-infractions",
    "title": "Infraction data",
    "section": "Loading Infractions",
    "text": "Loading Infractions\n\nreports2019 &lt;- read_csv(\"../00_data/bogota/Comparendos_2019_Bogota_D_C.csv\",\n                        col_types = cols(\n                          X = col_double(),\n                          Y = col_double(),\n                          OBJECTID = col_double(),\n                          NUM_COMPARENDO = col_character(),\n                          FECHA_HORA = col_character(),\n                          ANO = col_double(),\n                          HORA_OCURRENCIA = col_character(),\n                          MES = col_character(),\n                          MEDIO_DETECCION = col_character(),\n                          CLASE_VEHICULO = col_character(),\n                          TIPO_SERVICIO = col_character(), \n                          INFRACCION = col_character(),\n                          DES_INFRACCION = col_character(),\n                          LOCALIDAD = col_character(),\n                          MUNICIPIO = col_character(),\n                          LATITUD = col_double(),\n                          LONGITUD = col_double(),\n                          GlobalID = col_character()\n                        ))\n\n\nreports2020 &lt;- read_csv(\"../00_data/bogota/Comparendos_DEI_2020_Bogot%C3%A1_D_C.csv\",\n                        col_types = cols(\n                          X = col_double(),\n                          Y = col_double(),\n                          FID = col_double(),\n                          OBJECTID = col_double(),\n                          FECHA_HORA = col_character(),\n                          ANO = col_double(),\n                          HORA_OCURR = col_character(),\n                          MES = col_character(),\n                          MEDIO_DETE = col_character(),\n                          CLASE_VEHI = col_character(),\n                          TIPO_SERVI = col_character(),\n                          INFRACCION = col_character(),\n                          DES_INFRAC = col_character(),\n                          MUNICIPIO = col_character(),\n                          PAIS = col_character(),\n                          LATITUD = col_double(),\n                          LONGITUD = col_double()))"
  },
  {
    "objectID": "B1_infractions.html#exploring-types-of-infractions",
    "href": "B1_infractions.html#exploring-types-of-infractions",
    "title": "Infraction data",
    "section": "Exploring types of infractions",
    "text": "Exploring types of infractions\n\nreports2019 |&gt; \n  count(INFRACCION) |&gt; \n  filter(n&gt;quantile(n,0.90)) |&gt; \n  ggplot(aes(y = fct_reorder(INFRACCION,n),\n             x = n))+\n  geom_col()+\n  scale_x_continuous()\n\n\n\n\n\n\n\n\n\ncount_infractions &lt;- reports2019 |&gt; \n  count(INFRACCION,DES_INFRACCION) |&gt; \n  filter(n&gt;quantile(n,0.70)) |&gt; \n  arrange(-n)"
  },
  {
    "objectID": "B1_infractions.html#wrong-way-infraction",
    "href": "B1_infractions.html#wrong-way-infraction",
    "title": "Infraction data",
    "section": "Wrong way infraction",
    "text": "Wrong way infraction\nCreating an sf object with the reports for driving in the wrong-way\n\nwrong_way_2019_sf &lt;- reports2019 |&gt;\n  filter(INFRACCION == \"D03\") |&gt; \n  select(-DES_INFRACCION) |&gt;\n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  st_as_sf(coords = c(\"LONGITUD\",\"LATITUD\"),crs = 4326)\n\nwrong_way_2020_sf &lt;- reports2020 |&gt;\n  filter(INFRACCION == \"D03\") |&gt; \n  select(-DES_INFRAC) |&gt; \n  mutate(time = hms(HORA_OCURR)) |&gt;\n  st_as_sf(coords = c(\"LONGITUD\",\"LATITUD\"),crs = 4326)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `time = hms(HORA_OCURR)`.\nCaused by warning in `.parse_hms()`:\n! Some strings failed to parse"
  },
  {
    "objectID": "B1_infractions.html#mapping-the-infractions",
    "href": "B1_infractions.html#mapping-the-infractions",
    "title": "Infraction data",
    "section": "Mapping the infractions",
    "text": "Mapping the infractions\n\n# tmap_mode(\"view\")\ntm_shape(wrong_way_2019_sf)+\n  tm_dots(\"blue\")+\ntm_shape(wrong_way_2020_sf)+\n  tm_dots(\"red\")"
  },
  {
    "objectID": "B1_infractions.html#temporal-distribution",
    "href": "B1_infractions.html#temporal-distribution",
    "title": "Infraction data",
    "section": "Temporal distribution",
    "text": "Temporal distribution\n\n  ggplot(wrong_way_2019_sf,\n         aes(time))+\n  geom_density(col = \"dodgerblue3\",alpha = 0.5,linewidth = 2)+\n  geom_density(data = wrong_way_2020_sf, col = \"firebrick3\",alpha = 0.5,linewidth = 2)+\n    scale_x_time()+\n  # scale_y_continuous(labels = scales::label_percent(accuracy = 2))+\n  labs(x = \"Time\",\n       title = \"Daily profile of wrong-way driving reports\",\n       subtitle = \"blue = 2019 , red = 2020\",\n       caption = \"Showing all days\")+\n  theme_minimal()\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_density()`)."
  },
  {
    "objectID": "B1_infractions.html#summary-by-vehicle-type",
    "href": "B1_infractions.html#summary-by-vehicle-type",
    "title": "Infraction data",
    "section": "Summary by vehicle type",
    "text": "Summary by vehicle type\n\nwrong_way_2019_sf |&gt;\n  st_drop_geometry() |&gt; \n  mutate(veh_class = CLASE_VEHICULO |&gt;\n           str_to_lower()) |&gt; \n  count(veh_class) |&gt; \n  arrange(-n)\n\n# A tibble: 15 × 2\n   veh_class                n\n   &lt;chr&gt;                &lt;int&gt;\n 1 motocicleta           1743\n 2 automóvil              822\n 3 camioneta              277\n 4 campero                 76\n 5 bus                     29\n 6 camión                  27\n 7 micro                   17\n 8 microbus                12\n 9 buseta                   9\n10 motociclo                4\n11 tractocamión             3\n12 volqueta                 3\n13 -                        1\n14 bicicleta o triciclo     1\n15 tractocamion             1\n\n\n\nst_write(wrong_way_2019_sf,dsn = \"wwd_2019.gpkg\",delete_dsn = T)\n\nDeleting source `wwd_2019.gpkg' using driver `GPKG'\nWriting layer `wwd_2019' to data source `wwd_2019.gpkg' using driver `GPKG'\nWriting 3025 features with 16 fields and geometry type Point."
  },
  {
    "objectID": "A2_graph.html#building-the-graph",
    "href": "A2_graph.html#building-the-graph",
    "title": "Baseline Network Graph",
    "section": "",
    "text": "In this step, a graph representation of the 2019 road network of Bogotá is processed using the dodgr package. Posted speed limits are used as standard speeds for the road links (edges). The corresponding weighting profile has been saved in the bogota_wp.json file. To speed up the calculation, a distance threshold is applied based on an maximum error of 0.001.\n\ngraph_bogota &lt;- weight_streetnet(sf_bogota_2019,\n                                 left_side = F,\n                                 wt_profile_file = \"bogota_wp.json\",\n                                 wt_profile = \"motorcar\")\n\n# graph_bogota |&gt;\n#   dodgr_contract_graph() |&gt;\n#   estimate_centrality_threshold(tolerance = 1e-3)\n# converged on distance threshold of 14000\n\ngraph_bogota_centrality &lt;- graph_bogota |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality(dist_threshold = 1.4e4)\n\nsf_network &lt;- graph_bogota |&gt; \n    dodgr_to_sf ()\n\nExporting the results\n\nsf_net_cent &lt;- sf_network |&gt;\n  left_join(\n    tibble(edge_id = graph_bogota_centrality$edge_id,\n           centrality = graph_bogota_centrality$centrality),\n    by = \"edge_id\")\n\nst_write(sf_net_cent,\"sf_network/bogota_osm_network_cent.gpkg\",delete_dsn = F,delete_layer = T,layer = \"bog_cent_2019\")\n\n\n\nTo clip the network for visualisation, we will load the file with urban perimeter\n\nurban_perimeter &lt;- st_read(\"raw_data/perimetrourbano.gpkg\") |&gt; \n  st_transform(4326)\n\nReading layer `PerimetroUrbano' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\raw_data\\perimetrourbano.gpkg' \n  using driver `GPKG'\n\n\nWarning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : GDAL\nMessage 1: Non-conformant content for record 1 in column\nFECHA_ACTO_ADMINISTRATIVO, 2021-12-29T00:00:00.0Z, successfully parsed\n\n\nSimple feature collection with 3 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.22358 ymin: 4.468614 xmax: -74.01206 ymax: 4.830661\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nThe following code produces a visualisation of the network with the calculated centrality.\n\nroad_hierarchy &lt;- c( \n  \"trunk\",\n  \"trunk_link\",\n  \"primary\",\n  \"primary_link\",\n  \"secondary\",\n  \"secondary_link\",\n  \"tertiary\",\n  \"tertiary_link\",\n  \"residential\",\n  \"unclassified\"\n  )\n\n\nmymap &lt;- sf_net_cent[urban_perimeter,] |&gt; \n  mutate(highway = factor(highway,levels = road_hierarchy,ordered = T)) |&gt; \n  ggplot(aes(linewidth = centrality+1))+\n  geom_sf(aes(col = log(centrality)))+\n  scale_color_viridis_c(direction = -1)+\n  scale_linewidth_continuous(range = c(0.05,0.3),\n                             transform = scales::transform_boxcox(p = 2))+\n  theme_void()+\n  guides(linewidth = \"none\",)+\n  labs(col = \"Centrality (log)\",\n       caption = \"BC at posted speed limit\")+\n  theme(legend.position = \"inside\",\n        legend.position.inside = c(0.25,0.8),\n        # text = element_text(family = \"Roboto Condensed\"),\n        legend.key.width = unit(3, \"mm\"))\n\n## For saving the final plot\n# ggsave(plot = mymap,\n#        filename = \"bog_centrality.png\",\n#        dpi = 330,\n#        units = \"cm\",\n#        height = 13,\n#        width = 11)\nmymap\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_sf()`)."
  },
  {
    "objectID": "C1_infractions.html",
    "href": "C1_infractions.html",
    "title": "Infraction data",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"tmap\",\n    \"webshot2\"\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n       sf tidyverse      tmap  webshot2 \n     TRUE      TRUE      TRUE      TRUE \n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "C1_infractions.html#loading-infractions",
    "href": "C1_infractions.html#loading-infractions",
    "title": "Infraction data",
    "section": "Loading Infractions",
    "text": "Loading Infractions\n\nreports2019 &lt;- read_csv(\"../00_data/bogota/Comparendos_2019_Bogota_D_C.csv\",\n                        col_types = cols(\n                          X = col_double(),\n                          Y = col_double(),\n                          OBJECTID = col_double(),\n                          NUM_COMPARENDO = col_character(),\n                          FECHA_HORA = col_character(),\n                          ANO = col_double(),\n                          HORA_OCURRENCIA = col_character(),\n                          MES = col_character(),\n                          MEDIO_DETECCION = col_character(),\n                          CLASE_VEHICULO = col_character(),\n                          TIPO_SERVICIO = col_character(), \n                          INFRACCION = col_character(),\n                          DES_INFRACCION = col_character(),\n                          LOCALIDAD = col_character(),\n                          MUNICIPIO = col_character(),\n                          LATITUD = col_double(),\n                          LONGITUD = col_double(),\n                          GlobalID = col_character()\n                        ))\n\n\nreports2020 &lt;- read_csv(\"../00_data/bogota/Comparendos_DEI_2020_Bogot%C3%A1_D_C.csv\",\n                        col_types = cols(\n                          X = col_double(),\n                          Y = col_double(),\n                          FID = col_double(),\n                          OBJECTID = col_double(),\n                          FECHA_HORA = col_character(),\n                          ANO = col_double(),\n                          HORA_OCURR = col_character(),\n                          MES = col_character(),\n                          MEDIO_DETE = col_character(),\n                          CLASE_VEHI = col_character(),\n                          TIPO_SERVI = col_character(),\n                          INFRACCION = col_character(),\n                          DES_INFRAC = col_character(),\n                          MUNICIPIO = col_character(),\n                          PAIS = col_character(),\n                          LATITUD = col_double(),\n                          LONGITUD = col_double()))"
  },
  {
    "objectID": "C1_infractions.html#exploring-types-of-infractions",
    "href": "C1_infractions.html#exploring-types-of-infractions",
    "title": "Infraction data",
    "section": "Exploring types of infractions",
    "text": "Exploring types of infractions\n\nreports2019 |&gt; \n  count(INFRACCION) |&gt; \n  filter(n&gt;quantile(n,0.90)) |&gt; \n  ggplot(aes(y = fct_reorder(INFRACCION,n),\n             x = n))+\n  geom_col()+\n  scale_x_continuous()\n\n\n\n\n\n\n\n\n\ncount_infractions &lt;- reports2019 |&gt; \n  count(INFRACCION,DES_INFRACCION) |&gt; \n  filter(n&gt;quantile(n,0.70)) |&gt; \n  arrange(-n)"
  },
  {
    "objectID": "C1_infractions.html#wrong-way-infraction",
    "href": "C1_infractions.html#wrong-way-infraction",
    "title": "Infraction data",
    "section": "Wrong way infraction",
    "text": "Wrong way infraction\nCreating an sf object with the reports for driving in the wrong-way\n\nwrong_way_2019_sf &lt;- reports2019 |&gt;\n  filter(INFRACCION == \"D03\") |&gt; \n  select(-DES_INFRACCION) |&gt;\n  mutate(time = hms(HORA_OCURRENCIA)) |&gt; \n  st_as_sf(coords = c(\"LONGITUD\",\"LATITUD\"),crs = 4326)\n\nwrong_way_2020_sf &lt;- reports2020 |&gt;\n  filter(INFRACCION == \"D03\") |&gt; \n  select(-DES_INFRAC) |&gt; \n  mutate(time = hms(HORA_OCURR)) |&gt;\n  st_as_sf(coords = c(\"LONGITUD\",\"LATITUD\"),crs = 4326)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `time = hms(HORA_OCURR)`.\nCaused by warning in `.parse_hms()`:\n! Some strings failed to parse"
  },
  {
    "objectID": "C1_infractions.html#mapping-the-infractions",
    "href": "C1_infractions.html#mapping-the-infractions",
    "title": "Infraction data",
    "section": "Mapping the infractions",
    "text": "Mapping the infractions\n\n# tmap_mode(\"view\")\ntm_shape(wrong_way_2019_sf)+\n  tm_dots(\"blue\")+\ntm_shape(wrong_way_2020_sf)+\n  tm_dots(\"red\")"
  },
  {
    "objectID": "C1_infractions.html#temporal-distribution",
    "href": "C1_infractions.html#temporal-distribution",
    "title": "Infraction data",
    "section": "Temporal distribution",
    "text": "Temporal distribution\n\n  ggplot(wrong_way_2019_sf,\n         aes(time))+\n  geom_density(col = \"dodgerblue3\",alpha = 0.5,linewidth = 2)+\n  geom_density(data = wrong_way_2020_sf, col = \"firebrick3\",alpha = 0.5,linewidth = 2)+\n    scale_x_time()+\n  # scale_y_continuous(labels = scales::label_percent(accuracy = 2))+\n  labs(x = \"Time\",\n       title = \"Daily profile of wrong-way driving reports\",\n       subtitle = \"blue = 2019 , red = 2020\",\n       caption = \"Showing all days\")+\n  theme_minimal()\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_density()`)."
  },
  {
    "objectID": "C1_infractions.html#summary-by-vehicle-type",
    "href": "C1_infractions.html#summary-by-vehicle-type",
    "title": "Infraction data",
    "section": "Summary by vehicle type",
    "text": "Summary by vehicle type\n\nwrong_way_2019_sf |&gt;\n  st_drop_geometry() |&gt; \n  mutate(veh_class = CLASE_VEHICULO |&gt;\n           str_to_lower()) |&gt; \n  count(veh_class) |&gt; \n  arrange(-n)\n\n# A tibble: 15 × 2\n   veh_class                n\n   &lt;chr&gt;                &lt;int&gt;\n 1 motocicleta           1743\n 2 automóvil              822\n 3 camioneta              277\n 4 campero                 76\n 5 bus                     29\n 6 camión                  27\n 7 micro                   17\n 8 microbus                12\n 9 buseta                   9\n10 motociclo                4\n11 tractocamión             3\n12 volqueta                 3\n13 -                        1\n14 bicicleta o triciclo     1\n15 tractocamion             1\n\n\n\nst_write(wrong_way_2019_sf,dsn = \"wwd_2019.gpkg\",delete_dsn = T)\n\nDeleting source `wwd_2019.gpkg' using driver `GPKG'\nWriting layer `wwd_2019' to data source `wwd_2019.gpkg' using driver `GPKG'\nWriting 3025 features with 16 fields and geometry type Point."
  },
  {
    "objectID": "B1_speed_data.html",
    "href": "B1_speed_data.html",
    "title": "Speed Data Processing",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"data.table\",\n    \"paletteer\"\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n        sf  tidyverse data.table  paletteer \n      TRUE       TRUE       TRUE       TRUE \n\nsetDTthreads(0)"
  },
  {
    "objectID": "B1_speed_data.html#preliminary-cleaning",
    "href": "B1_speed_data.html#preliminary-cleaning",
    "title": "Speed Data Processing",
    "section": "Preliminary cleaning",
    "text": "Preliminary cleaning\n\nall_data[,\n           INICIO := mdy_hms(INICIO,\n                             tz = \"America/Bogota\")\n         ][,\n           `:=`(YEAR = year(INICIO))\n           ]\n\nNot all links have data for all months. So the first step is to identify the links with enough data per year.\n\nlinks_summary &lt;- unique(\n  all_data[,\n           c(\"TID\",\"YEAR\",\"MES\")])[,\n                                   .(count = .N),\n                                   by = c(\"TID\",\"YEAR\")]\n\n\nlinks_summary |&gt; \n  ggplot(aes(count))+\n  geom_histogram(binwidth = 1)+\n  scale_y_log10()+\n  scale_x_continuous(breaks = 0:12)+\n  facet_grid(YEAR~.)\n\nLinks with data in 5 or more months per year will be used for this analysis.\n\nlinks_data = links_summary[,count := 1*(count&gt;=5)\n                           ][,.(tot_count = sum(count)),\n                             by = \"TID\"][\n                               tot_count == 2,\n                               ] |&gt; pull(TID)\n\nWe extract the data only for these links with the following code and clean the memory:\n\nclean_data &lt;- all_data[TID %in% links_data]\nrm(all_data,links_data,links_summary,lst_files,a)\ngc()"
  },
  {
    "objectID": "B1_speed_data.html#classifiying-the-data",
    "href": "B1_speed_data.html#classifiying-the-data",
    "title": "Speed Data Processing",
    "section": "Classifiying the data",
    "text": "Classifiying the data\nFirst, we will identify the days that were bank holidays in Colombia\n\nbank_holidays &lt;- read.csv(\"../00_data/bogota/bank_holidays.csv\") |&gt;\n  mutate(bank_holiday = dmy(bank_holiday)) |&gt;\n  pull(bank_holiday)\n\n\nclean_data[date(INICIO) %in% bank_holidays,\n           DIA_SEMANA := \"Festivo\"\n           ]\n\nclean_data[,DAY_TYPE := fcase(\n             DIA_SEMANA == \"Domingo\",\"weekend\",\n             DIA_SEMANA == \"Sabado\",\"weekend\",\n             DIA_SEMANA == \"Festivo\",\"weekend\",\n             DIA_SEMANA == \"Viernes\",\"friday\",\n             default = \"weekday\")\n             ]\n\nThe following code extracts the 94th percentile of the speeds in each road link.\n\nmax_speeds &lt;- clean_data[,\n                             .(p94_speed = quantile(VEL_PROMEDIO,\n                                                       0.94,\n                                                       na.rm = T)),\n                             by =  c(\"TID\",\"YEAR\")]\n\nNow, we calculate the median hourly speed for each road link by day type and road link.\n\nsummary_speeds &lt;- clean_data[,\n                             .(median_speed = median(VEL_PROMEDIO,\n                                                     na.rm = T)),\n                             by =  c(\"TID\",\"HORA\",\"DAY_TYPE\",\"YEAR\")]\n\nNow we normalise the values by dividing by the 95th-percentile speed\n\nnorm_summary_spd &lt;- merge(summary_speeds,\n                          max_speeds,\n                          by = c(\"TID\",\"YEAR\"))[,\n                                                norm_speed := median_speed/p94_speed\n                                                ]"
  },
  {
    "objectID": "B1_speed_data.html#some-visualisations-of-speed-distribution",
    "href": "B1_speed_data.html#some-visualisations-of-speed-distribution",
    "title": "Speed Data Processing",
    "section": "Some visualisations of speed distribution:",
    "text": "Some visualisations of speed distribution:\n\nHourly distributions\n\nNormalised speed\n\nnorm_summary_spd |&gt; \n  ggplot(aes(x = HORA,y = norm_speed))+\n  geom_boxplot(aes(group = HORA), fill = NA,alpha = 0.3,outlier.shape = NA)+\n  geom_jitter(alpha = 0.3, size = 0.3,col = \"gray60\")+\n  stat_summary(geom = \"line\",\n               fun = \"mean\",\n               aes(col = DAY_TYPE),\n               linewidth = 1,\n               alpha = 0.6,\n               show.legend = F)+\n  facet_grid(DAY_TYPE~.)+\n  theme_minimal()+\n  labs(x = \"Hour\", y = \"Norm speed (observed/94th percentile)\")+\n  scale_x_continuous(breaks = 0:23,\n                     labels = sprintf(\"%02d:00\",0:23))+\n  theme(axis.text.x = element_text(angle = 90))+\n  scale_colour_manual(values = paletteer_d(\"ggsci::lanonc_lancet\",n = 3))\n\n\n\n\n\n\n\n\n\n\nAbsolute speed\n\nnorm_summary_spd |&gt; \n  ggplot(aes(x = HORA,y = median_speed))+\n  geom_boxplot(aes(group = HORA), fill = NA,alpha = 0.3,outlier.shape = NA)+\n  geom_jitter(alpha = 0.3, size = 0.3,col = \"gray60\")+\n  stat_summary(geom = \"line\",\n               fun = \"mean\",\n               aes(col = DAY_TYPE),\n               linewidth = 1,\n               alpha = 0.6,\n               show.legend = F)+\n  facet_grid(DAY_TYPE~YEAR)+\n  theme_minimal()+\n  labs(x = \"Hour\", y = \"Observed speed\")+\n  scale_x_continuous(breaks = 0:23,\n                     labels = sprintf(\"%02d:00\",0:23))+\n  theme(axis.text.x = element_text(angle = 90))+\n  scale_colour_manual(values = paletteer_d(\"ggsci::lanonc_lancet\",n = 3))\n\n\n\n\n\n\n\n\n\n\n\nDaily profile by Link\n\nNormalised speed\n\nnorm_summary_spd |&gt; \n  ggplot(aes(x = HORA,y = norm_speed))+\n  # geom_boxplot(aes(group = HORA), fill = NA,alpha = 0.3,outlier.shape = NA)+\n  # geom_jitter(alpha = 0.3, size = 0.3,col = \"gray60\")+\n  stat_summary(geom = \"line\",\n               fun = \"mean\",\n               aes(col = DAY_TYPE,\n                   group = TID),\n               linewidth = 0.01,\n               alpha = 0.04,\n               # show.legend = F\n               )+\n  facet_grid(DAY_TYPE~YEAR)+\n  theme_minimal()+\n  labs(x = \"Hour\", y = \"Speed ratio (observed/94th percentile)\")+\n  scale_x_continuous(breaks = 0:23,\n                     labels = sprintf(\"%02d:00\",0:23))+\n  scale_y_continuous(limits = c(0,1.25),breaks = seq(0,1.25,0.25))+\n  scale_colour_manual(values = paletteer_d(\"ggsci::default_nejm\",n = 3))+\n  theme(axis.text.x = element_text(angle = 90),\n        panel.grid.minor = element_blank(),\n        legend.position = \"top\")\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_summary()`).\n\n\n\n\n\n\n\n\n\n\n\nAbsolute speed\n\nnorm_summary_spd |&gt; \n  ggplot(aes(x = HORA,y = median_speed))+\n  # geom_boxplot(aes(group = HORA), fill = NA,alpha = 0.3,outlier.shape = NA)+\n  # geom_jitter(alpha = 0.3, size = 0.3,col = \"gray60\")+\n  stat_summary(geom = \"line\",\n               fun = \"mean\",\n               aes(col = DAY_TYPE,\n                   group = TID),\n               linewidth = 0.01,\n               alpha = 0.04,\n               # show.legend = F\n               )+\n  facet_grid(DAY_TYPE~YEAR)+\n  geom_hline(yintercept = 60,col = \"#EE4C97\",linetype = \"dashed\",alpha = 0.6,linewidth = 1)+\n  annotate(geom = \"text\",x = 23,y = 63,label = \"Speed Limit \",vjust = 0,hjust = 1,face = \"italic\")+\n  theme_minimal()+\n  labs(x = \"Hour\", y = \"Observed speed\")+\n  scale_x_continuous(breaks = 0:23,\n                     labels = sprintf(\"%02d:00\",0:23))+\n  scale_y_continuous(limits = c(0,100),breaks = seq(0,100,20))+\n  scale_colour_manual(values = paletteer_d(\"ggsci::default_nejm\",n = 3))+\n  theme(axis.text.x = element_text(angle = 90),\n        panel.grid.minor = element_blank(),\n        legend.position = \"none\")\n\nWarning in annotate(geom = \"text\", x = 23, y = 63, label = \"Speed Limit \", :\nIgnoring unknown parameters: `face`\n\n\n\n\n\n\n\n\n\nMedian overall speed profile\n\nnorm_summary_spd |&gt; \n  ggplot(aes(x = HORA,y = norm_speed))+\n  # geom_boxplot(aes(group = HORA), fill = NA,alpha = 0.3,outlier.shape = NA)+\n  # geom_jitter(alpha = 0.3, size = 0.3,col = \"gray60\")+\n  stat_summary(geom = \"line\",\n               fun = \"mean\",\n               aes(col = DAY_TYPE),\n               linewidth = 1.5,\n               alpha = 0.6,\n               # show.legend = F\n               )+\n  facet_grid(.~YEAR)+\n  theme_minimal()+\n  labs(x = \"Hour\", y = \"Speed ratio (observed/94th percentile)\")+\n  scale_x_continuous(breaks = 0:23,\n                     labels = sprintf(\"%02d:00\",0:23))+\n  scale_y_continuous(limits = c(0,1.25),breaks = seq(0,1.25,0.25))+\n  scale_colour_manual(values = paletteer_d(\"ggsci::default_nejm\",n = 3))+\n  theme(axis.text.x = element_text(angle = 90),\n        panel.grid.minor = element_blank(),\n        legend.position = \"top\")\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_summary()`)."
  },
  {
    "objectID": "B1_speed_data.html#spatial-data",
    "href": "B1_speed_data.html#spatial-data",
    "title": "Speed Data Processing",
    "section": "Spatial data",
    "text": "Spatial data\nUp to this point, all the data processing has not involved the spatial component. On the open data platform, it is possible to download the gpkg files for each month. With the following code, we will identify which file(s) is(are) needed to have all data.\nIdeally, we need a file that contains all 770 TID.\n\nunique(\n  clean_data[,\n           c(\"TID\",\"YEAR\",\"MES\")])[,\n                                   .(count = .N),\n                                   by = c(\"YEAR\",\"MES\")][count == max(count)]\n\n    YEAR      MES count\n   &lt;int&gt;   &lt;char&gt; &lt;int&gt;\n1:  2019 February   767\n\n\nAs the file of February 2019 does not have all the links, we identify alternative files.\n\ntid_feb2019 &lt;- unique(clean_data[YEAR == 2019 & MES == \"February\",\"TID\"])[,1]\ntid_missing &lt;- unique(clean_data[!(TID %in% tid_feb2019$TID),\"TID\"])\n\nunique(\n  clean_data[TID %in% tid_missing$TID,\n           c(\"TID\",\"YEAR\",\"MES\")])[,\n                                   .(count = .N),\n                                   by = c(\"YEAR\",\"MES\")][count == max(count)]\n\n     YEAR       MES count\n    &lt;int&gt;    &lt;char&gt; &lt;int&gt;\n 1:  2020     April     3\n 2:  2019    August     3\n 3:  2020    August     3\n 4:  2019  December     3\n 5:  2020  December     3\n 6:  2020   January     3\n 7:  2020  February     3\n 8:  2019      July     3\n 9:  2020      July     3\n10:  2020      June     3\n11:  2020     March     3\n12:  2020       May     3\n13:  2019  November     3\n14:  2020  November     3\n15:  2019   October     3\n16:  2020   October     3\n17:  2019 September     3\n18:  2020 September     3\n\n\nThe files for February 2019 and October 2020 have been downloaded manually from the same source. As we are only interested in the geometries, we filter out all the other data.\n\nsf_feb2019&lt;- st_read(\n   \"../00_data/bogota/speed_data/Velocidades_Bitcarrier_Febrero_2019_1361955177739874723.gpkg\",\n   query=\"select TID,SHAPE from 'Velocidades_Bitcarrier_Febrero_2019'\"\n   ) |&gt; filter(TID %in% tid_feb2019$TID) |&gt; select(TID) |&gt; slice_head(n = 1,by = TID)\n\nReading query `select TID,SHAPE from 'Velocidades_Bitcarrier_Febrero_2019''\nfrom data source `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\00_data\\bogota\\speed_data\\Velocidades_Bitcarrier_Febrero_2019_1361955177739874723.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1930309 features and 1 field\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: -74.18353 ymin: 5.684342e-14 xmax: 1 ymax: 4.764635\nGeodetic CRS:  MAGNA-SIRGAS\n\nsf_oct2020 &lt;- st_read(\n  \"../00_data/bogota/speed_data/Velocidades_Bitcarrier_Octubre_2020_-1518838627102027019.gpkg\",\n  query=\"select TID,SHAPE from 'Velocidades_Bitcarrier_Octubre_2020'\") |&gt; filter(TID %in% tid_missing$TID) |&gt; slice_head(n = 1,by = TID)\n\nReading query `select TID,SHAPE from 'Velocidades_Bitcarrier_Octubre_2020''\nfrom data source `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\00_data\\bogota\\speed_data\\Velocidades_Bitcarrier_Octubre_2020_-1518838627102027019.gpkg' \n  using driver `GPKG'\nSimple feature collection with 2325212 features and 1 field\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: -74.20333 ymin: 5.684342e-14 xmax: 1 ymax: 4.764635\nGeodetic CRS:  MAGNA-SIRGAS\n\n\n\nsf_speed &lt;- bind_rows(sf_feb2019,sf_oct2020)\nrm(sf_feb2019,sf_oct2020)\n\n\nurban_perimeter &lt;- st_read(\"raw_data/perimetrourbano.gpkg\")\n\nReading layer `PerimetroUrbano' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\raw_data\\perimetrourbano.gpkg' \n  using driver `GPKG'\n\n\nWarning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : GDAL\nMessage 1: Non-conformant content for record 1 in column\nFECHA_ACTO_ADMINISTRATIVO, 2021-12-29T00:00:00.0Z, successfully parsed\n\n\nSimple feature collection with 3 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.22358 ymin: 4.468614 xmax: -74.01206 ymax: 4.830661\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nA quick visualisation of the maximum speeds:\n\nsf_speed[urban_perimeter,] |&gt; \n  left_join(max_speeds,by = \"TID\") |&gt; \n  ggplot()+\n  geom_sf(aes(col = p94_speed),linewidth = 0.3,alpha = 0.7)+\n  scale_color_gradientn(colours = paletteer_c(\"grDevices::Plasma\", 30))+\n  theme_void()\n\n\n\n\n\n\n\n\n\nCalculate summary statistics per link, take a sample of links to visualise\nDetect peak hours (based on lower speeds)\nDownload google data for free flow and congested times"
  },
  {
    "objectID": "D1_graph_centrality_tests.html",
    "href": "D1_graph_centrality_tests.html",
    "title": "Graph Centrlity Tests",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"zonebuilder\"\n    # \"dodgr\" # Using the developer version of dodgr\n)\nremotes::install_cran(pkgs)\nsapply(pkgs, require, character.only = TRUE)\n\n         sf   tidyverse zonebuilder \n       TRUE        TRUE        TRUE \n\nrequire(dodgr)\n\n\n\n\nsf_bogota_2019_full &lt;- st_read(file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),\n                          layer = \"network_2019\")\n\nReading layer `network_2019' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 54531 features and 15 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.441 ymin: 4.236862 xmax: -73.72583 ymax: 5.042826\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nWe will use a small subset of the network for this test to speed up the process.\n\nbog_zone &lt;- zonebuilder::zb_zone(\"Bogota\",n_circles = 2) |&gt; st_transform(st_crs(sf_bogota_2019_full))\n\nLoading required namespace: tmaptools\n\n# zb_view(bog_zone)\n\n\nsf_bogota_2019 &lt;- sf_bogota_2019_full[bog_zone,]\n\n\ngraph_bogota &lt;- weight_streetnet(sf_bogota_2019,\n                                 left_side = F,\n                                 wt_profile_file = \"bogota_wp.json\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols = c(\"oneway\",\"lanes\",\"surface\",\"maxspeed\"),\n                                 turn_penalty = F)\n\nbog_contracted &lt;- graph_bogota |&gt; \n  dodgr_contract_graph()\n\n\n\n\nIn order to include the actual speed along each corridor, I will specify 60 different classes to be applied to each road link. By default, speeds are assigned by road link by road type, e.g. any trunk road in Bogotá has a 60 km/h speed.\n\n# custom_wp &lt;- dodgr::weighting_profiles$weighting_profiles |&gt; filter(name==\"motorcar\")\ncustom_penalties &lt;- dodgr::weighting_profiles$penalties |&gt; filter(name==\"motorcar\")\ncustom_surfaces &lt;- dodgr::weighting_profiles$surface_speeds |&gt; filter(name==\"motorcar\")\n\ncustom_wp &lt;- data.frame(name = \"motorcar\",\n                        way = paste0(\"road_\",1:60),\n                        value = 1,\n                        max_speed = as.numeric(1:60))\n\ncustom_wp_list &lt;- list(weighting_profiles = custom_wp,\n                       surface_speeds = custom_surfaces,\n                       pealties = custom_penalties)\n\nwpj &lt;- jsonlite::toJSON (custom_wp_list, pretty = TRUE)\nwrite_lines(wpj,file = \"custom_wp_speeds.json\")\n\nAssigning a speed category based on the speed limit (baseline scenario)\n\nsf_bogota_2019_cwp &lt;- sf_bogota_2019 |&gt;\n  mutate(way_speed = case_when(highway %in%\n                                 c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~\"road_60\",\n                                               TRUE ~ \"road_30\")) |&gt; \n  select(-highway)\n\nThe following code builds the graph using the new column instead of highway.\n\ngraph_bogota_custom &lt;- weight_streetnet(sf_bogota_2019_cwp,\n                                 left_side = F,\n                                 wt_profile_file = \"custom_wp_speeds.json\",\n                                 type_col = \"way_speed\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols = c(\"way_speed\",\"oneway\",\"lanes\",\"surface\",\"maxspeed\"),\n                                 turn_penalty = F)\n\n\n\nWe calculate the\n\ngraph_baseline_centrality &lt;- graph_bogota |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality()\n\ngraph_cwp_centrality &lt;- graph_bogota_custom |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality()\n\nTo validate that the results are identical, we can run the following code\n\nidentical(graph_baseline_centrality$centrality,graph_cwp_centrality$centrality)\n\n[1] TRUE\n\n\n\n\n\n\nThere are four core alternatives for calculating the centrality using dodgr.\n\nbog_contracted[,\n    c(\"d_weighted\", \"d\", \"time_weighted\", \"time\")] |&gt;\n  pairs()\n\n\n\n\n\n\n\n\nAn initial check on the four alternatives reveal some inconsistencies in the time_weighted column.\nThere are 23 links in the contracted graph with differences in the weighted distance and the distance. The location of these edges will be inspected after calculating the centrality in Section 1.3.3.\nWhen multiple paths are available between two nodes in the contracted version of the graph, dodgr takes only the shortest weighted distance, which creates the difference. However, the resulting weighted time is not corrected and in some cases a 0 is returned.\nGiven this, we will recalculate the weighted time based on the weighted distance.\n\nbog_contracted$time_weighted[bog_contracted$time_weighted==0] &lt;- (3.6*bog_contracted$d_weighted[bog_contracted$time_weighted==0])/case_when(\n      bog_contracted$highway[bog_contracted$time_weighted==0] %in% c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~60,\n      T~30)\n\n\n\n\ncent_all &lt;- lapply(c(\"d_weighted\", \"d\", \"time_weighted\", \"time\"), \\(x) {\n  \n    df &lt;- bog_contracted |&gt;\n      dodgr_centrality(column = x)\n  \n  tibble(edge_id = df$edge_id, cent = df$centrality) |&gt;\n    rename_with(.cols = \"cent\", .fn = \\(.y) {\n      paste(.y, x, sep = \"_\")\n    })\n  }) |&gt;\n  plyr::join_all(by = \"edge_id\",type = \"full\")\n\n\n\n\n\nigraph_bog &lt;- bog_contracted |&gt; \n  dodgr_to_igraph()\n\nLoading required namespace: igraph\n\n\n\ncent_all_ig &lt;- cent_all |&gt; \n  left_join(\n    tibble(edge_id = bog_contracted$edge_id,\n       cent_ig_d = igraph::edge_betweenness(graph = igraph_bog,\n                                            weights = bog_contracted$d),\n       cent_ig_d_weighted = igraph::edge_betweenness(graph = igraph_bog,\n                                                     weights = bog_contracted$d_weighted),\n       cent_ig_time = igraph::edge_betweenness(graph = igraph_bog,weights = bog_contracted$time),\n       cent_ig_time_weighted = igraph::edge_betweenness(graph = igraph_bog,\n                                                        weights = bog_contracted$time_weighted)\n       ),\n    by = \"edge_id\")\n\n\nsummary(cent_all_ig[,2:9])\n\n cent_d_weighted       cent_d        cent_time_weighted   cent_time      \n Min.   :      0   Min.   :      0   Min.   :      0    Min.   :      0  \n 1st Qu.:   5205   1st Qu.:   5171   1st Qu.:   4813    1st Qu.:   4767  \n Median :  21485   Median :  21479   Median :  19043    Median :  18886  \n Mean   :  93071   Mean   :  93203   Mean   :  94823    Mean   :  94902  \n 3rd Qu.:  89238   3rd Qu.:  88753   3rd Qu.:  70392    3rd Qu.:  68960  \n Max.   :1455647   Max.   :1486152   Max.   :1952831    Max.   :1957269  \n   cent_ig_d       cent_ig_d_weighted  cent_ig_time     cent_ig_time_weighted\n Min.   :      0   Min.   :      0    Min.   :      0   Min.   :      0      \n 1st Qu.:   5171   1st Qu.:   5205    1st Qu.:   4767   1st Qu.:   4813      \n Median :  21479   Median :  21485    Median :  18886   Median :  19043      \n Mean   :  93203   Mean   :  93071    Mean   :  94902   Mean   :  94823      \n 3rd Qu.:  88753   3rd Qu.:  89238    3rd Qu.:  68960   3rd Qu.:  70392      \n Max.   :1486152   Max.   :1455647    Max.   :1957269   Max.   :1952831      \n\n\nCheck if igraph results are identical to the ones obtained with dodgr\n\nwith(cent_all_ig,identical(cent_ig_d_weighted,cent_d_weighted))\n\n[1] TRUE\n\nwith(cent_all_ig,identical(cent_ig_time_weighted,cent_time_weighted))\n\n[1] TRUE\n\n\n\npairs(cent_all_ig[,2:9])\n\n\n\n\n\n\n\n\nJoining the results to the sf object\n\nsf_net &lt;- graph_bogota |&gt;\n  dodgr_to_sf() |&gt; \n  left_join(cent_all,by = \"edge_id\")\n\n\n\n\n\nsf_net |&gt;  \n  select(cent_d_weighted:cent_time) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  ggplot()+\n  geom_sf(aes(col = log(cent),linewidth = cent+1))+\n  facet_wrap(type~.)+\n  scale_color_viridis_c(\n    # direction = -1\n    )+\n  scale_linewidth_continuous(range = c(0.05,0.5),\n                             transform = scales::transform_boxcox(p = 2))+\n  theme_void()+\n  guides(linewidth = \"none\",)\n\n\n\n\n\n\n\n\nVisualising differences\n\nsf_net |&gt; \n  transmute(across(cent_d_weighted:cent_time,\n                   \\(x) (x - cent_d)/cent_d)) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  ggplot(aes(cent))+\n  geom_histogram()+\n  facet_wrap(type~.)+\n  scale_x_continuous(limits = c(-1,1))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2009 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nInspecting significant changes\n\nsf_net |&gt; \n  transmute(across(cent_d_weighted:cent_time,\n                   \\(x) (x - cent_d)/cent_d)) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  mutate(cent = case_when(abs(cent)&lt;0.1~0,\n                          cent &gt; 0.6 ~ 1,\n                          -cent &gt; 0.6 ~ -1,\n                          is.na(cent)~NA)) |&gt; \n  ggplot()+\n  geom_sf(aes(col = cent))+\n  facet_wrap(type~.)+\n  scale_color_distiller(palette = \"Spectral\", direction = 1)+\n  # scale_linewidth_continuous(range = c(0.05,0.5),\n  #                            transform = scales::transform_boxcox(p = 2))+\n  theme_void()\n\n\n\n\n\n\n\n\nIdentifying the links with differences &gt; 0 in d and weighted d\n\nsf_net |&gt; \n  mutate(diff_check = (d-d_weighted)==0) |&gt; \n  ggplot(aes(col = diff_check))+\n  geom_sf()+\n  theme_void()\n\n\n\n\n\n\n\n\nSame for time\n\nsf_net |&gt; \n  mutate(diff_check = (time-time_weighted)==0) |&gt; \n  ggplot(aes(col = diff_check))+\n  geom_sf()+\n  theme_void()\n\n\n\n\n\n\n\n\nA course assumption is that people decide the route they will use based on the ETA, also differences in speed limits can only captured if time is used. So weighted time will be used.\n\n\n\n\nlibrary(sfnetworks)\n\n\nsf_net$time_weighted[sf_net$time_weighted==0] &lt;- (3.6*sf_net$d_weighted[sf_net$time_weighted==0])/case_when(\n      sf_net$highway[sf_net$time_weighted==0] %in% c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~60,\n      T~30)\n\nbog_sfnet &lt;- sf_net |&gt; \n  as_sfnetwork(directed = TRUE)\n\n\nbog_sfnet &lt;- bog_sfnet |&gt;\n  activate(\"edges\") |&gt; \n  mutate(cent_sfn_time_weighted = tidygraph::centrality_edge_betweenness(\n    weights = time_weighted,\n    directed = T))\n\n\nbog_sfnet |&gt; \n  st_as_sf(\"edges\") |&gt; \nggplot()+\n  geom_sf(aes(col = cent_time_weighted))+\n  theme_void()\n\n\n\n\n\n\n\n\n\nbog_sfnet |&gt; \n  activate(\"edges\") |&gt;\n  data.frame() |&gt; \n  select(cent_time_weighted,cent_sfn_time_weighted) |&gt; \n  pairs()\n\n\n\n\n\n\n\n\n\nbog_sfnet |&gt; \n  activate(\"edges\") |&gt;\n  data.frame() |&gt; \n  with(identical(cent_time_weighted,cent_sfn_time_weighted))\n\n[1] TRUE\n\n\n\np1 = st_geometry(bog_sfnet, \"nodes\")[2401]\nst_crs(p1) = st_crs(bog_sfnet)\np2 = st_geometry(bog_sfnet, \"nodes\")[1407]\np3 = st_geometry(bog_sfnet, \"nodes\")[1509]\np4 = st_geometry(bog_sfnet, \"nodes\")[1840]\nst_crs(p3) = st_crs(bog_sfnet)\n\npaths = st_network_paths(bog_sfnet, from = p1, to = c(p2,p3,p4), weights = \"time_weighted\")\n\n\nplot_path = function(node_path) {\n  bog_sfnet %&gt;%\n    activate(\"nodes\") %&gt;%\n    slice(node_path) %&gt;%\n    plot(cex = 1.5, lwd = 1.5, add = TRUE)\n}\n\ncolors = sf.colors(4, categorical = TRUE)\n\n\nplot(bog_sfnet, col = \"grey\")\npaths %&gt;%\n  pull(node_paths) %&gt;%\n  walk(plot_path)\nplot(c(p1, p2, p3,p4), col = colors, pch = 8, cex = 2, lwd = 2, add = TRUE)"
  },
  {
    "objectID": "D1_graph_centrality_tests.html#loading-network",
    "href": "D1_graph_centrality_tests.html#loading-network",
    "title": "Graph Centrlity Tests",
    "section": "",
    "text": "sf_bogota_2019_full &lt;- st_read(file.path(\"sf_network\",\"bogota_osm_network.gpkg\"),\n                          layer = \"network_2019\")\n\nReading layer `network_2019' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\P1_Ratruns\\P1_ratruns_analysis\\sf_network\\bogota_osm_network.gpkg' \n  using driver `GPKG'\nSimple feature collection with 54531 features and 15 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -74.441 ymin: 4.236862 xmax: -73.72583 ymax: 5.042826\nGeodetic CRS:  MAGNA-SIRGAS\n\n\nWe will use a small subset of the network for this test to speed up the process.\n\nbog_zone &lt;- zonebuilder::zb_zone(\"Bogota\",n_circles = 2) |&gt; st_transform(st_crs(sf_bogota_2019_full))\n\nLoading required namespace: tmaptools\n\n# zb_view(bog_zone)\n\n\nsf_bogota_2019 &lt;- sf_bogota_2019_full[bog_zone,]\n\n\ngraph_bogota &lt;- weight_streetnet(sf_bogota_2019,\n                                 left_side = F,\n                                 wt_profile_file = \"bogota_wp.json\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols = c(\"oneway\",\"lanes\",\"surface\",\"maxspeed\"),\n                                 turn_penalty = F)\n\nbog_contracted &lt;- graph_bogota |&gt; \n  dodgr_contract_graph()"
  },
  {
    "objectID": "D1_graph_centrality_tests.html#assignment-of-the-weighting-profile",
    "href": "D1_graph_centrality_tests.html#assignment-of-the-weighting-profile",
    "title": "Graph Centrlity Tests",
    "section": "",
    "text": "In order to include the actual speed along each corridor, I will specify 60 different classes to be applied to each road link. By default, speeds are assigned by road link by road type, e.g. any trunk road in Bogotá has a 60 km/h speed.\n\n# custom_wp &lt;- dodgr::weighting_profiles$weighting_profiles |&gt; filter(name==\"motorcar\")\ncustom_penalties &lt;- dodgr::weighting_profiles$penalties |&gt; filter(name==\"motorcar\")\ncustom_surfaces &lt;- dodgr::weighting_profiles$surface_speeds |&gt; filter(name==\"motorcar\")\n\ncustom_wp &lt;- data.frame(name = \"motorcar\",\n                        way = paste0(\"road_\",1:60),\n                        value = 1,\n                        max_speed = as.numeric(1:60))\n\ncustom_wp_list &lt;- list(weighting_profiles = custom_wp,\n                       surface_speeds = custom_surfaces,\n                       pealties = custom_penalties)\n\nwpj &lt;- jsonlite::toJSON (custom_wp_list, pretty = TRUE)\nwrite_lines(wpj,file = \"custom_wp_speeds.json\")\n\nAssigning a speed category based on the speed limit (baseline scenario)\n\nsf_bogota_2019_cwp &lt;- sf_bogota_2019 |&gt;\n  mutate(way_speed = case_when(highway %in%\n                                 c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~\"road_60\",\n                                               TRUE ~ \"road_30\")) |&gt; \n  select(-highway)\n\nThe following code builds the graph using the new column instead of highway.\n\ngraph_bogota_custom &lt;- weight_streetnet(sf_bogota_2019_cwp,\n                                 left_side = F,\n                                 wt_profile_file = \"custom_wp_speeds.json\",\n                                 type_col = \"way_speed\",\n                                 wt_profile = \"motorcar\",\n                                 keep_cols = c(\"way_speed\",\"oneway\",\"lanes\",\"surface\",\"maxspeed\"),\n                                 turn_penalty = F)\n\n\n\nWe calculate the\n\ngraph_baseline_centrality &lt;- graph_bogota |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality()\n\ngraph_cwp_centrality &lt;- graph_bogota_custom |&gt; \n  dodgr_deduplicate_graph() |&gt;\n  dodgr_contract_graph() |&gt;\n  dodgr_centrality()\n\nTo validate that the results are identical, we can run the following code\n\nidentical(graph_baseline_centrality$centrality,graph_cwp_centrality$centrality)\n\n[1] TRUE"
  },
  {
    "objectID": "D1_graph_centrality_tests.html#centrality-calculations",
    "href": "D1_graph_centrality_tests.html#centrality-calculations",
    "title": "Graph Centrlity Tests",
    "section": "",
    "text": "There are four core alternatives for calculating the centrality using dodgr.\n\nbog_contracted[,\n    c(\"d_weighted\", \"d\", \"time_weighted\", \"time\")] |&gt;\n  pairs()\n\n\n\n\n\n\n\n\nAn initial check on the four alternatives reveal some inconsistencies in the time_weighted column.\nThere are 23 links in the contracted graph with differences in the weighted distance and the distance. The location of these edges will be inspected after calculating the centrality in Section 1.3.3.\nWhen multiple paths are available between two nodes in the contracted version of the graph, dodgr takes only the shortest weighted distance, which creates the difference. However, the resulting weighted time is not corrected and in some cases a 0 is returned.\nGiven this, we will recalculate the weighted time based on the weighted distance.\n\nbog_contracted$time_weighted[bog_contracted$time_weighted==0] &lt;- (3.6*bog_contracted$d_weighted[bog_contracted$time_weighted==0])/case_when(\n      bog_contracted$highway[bog_contracted$time_weighted==0] %in% c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~60,\n      T~30)\n\n\n\n\ncent_all &lt;- lapply(c(\"d_weighted\", \"d\", \"time_weighted\", \"time\"), \\(x) {\n  \n    df &lt;- bog_contracted |&gt;\n      dodgr_centrality(column = x)\n  \n  tibble(edge_id = df$edge_id, cent = df$centrality) |&gt;\n    rename_with(.cols = \"cent\", .fn = \\(.y) {\n      paste(.y, x, sep = \"_\")\n    })\n  }) |&gt;\n  plyr::join_all(by = \"edge_id\",type = \"full\")\n\n\n\n\n\nigraph_bog &lt;- bog_contracted |&gt; \n  dodgr_to_igraph()\n\nLoading required namespace: igraph\n\n\n\ncent_all_ig &lt;- cent_all |&gt; \n  left_join(\n    tibble(edge_id = bog_contracted$edge_id,\n       cent_ig_d = igraph::edge_betweenness(graph = igraph_bog,\n                                            weights = bog_contracted$d),\n       cent_ig_d_weighted = igraph::edge_betweenness(graph = igraph_bog,\n                                                     weights = bog_contracted$d_weighted),\n       cent_ig_time = igraph::edge_betweenness(graph = igraph_bog,weights = bog_contracted$time),\n       cent_ig_time_weighted = igraph::edge_betweenness(graph = igraph_bog,\n                                                        weights = bog_contracted$time_weighted)\n       ),\n    by = \"edge_id\")\n\n\nsummary(cent_all_ig[,2:9])\n\n cent_d_weighted       cent_d        cent_time_weighted   cent_time      \n Min.   :      0   Min.   :      0   Min.   :      0    Min.   :      0  \n 1st Qu.:   5205   1st Qu.:   5171   1st Qu.:   4813    1st Qu.:   4767  \n Median :  21485   Median :  21479   Median :  19043    Median :  18886  \n Mean   :  93071   Mean   :  93203   Mean   :  94823    Mean   :  94902  \n 3rd Qu.:  89238   3rd Qu.:  88753   3rd Qu.:  70392    3rd Qu.:  68960  \n Max.   :1455647   Max.   :1486152   Max.   :1952831    Max.   :1957269  \n   cent_ig_d       cent_ig_d_weighted  cent_ig_time     cent_ig_time_weighted\n Min.   :      0   Min.   :      0    Min.   :      0   Min.   :      0      \n 1st Qu.:   5171   1st Qu.:   5205    1st Qu.:   4767   1st Qu.:   4813      \n Median :  21479   Median :  21485    Median :  18886   Median :  19043      \n Mean   :  93203   Mean   :  93071    Mean   :  94902   Mean   :  94823      \n 3rd Qu.:  88753   3rd Qu.:  89238    3rd Qu.:  68960   3rd Qu.:  70392      \n Max.   :1486152   Max.   :1455647    Max.   :1957269   Max.   :1952831      \n\n\nCheck if igraph results are identical to the ones obtained with dodgr\n\nwith(cent_all_ig,identical(cent_ig_d_weighted,cent_d_weighted))\n\n[1] TRUE\n\nwith(cent_all_ig,identical(cent_ig_time_weighted,cent_time_weighted))\n\n[1] TRUE\n\n\n\npairs(cent_all_ig[,2:9])\n\n\n\n\n\n\n\n\nJoining the results to the sf object\n\nsf_net &lt;- graph_bogota |&gt;\n  dodgr_to_sf() |&gt; \n  left_join(cent_all,by = \"edge_id\")\n\n\n\n\n\nsf_net |&gt;  \n  select(cent_d_weighted:cent_time) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  ggplot()+\n  geom_sf(aes(col = log(cent),linewidth = cent+1))+\n  facet_wrap(type~.)+\n  scale_color_viridis_c(\n    # direction = -1\n    )+\n  scale_linewidth_continuous(range = c(0.05,0.5),\n                             transform = scales::transform_boxcox(p = 2))+\n  theme_void()+\n  guides(linewidth = \"none\",)\n\n\n\n\n\n\n\n\nVisualising differences\n\nsf_net |&gt; \n  transmute(across(cent_d_weighted:cent_time,\n                   \\(x) (x - cent_d)/cent_d)) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  ggplot(aes(cent))+\n  geom_histogram()+\n  facet_wrap(type~.)+\n  scale_x_continuous(limits = c(-1,1))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2009 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nInspecting significant changes\n\nsf_net |&gt; \n  transmute(across(cent_d_weighted:cent_time,\n                   \\(x) (x - cent_d)/cent_d)) |&gt; \n  pivot_longer(names_to = \"type\",names_prefix = \"cent_\",\n               cols = -geometry,\n               values_to = \"cent\") |&gt; \n  mutate(cent = case_when(abs(cent)&lt;0.1~0,\n                          cent &gt; 0.6 ~ 1,\n                          -cent &gt; 0.6 ~ -1,\n                          is.na(cent)~NA)) |&gt; \n  ggplot()+\n  geom_sf(aes(col = cent))+\n  facet_wrap(type~.)+\n  scale_color_distiller(palette = \"Spectral\", direction = 1)+\n  # scale_linewidth_continuous(range = c(0.05,0.5),\n  #                            transform = scales::transform_boxcox(p = 2))+\n  theme_void()\n\n\n\n\n\n\n\n\nIdentifying the links with differences &gt; 0 in d and weighted d\n\nsf_net |&gt; \n  mutate(diff_check = (d-d_weighted)==0) |&gt; \n  ggplot(aes(col = diff_check))+\n  geom_sf()+\n  theme_void()\n\n\n\n\n\n\n\n\nSame for time\n\nsf_net |&gt; \n  mutate(diff_check = (time-time_weighted)==0) |&gt; \n  ggplot(aes(col = diff_check))+\n  geom_sf()+\n  theme_void()\n\n\n\n\n\n\n\n\nA course assumption is that people decide the route they will use based on the ETA, also differences in speed limits can only captured if time is used. So weighted time will be used.\n\n\n\n\nlibrary(sfnetworks)\n\n\nsf_net$time_weighted[sf_net$time_weighted==0] &lt;- (3.6*sf_net$d_weighted[sf_net$time_weighted==0])/case_when(\n      sf_net$highway[sf_net$time_weighted==0] %in% c(\"trunk_link\",\"primary_link\",\"primary\",\"trunk\")~60,\n      T~30)\n\nbog_sfnet &lt;- sf_net |&gt; \n  as_sfnetwork(directed = TRUE)\n\n\nbog_sfnet &lt;- bog_sfnet |&gt;\n  activate(\"edges\") |&gt; \n  mutate(cent_sfn_time_weighted = tidygraph::centrality_edge_betweenness(\n    weights = time_weighted,\n    directed = T))\n\n\nbog_sfnet |&gt; \n  st_as_sf(\"edges\") |&gt; \nggplot()+\n  geom_sf(aes(col = cent_time_weighted))+\n  theme_void()\n\n\n\n\n\n\n\n\n\nbog_sfnet |&gt; \n  activate(\"edges\") |&gt;\n  data.frame() |&gt; \n  select(cent_time_weighted,cent_sfn_time_weighted) |&gt; \n  pairs()\n\n\n\n\n\n\n\n\n\nbog_sfnet |&gt; \n  activate(\"edges\") |&gt;\n  data.frame() |&gt; \n  with(identical(cent_time_weighted,cent_sfn_time_weighted))\n\n[1] TRUE\n\n\n\np1 = st_geometry(bog_sfnet, \"nodes\")[2401]\nst_crs(p1) = st_crs(bog_sfnet)\np2 = st_geometry(bog_sfnet, \"nodes\")[1407]\np3 = st_geometry(bog_sfnet, \"nodes\")[1509]\np4 = st_geometry(bog_sfnet, \"nodes\")[1840]\nst_crs(p3) = st_crs(bog_sfnet)\n\npaths = st_network_paths(bog_sfnet, from = p1, to = c(p2,p3,p4), weights = \"time_weighted\")\n\n\nplot_path = function(node_path) {\n  bog_sfnet %&gt;%\n    activate(\"nodes\") %&gt;%\n    slice(node_path) %&gt;%\n    plot(cex = 1.5, lwd = 1.5, add = TRUE)\n}\n\ncolors = sf.colors(4, categorical = TRUE)\n\n\nplot(bog_sfnet, col = \"grey\")\npaths %&gt;%\n  pull(node_paths) %&gt;%\n  walk(plot_path)\nplot(c(p1, p2, p3,p4), col = colors, pch = 8, cex = 2, lwd = 2, add = TRUE)"
  }
]