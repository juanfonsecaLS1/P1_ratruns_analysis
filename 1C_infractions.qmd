---
editor: 
  markdown: 
    wrap: 72
---

# Ticket Data

```{r}
#| message: false
options(repos = c(CRAN = "https://cloud.r-project.org"))
if (!require("remotes")) install.packages("remotes")
pkgs = c(
    "sf",
    "tidyverse",
    "tmap",
    "webshot2",
    "gganimate"
)
remotes::install_cran(pkgs)
sapply(pkgs, require, character.only = TRUE)

tmap_mode("plot")
```

## Download data

```{r}
if(!dir.exists("raw_data/bogota")) {
  if (!file.exists("raw_data/bogota_data.zip")) {
    options(timeout = 180)
    download.file(
      "https://github.com/juanfonsecaLS1/P1_ratruns_analysis/releases/download/v0/bogota_data.zip",
      destfile = "raw_data/bogota_data.zip",
      mode = "wb"
    )
    unzip("raw_data/bogota_data.zip", exdir = "raw_data")
  }
}
```

### Urban perimeter

```{r}
urban_perimeter <- st_read("raw_data/perimetrourbano.gpkg") |>
  st_transform(4326)

```

## Loading Infractions

```{r}
#| label: reading-data
reports2019 <- read_csv("raw_data/bogota/Comparendos_2019_Bogota_D_C.csv",
                        col_types = cols(
                          X = col_double(),
                          Y = col_double(),
                          OBJECTID = col_double(),
                          NUM_COMPARENDO = col_character(),
                          FECHA_HORA = col_character(),
                          ANO = col_double(),
                          HORA_OCURRENCIA = col_character(),
                          MES = col_character(),
                          MEDIO_DETECCION = col_character(),
                          CLASE_VEHICULO = col_character(),
                          TIPO_SERVICIO = col_character(), 
                          INFRACCION = col_character(),
                          DES_INFRACCION = col_character(),
                          LOCALIDAD = col_character(),
                          MUNICIPIO = col_character(),
                          LATITUD = col_double(),
                          LONGITUD = col_double(),
                          GlobalID = col_character()
                        ))

reports2020 <- read_csv("raw_data/bogota/Comparendos_DEI_2020_Bogot%C3%A1_D_C.csv",
                        col_types = cols(
                          X = col_double(),
                          Y = col_double(),
                          FID = col_double(),
                          OBJECTID = col_double(),
                          FECHA_HORA = col_character(),
                          ANO = col_double(),
                          HORA_OCURR = col_character(),
                          MES = col_character(),
                          MEDIO_DETE = col_character(),
                          CLASE_VEHI = col_character(),
                          TIPO_SERVI = col_character(),
                          INFRACCION = col_character(),
                          DES_INFRAC = col_character(),
                          MUNICIPIO = col_character(),
                          PAIS = col_character(),
                          LATITUD = col_double(),
                          LONGITUD = col_double()))

```

A list of the codes with codes of offences related to vehicles
circulating.

```{r}
selected_codes <- read.csv("list_infractions.csv")$INFRACCION
```

## Exploring types of infractions

```{r}
#| label: top-infractions-plot

reports2019 |> 
  count(INFRACCION) |> 
  filter(n>quantile(n,0.90)) |> 
  ggplot(aes(y = fct_reorder(INFRACCION,n),
             x = n))+
  geom_col()+
  scale_x_continuous()
```

```{r}
#| label: top-infractions-tibble
 
count_infractions <- reports2019 |> 
  count(INFRACCION,DES_INFRACCION) |> 
  filter(n>quantile(n,0.70)) |> 
  arrange(-n)
```

## Wrong way infraction

Creating an `sf` object with the reports for driving in the wrong-way

```{r}

wrong_way_2019_sf <- reports2019 |>
  filter(INFRACCION == "D03") |> 
  select(-DES_INFRACCION) |>
  mutate(time = hms(HORA_OCURRENCIA)) |> 
  st_as_sf(coords = c("LONGITUD","LATITUD"),crs = 4326)

wrong_way_2020_sf <- reports2020 |>
  filter(INFRACCION == "D03") |> 
  select(-DES_INFRAC) |> 
  mutate(time = hms(HORA_OCURR)) |>
  st_as_sf(coords = c("LONGITUD","LATITUD"),crs = 4326)
```

```{r}

manual_2019_sf <- reports2019 |>
  filter(INFRACCION %in% selected_codes) |> 
  select(-DES_INFRACCION) |>
  mutate(time = hms(HORA_OCURRENCIA)) |> 
  st_as_sf(coords = c("LONGITUD","LATITUD"),crs = 4326)

manual_2020_sf <- reports2020 |>
  filter(INFRACCION %in% selected_codes) |> 
  select(-DES_INFRAC) |> 
  mutate(time = hms(HORA_OCURR)) |>
  st_as_sf(coords = c("LONGITUD","LATITUD"),crs = 4326)
```

## Tidying-up the datasets

We will select only relevant columns and also classify the records by
type of day. For that, we will use the bank holiday list we used for the
speed data processing.

```{r}
#| label: read-bankholidays

bank_holidays <- read.csv("raw_data/bogota/bank_holidays.csv") |>
  mutate(bank_holiday = dmy(bank_holiday)) |>
  pull(bank_holiday)
```

```{r}
wwd_2019_clean <- wrong_way_2019_sf |> 
  select(FECHA_HORA,
         MEDIO_DETECCION,
         CLASE_VEHICULO,
         time) |>
  rename(date_time = FECHA_HORA,
         detect_device = MEDIO_DETECCION,
         veh_class = CLASE_VEHICULO) |>
  mutate(date_time = str_replace(date_time,"\\+00","-05")) |> 
  mutate(timestamp = ymd_hms(date_time, tz = "America/Bogota"),
         hour = hour(time),
         year = year(timestamp)) |> 
  mutate(day_type = case_when(date(timestamp) %in% bank_holidays~"weekend",
                              wday(timestamp,week_start = 1)<=4~"weekday",
                              wday(timestamp,week_start = 1) == 5~"friday",
                              T~"weekend"))
```

```{r}
wwd_2020_clean <- wrong_way_2020_sf |> 
  select(FECHA_HORA,
         MEDIO_DETE,
         CLASE_VEHI,
         time) |>
  rename(date_time = FECHA_HORA,
         detect_device = MEDIO_DETE,
         veh_class = CLASE_VEHI) |>
  mutate(date_time = str_replace(date_time,"\\+00","-05")) |> 
  mutate(timestamp = ymd_hms(date_time, tz = "America/Bogota"),
         hour = hour(time),
         year = year(timestamp)) |> 
  mutate(day_type = case_when(date(timestamp) %in% bank_holidays~"weekend",
                              wday(timestamp,week_start = 1)<=4~"weekday",
                              wday(timestamp,week_start = 1) == 5~"friday",
                              T~"weekend"))
```

All manual tickets

```{r}
manual_2019_clean <-  manual_2019_sf|> 
  select(FECHA_HORA,
         MEDIO_DETECCION,
         CLASE_VEHICULO,
         time,
         INFRACCION) |>
  rename(date_time = FECHA_HORA,
         detect_device = MEDIO_DETECCION,
         veh_class = CLASE_VEHICULO,
         off_code = INFRACCION) |>
  mutate(date_time = str_replace(date_time,"\\+00","-05")) |> 
  mutate(timestamp = ymd_hms(date_time, tz = "America/Bogota"),
         hour = hour(time),
         year = year(timestamp)) |> 
  mutate(day_type = case_when(date(timestamp) %in% bank_holidays~"weekend",
                              wday(timestamp,week_start = 1)<=4~"weekday",
                              wday(timestamp,week_start = 1) == 5~"friday",
                              T~"weekend"))
```

```{r}
manual_2020_clean <- manual_2020_sf |> 
  select(FECHA_HORA,
         MEDIO_DETE,
         CLASE_VEHI,
         time,
         INFRACCION) |>
  rename(date_time = FECHA_HORA,
         detect_device = MEDIO_DETE,
         veh_class = CLASE_VEHI,
         off_code = INFRACCION) |>
  mutate(date_time = str_replace(date_time,"\\+00","-05")) |> 
  mutate(timestamp = ymd_hms(date_time, tz = "America/Bogota"),
         hour = hour(time),
         year = year(timestamp)) |> 
  mutate(day_type = case_when(date(timestamp) %in% bank_holidays~"weekend",
                              wday(timestamp,week_start = 1)<=4~"weekday",
                              wday(timestamp,week_start = 1) == 5~"friday",
                              T~"weekend"))
```

And consolidating the two datasets

```{r}
all_wwd_reports <- bind_rows(wwd_2019_clean,wwd_2020_clean)[urban_perimeter,] |> 
  mutate(veh_class = str_to_lower(veh_class)) |> drop_na()

all_manual_reports <- bind_rows(manual_2019_clean,manual_2020_clean)[urban_perimeter,] |> 
  mutate(veh_class = str_to_lower(veh_class)) |> drop_na()
```

## EDA

### Temporal distribution

A daily profile

```{r}
ggplot(all_wwd_reports,
         aes(x = time, col = factor(year)))+
  geom_density(alpha = 0.5,linewidth = 2)+
    scale_x_time()+
  scale_colour_manual(values = c("dodgerblue3","firebrick3"))+
  # scale_y_continuous(labels = scales::label_percent(accuracy = 2))+
theme_minimal()+
  labs(title = "WWD reports")+
  facet_grid(.~day_type)

ggplot(all_manual_reports,
         aes(x = time, col = factor(year)))+
  geom_density(alpha = 0.5,linewidth = 2)+
    scale_x_time()+
  scale_colour_manual(values = c("dodgerblue3","firebrick3"))+
  # scale_y_continuous(labels = scales::label_percent(accuracy = 2))+
theme_minimal()+
  labs(title = "All manual reports")+
  facet_grid(.~day_type)
```

```{r}
all_wwd_reports |>
  st_drop_geometry() |> 
  count(date(timestamp),day_type,hour,year) |> 
  ggplot(aes(x=factor(hour),y = n,col = day_type))+
  geom_jitter(alpha = 0.05)+
  geom_boxplot(alpha = 0.5,outlier.shape = NA)+
  facet_grid(year~.)+
  theme_minimal()

all_manual_reports |>
  st_drop_geometry() |> 
  count(date(timestamp),day_type,hour,year) |> 
  ggplot(aes(x=factor(hour),y = n,col = day_type))+
  geom_jitter(alpha = 0.05)+
  geom_boxplot(alpha = 0.5,outlier.shape = NA)+
  facet_grid(year~.)+
  theme_minimal()
```

A check of the reports per day

```{r}
exp_dates_count <- all_wwd_reports |>
  st_drop_geometry() |> 
  count(date = date(timestamp)) |> 
  right_join(
    tibble(date = seq(min(date(all_wwd_reports$date_time)),
                      max(date(all_wwd_reports$date_time)),
                      by = "1 day")),by = "date")

exp_dates_count_all <- all_manual_reports |>
  st_drop_geometry() |> 
  count(date = date(timestamp)) |> 
  right_join(
    tibble(date = seq(min(date(all_manual_reports$date_time)),
                      max(date(all_manual_reports$date_time)),
                      by = "1 day")),by = "date")
  
```

A quick check of the timeline reveals gaps in the reports of 2019. We do
not know the causes.

```{r}
exp_dates_count |> 
  mutate(n = if_else(is.na(n),0,n)) |> 
  ggplot(aes(x = date,y = n))+
  geom_line()+
  theme_minimal()
```

```{r}
exp_dates_count |> 
  mutate(wday = wday(date,week_start = 2),
         week = week(date)) |> 
  ggplot(aes(y = factor(wday),x = factor(week),fill = n))+
  geom_tile()+
  theme_minimal()+
  facet_grid(year(date)~.)+
  scale_fill_viridis_c(direction = -1)+
  labs(title = "Daily WWD reports")

exp_dates_count_all |> 
  mutate(wday = wday(date,week_start = 2),
         week = week(date)) |> 
  ggplot(aes(y = factor(wday),x = factor(week),fill = n))+
  geom_tile()+
  theme_minimal()+
  facet_grid(year(date)~.)+
  scale_fill_viridis_c(direction = -1)+
  labs(title = "Daily manual reports (all)")

```

### Spatial distribution

```{r}
ggplot(all_wwd_reports,aes(col = factor(year)))+
  geom_sf(alpha = 0.2,size = 0.5)+
  theme_void()   
```

#### Distributed


```{r}
#| eval: false
a <- all_manual_reports |>
  filter(year == 2019, day_type == "weekday") |>
  mutate(quarter = floor(time@minute/15)) |> 
  nest(.by = c(hour,quarter)) |> 
  arrange(hour,quarter) |> 
  mutate(hour. = paste0(sprintf("%2d",hour),":",sprintf("%02d",quarter*15)),
         plot = map2(.x = data,.y = hour.,
                     \(.x,.y){
                       .x |> 
                         ggplot() +
                         geom_sf(data = urban_perimeter, fill = "white")+
                         geom_sf(col = "red",shape = "+",size = 2.5)+
                         theme_void()+
                         labs(title = paste("Reports:",.y))
                     }))


for (i in seq_len(nrow(a))){
  ggsave(a$plot[[i]],filename = paste0("sf_network/off_",sprintf("%02d",a$hour[i]),"_",a$quarter[i],".png"))
}


png_files= list.files(path = "sf_network/",pattern = "off_.*.png",full.names = T)


apng::apng(png_files, output_file = "sf_network/anim_off.png",num_plays = 0,delay_num = 1,delay_den = 2)

```

```{r}
#| echo: false
knitr::include_graphics("sf_network/anim_off.png")
```


#### Aggregated
Generating a grid covering the urban perimeter

```{r}
grid_bog <- urban_perimeter |> 
  st_transform(3116) |> 
  st_make_grid(cellsize = 1e3) |> 
  st_as_sf() 


grid_bog <- grid_bog[urban_perimeter |> 
                       st_transform(3116) |>
                       st_union() |> 
                       st_convex_hull(),] |> 
  st_transform(st_crs(all_manual_reports)) |> 
  rowid_to_column("cell_id")
```

Assigning the reports to the grid cells

```{r}
all_manual_grid <- all_manual_reports

all_manual_grid$grid_cell <- st_intersects(all_manual_reports,
                                              grid_bog) |> 
  unlist()
```

```{r}
exp_hourly_grid <- expand_grid(grid_cell = all_manual_grid$grid_cell |> unique(),
                               hour=all_manual_grid$hour |> unique(),
                               date = seq(min(date(all_manual_grid$date_time)),
                                          max(date(all_manual_grid$date_time)),
                                          by = "1 day"))

hourly_grid <- all_manual_grid |> 
  st_drop_geometry() |> 
  count(grid_cell,date = date(timestamp),hour) |>
  right_join(exp_hourly_grid,
             by = join_by(date, hour,grid_cell)) |>
  mutate(n = if_else(is.na(n),0,n)) |> 
  mutate(year = year(date),
         day_type = case_when(date %in% bank_holidays~"weekend",
                              wday(date, week_start = 1)<=4~"weekday",
                              wday(date, week_start = 1) == 5~"friday",
                              T~"weekend")) |> 
  summarise(across(n,
                   list(mean = mean,
                        median = median)),
            .by = c(grid_cell,hour,year,day_type)
            ) 
```

```{r}
#| eval: false

p <- grid_bog |>
  right_join(hourly_grid |>
               expand(grid_cell,hour,year,day_type),
             by = c("cell_id" = "grid_cell")) |>
  left_join(hourly_grid |> filter(n_mean>0),
            by = c("cell_id" = "grid_cell","hour","year","day_type")) |>
            # by = c("cell_id" = "grid_cell")) |>
  filter(day_type == "weekday") |>
  ggplot() +
  geom_sf(aes(fill = n_mean,
              group = cell_id),
          alpha = 0.6) +
  scale_fill_viridis_b(na.value = "gray80") +
  theme_void() +
  facet_grid(. ~ year) +
  labs(title = "Mean hourly reports",
    subtitle = 'Hour: {closest_state}') +
  transition_states(hour, transition_length = 2, state_length = 1) +
  enter_appear()

anim_save(animation = p,filename = "sf_network/map_animated.gif")

```

```{r}
#| echo: false

knitr::include_graphics("sf_network/map_animated.gif")
```



### Exploring biases

#### Temporal sampling bias?

Let us check if there is any patter related to the day of the week

```{r}
all_wwd_reports |>
  st_drop_geometry() |> 
  count(date = date(timestamp),year) |> 
  mutate(wday = wday(date,week_start = 2)) |> 
  summarise(n = mean(n),.by = c(wday,year)) |> 
  ggplot(aes(x= wday,y = n, col = factor(year)))+
  geom_line()+
  scale_x_continuous(breaks = 1:7,
                     labels = weekdays(as.Date(4,"1970-01-01",tz="GMT")+0:6))+
  labs(x="")
```

There seems to be a pattern that might be related to the sampling i.e.
how the enforcement officers are assigned along the week.

Let's compare with other offences reported manually by officers

```{r}
all_manual_reports |>
  st_drop_geometry() |> 
  count(date = date(timestamp),year) |> 
  mutate(wday = wday(date,week_start = 2)) |> 
  summarise(n = mean(n),.by = c(wday,year)) |> 
  ggplot(aes(x= wday,y = n, col = factor(year)))+
  geom_line()+
  scale_x_continuous(breaks = 1:7,
                     labels = weekdays(as.Date(4,"1970-01-01",tz="GMT")+0:6))+
  labs(x="")
```

We can also inspect the median number of tickets per weekday for all
offences that are reported by traffic management officers in 2019 and
2020

```{r}
all_manual_reports |> 
  st_drop_geometry() |> 
  count(date = date(timestamp),year) |> 
  mutate(wday = wday(date,week_start = 2)) |> 
  summarise(n = mean(n),.by = c(wday,year)) |> 
  # filter(sum(n)>250,.by = offence) |> 
  ggplot(aes(x= wday,y = n,col = factor(year)))+
  geom_line()+
  scale_x_continuous(breaks = 1:7,
                     labels = weekdays(as.Date(4,"1970-01-01",tz="GMT")+0:6))+
  labs(x="")+
  theme_minimal()
```

Is it a problem with the data, as some months are not reported? Let's
see if the pattern is similar across months

```{r}
all_manual_reports |> 
  st_drop_geometry() |>  
  mutate(month = month(timestamp)) |> 
  count(date = date(timestamp),month,year) |> 
  mutate(wday = wday(date,week_start = 2)) |> 
  summarise(n = median(n),.by = c(wday,month,year)) |> 
  # filter(sum(n)>250,.by = offence) |> 
  ggplot(aes(x= wday,y = n,col =  factor(month)))+
  geom_line()+
  scale_x_continuous(breaks = 1:7,
                     labels = weekdays(as.Date(4,"1970-01-01",tz="GMT")+0:6))+
  labs(x="")+
  theme_minimal()+
  facet_grid(.~year)+
  theme(axis.text.x = element_text(angle = 90))
  
```

Visually, there seems to be a consistent pattern of a low number of
reports during Friday and Saturday, followed by a surge on Sundays.

#### Spatial sampling bias?

Let's assign all reports to the nearest link to explore where the
enforcement offices tend to `catch` the offenders

```{r}
net_bog_2019 <-
  st_read(file.path("sf_network", "bogota_osm_network.gpkg")) |>
  st_transform(3116)
```

```{r}
major_network <- net_bog_2019 |>
  filter(!(highway %in% c("residential","unclassified")))
```

```{r}
manual_reports_2019 <- reports2019 |>
  select(-DES_INFRACCION) |>
  filter(MEDIO_DETECCION == "LAPIZ",INFRACCION %in% selected_codes) |> 
  mutate(time = hms(HORA_OCURRENCIA)) |> 
  select(FECHA_HORA,
         MEDIO_DETECCION,
         CLASE_VEHICULO,
         time,
         INFRACCION,
         LONGITUD,LATITUD) |>
  rename(date_time = FECHA_HORA,
         detect_device = MEDIO_DETECCION,
         veh_class = CLASE_VEHICULO,
         offence = INFRACCION) |> 
  st_as_sf(coords = c("LONGITUD","LATITUD"),crs = 4326) |> 
  st_transform(3116)
```

```{r}
manual_reports_2019$near_index <- st_nearest_feature(manual_reports_2019,net_bog_2019)
manual_reports_2019$near_major_index <- st_nearest_feature(manual_reports_2019,major_network)
```

```{r}
manual_reports_2019$highway <- net_bog_2019$highway[manual_reports_2019$near_index]
manual_reports_2019$oneway <- net_bog_2019$oneway[manual_reports_2019$near_index]
```

```{r}
manual_reports_2019$dist_to_major <- st_distance(
  manual_reports_2019,
  major_network[manual_reports_2019$near_major_index,],
  by_element = T) |> as.numeric()
```

Type of road where the offence was reported

```{r}
manual_reports_2019 |> 
  st_drop_geometry() |> 
  mutate(highway = str_remove(highway,"_link")) |> 
  mutate(date_time = str_replace(date_time,"\\+00","-05")) |> 
  mutate(timestamp = ymd_hms(date_time, tz = "America/Bogota"),
         hour = hour(time),
         year = year(timestamp),
         month = month(timestamp)) |> 
  count(date = date(timestamp),highway) |> 
  summarise(n = median(n),.by = c(highway)) |> 
  ggplot(aes(x = fct_reorder(highway,n,.desc = F),y = n))+
  geom_col()+
  coord_flip()
```

```{r}
manual_reports_2019 |> 
  st_drop_geometry() |> 
  mutate(highway = str_remove(highway,"_link")) |>
  mutate(highway = factor(highway,
                          levels =
                            c("trunk","primary","secondary","tertiary","residential","unclassified"),
                          ordered = T)) |> 
  mutate(date_time = str_replace(date_time,"\\+00","-05")) |> 
  mutate(timestamp = ymd_hms(date_time, tz = "America/Bogota"),
         hour = hour(time),
         year = year(timestamp),
         month = month(timestamp)) |> 
  count(date = date(timestamp),highway) |> 
  summarise(n = median(n),.by = c(highway)) |>
  arrange(highway) |> 
  mutate(perc = n/sum(n)) |>
  # mutate(prev = cumsum(perc)-perc) |> 
  # select(-n) |> 
  # pivot_longer(-highway) |> 
  ggplot(aes(x = 1,y = perc,fill = highway))+
  geom_col(position = "stack")+
  # scale_alpha_manual(values = c(1,0.2))+
  coord_flip()+
  theme_minimal()+
  scale_y_continuous(labels = scales::label_percent())
```

Median daily reports in residential roads

```{r}
manual_reports_2019 |> 
  st_drop_geometry() |> 
  mutate(highway = str_remove(highway,"_link")) |> 
  mutate(date_time = str_replace(date_time,"\\+00","-05")) |> 
  mutate(timestamp = ymd_hms(date_time, tz = "America/Bogota"),
         hour = hour(time),
         year = year(timestamp),
         month = month(timestamp)) |> 
  filter(highway == "residential") |>
  count(date = date(timestamp),offence) |> 
  summarise(n = median(n),.by = c(offence)) |>
  slice_max(n,n=15) |> 
  ggplot(aes(x = fct_reorder(offence,n), y = n))+
  geom_col()+
  coord_flip()
```

Euclidean distance to major network vs all reports

```{r}
ggplot()+
  geom_histogram(data = manual_reports_2019,
                 aes(dist_to_major),
                 alpha = 0.1)+
  geom_histogram(data = manual_reports_2019 |> 
  filter(highway %in% c("residential","unclassified")),
  aes(dist_to_major),
  alpha = 0.3,
  fill = "dodgerblue4",
  col = "dodgerblue3")+
  scale_x_log10()
  
```

```{r}
ggplot()+
  geom_histogram(data = manual_reports_2019 |> 
  filter(highway %in% c("residential","unclassified")),
  aes(dist_to_major),
  alpha = 0.2)+
  geom_histogram(data = manual_reports_2019 |> 
  filter(highway %in% c("residential","unclassified"),offence == "D03"),
  aes(dist_to_major),
  alpha = 0.3,
  fill = "dodgerblue4",
  col = "dodgerblue3")+
  scale_x_sqrt()
  

```

```{r}
net_points <- net_bog_2019 |>
  st_cast("POINT") |>
  slice_head(by = osm_id)
net_points <- net_bog_2019 |> st_centroid()

net_points$near_id <- st_nearest_feature(net_points,major_network)
net_points$dist_to_major <- st_distance(net_points,
                                        major_network[net_points$near_id,],
                                        by_element = T) |>
  as.numeric()
```

```{r}
ggplot()+
  geom_density(data = net_points|> 
  filter(highway %in% c("residential","unclassified")),
                 aes(dist_to_major),
                 alpha = 0.1)+
  geom_density(data = manual_reports_2019 |> 
  filter(highway %in% c("residential","unclassified"), offence == "D03"),
  aes(dist_to_major),
  alpha = 0.3,
  fill = "dodgerblue4",
  col = "dodgerblue3")+
  scale_x_sqrt(breaks = c(0,0.1,0.25,.5,1,2.5,5,7.5,10)*1e3)
```

```{r}
tmap_mode("plot")

tm_shape(major_network)+
  tm_lines()+
  tm_shape(manual_reports_2019 |> 
  filter(highway %in% c("residential","unclassified"), offence == "D03"))+
  tm_dots("dist_to_major")
```

### Summary by vehicle type

```{r}
all_wwd_reports |>
  st_drop_geometry() |>  
  count(veh_class,year) |> 
  arrange(-n) |> 
  mutate(n = n/sum(n),.by=year) |> 
  ggplot(aes(x = fct_reorder(veh_class,n,.desc = F),  y = n, fill = factor(year)))+
  geom_col(position = "dodge",)+
  coord_flip()+
  scale_y_continuous(labels = scales::label_percent())+
  theme_minimal()+
  scale_fill_manual(values = c("dodgerblue3","firebrick3"))
```

## Saving clean datasets

```{r}
st_write(all_wwd_reports,
         dsn = "sf_network/wwd_clean_sf.gpkg",
         delete_dsn = T)
```

```{r}
st_write(all_manual_reports,
         dsn = "sf_network/manualtickets_clean_sf.gpkg",
         delete_dsn = T)
```
